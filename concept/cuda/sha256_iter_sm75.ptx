//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-29373293
// Cuda compilation tools, release 11.2, V11.2.67
// Based on NVVM 7.0.1
//

.version 7.2
.target sm_75
.address_size 64

	// .globl	sha256_iter

.visible .entry sha256_iter(
	.param .u32 sha256_iter_param_0,
	.param .u64 sha256_iter_param_1,
	.param .u64 sha256_iter_param_2
)
.maxntid 128, 1, 1
.minnctapersm 1
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<3917>;
	.reg .b64 	%rd<11>;


	ld.param.u32 	%r36, [sha256_iter_param_0];
	ld.param.u64 	%rd2, [sha256_iter_param_1];
	mov.u32 	%r37, %tid.x;
	shl.b32 	%r1, %r37, 3;
	cvta.to.global.u64 	%rd3, %rd2;
	mul.wide.s32 	%rd4, %r1, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.u32 	%r3913, [%rd5];
	ld.global.u32 	%r3912, [%rd5+4];
	ld.global.u32 	%r3911, [%rd5+8];
	ld.global.u32 	%r3910, [%rd5+12];
	ld.global.u32 	%r3909, [%rd5+16];
	ld.global.u32 	%r3914, [%rd5+20];
	ld.global.u32 	%r3915, [%rd5+24];
	ld.global.u32 	%r3916, [%rd5+28];
	setp.lt.s32 	%p1, %r36, 1;
	@%p1 bra 	LBB0_3;

	mov.u32 	%r38, 0;
	mov.u32 	%r3900, %r38;

LBB0_2:
	ld.param.u32 	%r3897, [sha256_iter_param_0];
	mov.u32 	%r794, 7;
	// begin inline asm
	shf.r.clamp.b32 %r39, %r3912, %r3912, %r794;
	// end inline asm
	mov.u32 	%r798, 18;
	// begin inline asm
	shf.r.clamp.b32 %r43, %r3912, %r3912, %r798;
	// end inline asm
	shr.u32 	%r2599, %r3912, 3;
	xor.b32  	%r2600, %r39, %r2599;
	xor.b32  	%r2601, %r2600, %r43;
	mov.u32 	%r802, 17;
	// begin inline asm
	shf.r.clamp.b32 %r47, %r38, %r38, %r802;
	// end inline asm
	mov.u32 	%r806, 19;
	// begin inline asm
	shf.r.clamp.b32 %r51, %r38, %r38, %r806;
	// end inline asm
	xor.b32  	%r2602, %r51, %r47;
	add.s32 	%r2603, %r2601, %r3913;
	add.s32 	%r285, %r2603, %r2602;
	// begin inline asm
	shf.r.clamp.b32 %r55, %r3911, %r3911, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r59, %r3911, %r3911, %r798;
	// end inline asm
	shr.u32 	%r2604, %r3911, 3;
	xor.b32  	%r2605, %r55, %r2604;
	xor.b32  	%r2606, %r2605, %r59;
	mov.u32 	%r269, 256;
	// begin inline asm
	shf.r.clamp.b32 %r63, %r269, %r269, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r67, %r269, %r269, %r806;
	// end inline asm
	xor.b32  	%r2607, %r67, %r63;
	add.s32 	%r2608, %r2606, %r3912;
	add.s32 	%r301, %r2608, %r2607;
	// begin inline asm
	shf.r.clamp.b32 %r71, %r3910, %r3910, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r75, %r3910, %r3910, %r798;
	// end inline asm
	shr.u32 	%r2609, %r3910, 3;
	xor.b32  	%r2610, %r71, %r2609;
	xor.b32  	%r2611, %r2610, %r75;
	// begin inline asm
	shf.r.clamp.b32 %r79, %r285, %r285, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r83, %r285, %r285, %r806;
	// end inline asm
	shr.u32 	%r2612, %r285, 10;
	xor.b32  	%r2613, %r79, %r2612;
	xor.b32  	%r2614, %r2613, %r83;
	add.s32 	%r2615, %r2611, %r3911;
	add.s32 	%r317, %r2615, %r2614;
	// begin inline asm
	shf.r.clamp.b32 %r87, %r3909, %r3909, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r91, %r3909, %r3909, %r798;
	// end inline asm
	shr.u32 	%r2616, %r3909, 3;
	xor.b32  	%r2617, %r87, %r2616;
	xor.b32  	%r2618, %r2617, %r91;
	// begin inline asm
	shf.r.clamp.b32 %r95, %r301, %r301, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r99, %r301, %r301, %r806;
	// end inline asm
	shr.u32 	%r2619, %r301, 10;
	xor.b32  	%r2620, %r95, %r2619;
	xor.b32  	%r2621, %r2620, %r99;
	add.s32 	%r2622, %r2618, %r3910;
	add.s32 	%r333, %r2622, %r2621;
	// begin inline asm
	shf.r.clamp.b32 %r103, %r3914, %r3914, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r107, %r3914, %r3914, %r798;
	// end inline asm
	shr.u32 	%r2623, %r3914, 3;
	xor.b32  	%r2624, %r103, %r2623;
	xor.b32  	%r2625, %r2624, %r107;
	// begin inline asm
	shf.r.clamp.b32 %r111, %r317, %r317, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r115, %r317, %r317, %r806;
	// end inline asm
	shr.u32 	%r2626, %r317, 10;
	xor.b32  	%r2627, %r111, %r2626;
	xor.b32  	%r2628, %r2627, %r115;
	add.s32 	%r2629, %r2625, %r3909;
	add.s32 	%r349, %r2629, %r2628;
	// begin inline asm
	shf.r.clamp.b32 %r119, %r3915, %r3915, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r123, %r3915, %r3915, %r798;
	// end inline asm
	shr.u32 	%r2630, %r3915, 3;
	xor.b32  	%r2631, %r119, %r2630;
	xor.b32  	%r2632, %r2631, %r123;
	// begin inline asm
	shf.r.clamp.b32 %r127, %r333, %r333, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r131, %r333, %r333, %r806;
	// end inline asm
	shr.u32 	%r2633, %r333, 10;
	xor.b32  	%r2634, %r127, %r2633;
	xor.b32  	%r2635, %r2634, %r131;
	add.s32 	%r2636, %r2632, %r3914;
	add.s32 	%r365, %r2636, %r2635;
	// begin inline asm
	shf.r.clamp.b32 %r135, %r3916, %r3916, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r139, %r3916, %r3916, %r798;
	// end inline asm
	shr.u32 	%r2637, %r3916, 3;
	xor.b32  	%r2638, %r135, %r2637;
	xor.b32  	%r2639, %r2638, %r139;
	// begin inline asm
	shf.r.clamp.b32 %r143, %r349, %r349, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r147, %r349, %r349, %r806;
	// end inline asm
	shr.u32 	%r2640, %r349, 10;
	xor.b32  	%r2641, %r143, %r2640;
	xor.b32  	%r2642, %r2641, %r147;
	add.s32 	%r2643, %r3915, %r2639;
	add.s32 	%r2644, %r2643, %r2642;
	add.s32 	%r176, %r2644, 256;
	mov.u32 	%r157, -2147483648;
	// begin inline asm
	shf.r.clamp.b32 %r151, %r157, %r157, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r155, %r157, %r157, %r798;
	// end inline asm
	xor.b32  	%r2645, %r151, %r155;
	xor.b32  	%r2646, %r2645, 268435456;
	// begin inline asm
	shf.r.clamp.b32 %r159, %r365, %r365, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r163, %r365, %r365, %r806;
	// end inline asm
	shr.u32 	%r2647, %r365, 10;
	xor.b32  	%r2648, %r159, %r2647;
	xor.b32  	%r2649, %r2648, %r163;
	add.s32 	%r2650, %r285, %r3916;
	add.s32 	%r2651, %r2650, %r2646;
	add.s32 	%r397, %r2651, %r2649;
	// begin inline asm
	shf.r.clamp.b32 %r167, %r38, %r38, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r171, %r38, %r38, %r798;
	// end inline asm
	xor.b32  	%r2652, %r171, %r167;
	// begin inline asm
	shf.r.clamp.b32 %r175, %r176, %r176, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r179, %r176, %r176, %r806;
	// end inline asm
	shr.u32 	%r2653, %r176, 10;
	xor.b32  	%r2654, %r175, %r2653;
	xor.b32  	%r2655, %r2654, %r179;
	add.s32 	%r2656, %r2652, %r301;
	add.s32 	%r2657, %r2656, %r2655;
	xor.b32  	%r413, %r2657, -2147483648;
	// begin inline asm
	shf.r.clamp.b32 %r183, %r38, %r38, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r187, %r38, %r38, %r798;
	// end inline asm
	xor.b32  	%r2658, %r187, %r183;
	// begin inline asm
	shf.r.clamp.b32 %r191, %r397, %r397, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r195, %r397, %r397, %r806;
	// end inline asm
	shr.u32 	%r2659, %r397, 10;
	xor.b32  	%r2660, %r191, %r2659;
	xor.b32  	%r2661, %r2660, %r195;
	add.s32 	%r2662, %r2658, %r317;
	add.s32 	%r429, %r2662, %r2661;
	// begin inline asm
	shf.r.clamp.b32 %r199, %r38, %r38, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r203, %r38, %r38, %r798;
	// end inline asm
	xor.b32  	%r2663, %r203, %r199;
	// begin inline asm
	shf.r.clamp.b32 %r207, %r413, %r413, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r211, %r413, %r413, %r806;
	// end inline asm
	shr.u32 	%r2664, %r413, 10;
	xor.b32  	%r2665, %r207, %r2664;
	xor.b32  	%r2666, %r2665, %r211;
	add.s32 	%r2667, %r2663, %r333;
	add.s32 	%r445, %r2667, %r2666;
	// begin inline asm
	shf.r.clamp.b32 %r215, %r38, %r38, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r219, %r38, %r38, %r798;
	// end inline asm
	xor.b32  	%r2668, %r219, %r215;
	// begin inline asm
	shf.r.clamp.b32 %r223, %r429, %r429, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r227, %r429, %r429, %r806;
	// end inline asm
	shr.u32 	%r2669, %r429, 10;
	xor.b32  	%r2670, %r223, %r2669;
	xor.b32  	%r2671, %r2670, %r227;
	add.s32 	%r2672, %r2668, %r349;
	add.s32 	%r461, %r2672, %r2671;
	// begin inline asm
	shf.r.clamp.b32 %r231, %r38, %r38, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r235, %r38, %r38, %r798;
	// end inline asm
	xor.b32  	%r2673, %r235, %r231;
	// begin inline asm
	shf.r.clamp.b32 %r239, %r445, %r445, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r243, %r445, %r445, %r806;
	// end inline asm
	shr.u32 	%r2674, %r445, 10;
	xor.b32  	%r2675, %r239, %r2674;
	xor.b32  	%r2676, %r2675, %r243;
	add.s32 	%r2677, %r2673, %r365;
	add.s32 	%r477, %r2677, %r2676;
	// begin inline asm
	shf.r.clamp.b32 %r247, %r38, %r38, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r251, %r38, %r38, %r798;
	// end inline asm
	xor.b32  	%r2678, %r251, %r247;
	// begin inline asm
	shf.r.clamp.b32 %r255, %r461, %r461, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r259, %r461, %r461, %r806;
	// end inline asm
	shr.u32 	%r2679, %r461, 10;
	xor.b32  	%r2680, %r255, %r2679;
	xor.b32  	%r2681, %r2680, %r259;
	add.s32 	%r2682, %r2678, %r176;
	add.s32 	%r493, %r2682, %r2681;
	// begin inline asm
	shf.r.clamp.b32 %r263, %r269, %r269, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r267, %r269, %r269, %r798;
	// end inline asm
	xor.b32  	%r2683, %r263, %r267;
	xor.b32  	%r2684, %r2683, 32;
	// begin inline asm
	shf.r.clamp.b32 %r271, %r477, %r477, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r275, %r477, %r477, %r806;
	// end inline asm
	shr.u32 	%r2685, %r477, 10;
	xor.b32  	%r2686, %r271, %r2685;
	xor.b32  	%r2687, %r2686, %r275;
	add.s32 	%r2688, %r2684, %r397;
	add.s32 	%r509, %r2688, %r2687;
	// begin inline asm
	shf.r.clamp.b32 %r279, %r285, %r285, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r283, %r285, %r285, %r798;
	// end inline asm
	shr.u32 	%r2689, %r285, 3;
	xor.b32  	%r2690, %r279, %r2689;
	xor.b32  	%r2691, %r2690, %r283;
	// begin inline asm
	shf.r.clamp.b32 %r287, %r493, %r493, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r291, %r493, %r493, %r806;
	// end inline asm
	shr.u32 	%r2692, %r493, 10;
	xor.b32  	%r2693, %r287, %r2692;
	xor.b32  	%r2694, %r2693, %r291;
	add.s32 	%r2695, %r2657, %r2691;
	add.s32 	%r2696, %r2695, %r2694;
	add.s32 	%r320, %r2696, -2147483392;
	// begin inline asm
	shf.r.clamp.b32 %r295, %r301, %r301, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r299, %r301, %r301, %r798;
	// end inline asm
	shr.u32 	%r2697, %r301, 3;
	xor.b32  	%r2698, %r295, %r2697;
	xor.b32  	%r2699, %r2698, %r299;
	// begin inline asm
	shf.r.clamp.b32 %r303, %r509, %r509, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r307, %r509, %r509, %r806;
	// end inline asm
	shr.u32 	%r2700, %r509, 10;
	xor.b32  	%r2701, %r303, %r2700;
	xor.b32  	%r2702, %r2701, %r307;
	add.s32 	%r2703, %r429, %r285;
	add.s32 	%r2704, %r2703, %r2699;
	add.s32 	%r541, %r2704, %r2702;
	// begin inline asm
	shf.r.clamp.b32 %r311, %r317, %r317, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r315, %r317, %r317, %r798;
	// end inline asm
	shr.u32 	%r2705, %r317, 3;
	xor.b32  	%r2706, %r311, %r2705;
	xor.b32  	%r2707, %r2706, %r315;
	// begin inline asm
	shf.r.clamp.b32 %r319, %r320, %r320, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r323, %r320, %r320, %r806;
	// end inline asm
	shr.u32 	%r2708, %r320, 10;
	xor.b32  	%r2709, %r319, %r2708;
	xor.b32  	%r2710, %r2709, %r323;
	add.s32 	%r2711, %r445, %r301;
	add.s32 	%r2712, %r2711, %r2707;
	add.s32 	%r557, %r2712, %r2710;
	// begin inline asm
	shf.r.clamp.b32 %r327, %r333, %r333, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r331, %r333, %r333, %r798;
	// end inline asm
	shr.u32 	%r2713, %r333, 3;
	xor.b32  	%r2714, %r327, %r2713;
	xor.b32  	%r2715, %r2714, %r331;
	// begin inline asm
	shf.r.clamp.b32 %r335, %r541, %r541, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r339, %r541, %r541, %r806;
	// end inline asm
	shr.u32 	%r2716, %r541, 10;
	xor.b32  	%r2717, %r335, %r2716;
	xor.b32  	%r2718, %r2717, %r339;
	add.s32 	%r2719, %r461, %r317;
	add.s32 	%r2720, %r2719, %r2715;
	add.s32 	%r573, %r2720, %r2718;
	// begin inline asm
	shf.r.clamp.b32 %r343, %r349, %r349, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r347, %r349, %r349, %r798;
	// end inline asm
	shr.u32 	%r2721, %r349, 3;
	xor.b32  	%r2722, %r343, %r2721;
	xor.b32  	%r2723, %r2722, %r347;
	// begin inline asm
	shf.r.clamp.b32 %r351, %r557, %r557, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r355, %r557, %r557, %r806;
	// end inline asm
	shr.u32 	%r2724, %r557, 10;
	xor.b32  	%r2725, %r351, %r2724;
	xor.b32  	%r2726, %r2725, %r355;
	add.s32 	%r2727, %r477, %r333;
	add.s32 	%r2728, %r2727, %r2723;
	add.s32 	%r589, %r2728, %r2726;
	// begin inline asm
	shf.r.clamp.b32 %r359, %r365, %r365, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r363, %r365, %r365, %r798;
	// end inline asm
	shr.u32 	%r2729, %r365, 3;
	xor.b32  	%r2730, %r359, %r2729;
	xor.b32  	%r2731, %r2730, %r363;
	// begin inline asm
	shf.r.clamp.b32 %r367, %r573, %r573, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r371, %r573, %r573, %r806;
	// end inline asm
	shr.u32 	%r2732, %r573, 10;
	xor.b32  	%r2733, %r367, %r2732;
	xor.b32  	%r2734, %r2733, %r371;
	add.s32 	%r2735, %r493, %r349;
	add.s32 	%r2736, %r2735, %r2731;
	add.s32 	%r605, %r2736, %r2734;
	// begin inline asm
	shf.r.clamp.b32 %r375, %r176, %r176, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r379, %r176, %r176, %r798;
	// end inline asm
	shr.u32 	%r2737, %r176, 3;
	xor.b32  	%r2738, %r375, %r2737;
	xor.b32  	%r2739, %r2738, %r379;
	// begin inline asm
	shf.r.clamp.b32 %r383, %r589, %r589, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r387, %r589, %r589, %r806;
	// end inline asm
	shr.u32 	%r2740, %r589, 10;
	xor.b32  	%r2741, %r383, %r2740;
	xor.b32  	%r2742, %r2741, %r387;
	add.s32 	%r2743, %r509, %r365;
	add.s32 	%r2744, %r2743, %r2739;
	add.s32 	%r621, %r2744, %r2742;
	// begin inline asm
	shf.r.clamp.b32 %r391, %r397, %r397, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r395, %r397, %r397, %r798;
	// end inline asm
	shr.u32 	%r2745, %r397, 3;
	xor.b32  	%r2746, %r391, %r2745;
	xor.b32  	%r2747, %r2746, %r395;
	// begin inline asm
	shf.r.clamp.b32 %r399, %r605, %r605, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r403, %r605, %r605, %r806;
	// end inline asm
	shr.u32 	%r2748, %r605, 10;
	xor.b32  	%r2749, %r399, %r2748;
	xor.b32  	%r2750, %r2749, %r403;
	add.s32 	%r2751, %r320, %r176;
	add.s32 	%r2752, %r2751, %r2747;
	add.s32 	%r637, %r2752, %r2750;
	// begin inline asm
	shf.r.clamp.b32 %r407, %r413, %r413, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r411, %r413, %r413, %r798;
	// end inline asm
	shr.u32 	%r2753, %r413, 3;
	xor.b32  	%r2754, %r407, %r2753;
	xor.b32  	%r2755, %r2754, %r411;
	// begin inline asm
	shf.r.clamp.b32 %r415, %r621, %r621, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r419, %r621, %r621, %r806;
	// end inline asm
	shr.u32 	%r2756, %r621, 10;
	xor.b32  	%r2757, %r415, %r2756;
	xor.b32  	%r2758, %r2757, %r419;
	add.s32 	%r2759, %r541, %r397;
	add.s32 	%r2760, %r2759, %r2755;
	add.s32 	%r653, %r2760, %r2758;
	// begin inline asm
	shf.r.clamp.b32 %r423, %r429, %r429, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r427, %r429, %r429, %r798;
	// end inline asm
	shr.u32 	%r2761, %r429, 3;
	xor.b32  	%r2762, %r423, %r2761;
	xor.b32  	%r2763, %r2762, %r427;
	// begin inline asm
	shf.r.clamp.b32 %r431, %r637, %r637, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r435, %r637, %r637, %r806;
	// end inline asm
	shr.u32 	%r2764, %r637, 10;
	xor.b32  	%r2765, %r431, %r2764;
	xor.b32  	%r2766, %r2765, %r435;
	add.s32 	%r2767, %r557, %r413;
	add.s32 	%r2768, %r2767, %r2763;
	add.s32 	%r669, %r2768, %r2766;
	// begin inline asm
	shf.r.clamp.b32 %r439, %r445, %r445, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r443, %r445, %r445, %r798;
	// end inline asm
	shr.u32 	%r2769, %r445, 3;
	xor.b32  	%r2770, %r439, %r2769;
	xor.b32  	%r2771, %r2770, %r443;
	// begin inline asm
	shf.r.clamp.b32 %r447, %r653, %r653, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r451, %r653, %r653, %r806;
	// end inline asm
	shr.u32 	%r2772, %r653, 10;
	xor.b32  	%r2773, %r447, %r2772;
	xor.b32  	%r2774, %r2773, %r451;
	add.s32 	%r2775, %r573, %r429;
	add.s32 	%r2776, %r2775, %r2771;
	add.s32 	%r685, %r2776, %r2774;
	// begin inline asm
	shf.r.clamp.b32 %r455, %r461, %r461, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r459, %r461, %r461, %r798;
	// end inline asm
	shr.u32 	%r2777, %r461, 3;
	xor.b32  	%r2778, %r455, %r2777;
	xor.b32  	%r2779, %r2778, %r459;
	// begin inline asm
	shf.r.clamp.b32 %r463, %r669, %r669, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r467, %r669, %r669, %r806;
	// end inline asm
	shr.u32 	%r2780, %r669, 10;
	xor.b32  	%r2781, %r463, %r2780;
	xor.b32  	%r2782, %r2781, %r467;
	add.s32 	%r2783, %r589, %r445;
	add.s32 	%r2784, %r2783, %r2779;
	add.s32 	%r701, %r2784, %r2782;
	// begin inline asm
	shf.r.clamp.b32 %r471, %r477, %r477, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r475, %r477, %r477, %r798;
	// end inline asm
	shr.u32 	%r2785, %r477, 3;
	xor.b32  	%r2786, %r471, %r2785;
	xor.b32  	%r2787, %r2786, %r475;
	// begin inline asm
	shf.r.clamp.b32 %r479, %r685, %r685, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r483, %r685, %r685, %r806;
	// end inline asm
	shr.u32 	%r2788, %r685, 10;
	xor.b32  	%r2789, %r479, %r2788;
	xor.b32  	%r2790, %r2789, %r483;
	add.s32 	%r2791, %r605, %r461;
	add.s32 	%r2792, %r2791, %r2787;
	add.s32 	%r717, %r2792, %r2790;
	// begin inline asm
	shf.r.clamp.b32 %r487, %r493, %r493, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r491, %r493, %r493, %r798;
	// end inline asm
	shr.u32 	%r2793, %r493, 3;
	xor.b32  	%r2794, %r487, %r2793;
	xor.b32  	%r2795, %r2794, %r491;
	// begin inline asm
	shf.r.clamp.b32 %r495, %r701, %r701, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r499, %r701, %r701, %r806;
	// end inline asm
	shr.u32 	%r2796, %r701, 10;
	xor.b32  	%r2797, %r495, %r2796;
	xor.b32  	%r2798, %r2797, %r499;
	add.s32 	%r2799, %r621, %r477;
	add.s32 	%r2800, %r2799, %r2795;
	add.s32 	%r733, %r2800, %r2798;
	// begin inline asm
	shf.r.clamp.b32 %r503, %r509, %r509, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r507, %r509, %r509, %r798;
	// end inline asm
	shr.u32 	%r2801, %r509, 3;
	xor.b32  	%r2802, %r503, %r2801;
	xor.b32  	%r2803, %r2802, %r507;
	// begin inline asm
	shf.r.clamp.b32 %r511, %r717, %r717, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r515, %r717, %r717, %r806;
	// end inline asm
	shr.u32 	%r2804, %r717, 10;
	xor.b32  	%r2805, %r511, %r2804;
	xor.b32  	%r2806, %r2805, %r515;
	add.s32 	%r2807, %r637, %r493;
	add.s32 	%r2808, %r2807, %r2803;
	add.s32 	%r749, %r2808, %r2806;
	// begin inline asm
	shf.r.clamp.b32 %r519, %r320, %r320, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r523, %r320, %r320, %r798;
	// end inline asm
	shr.u32 	%r2809, %r320, 3;
	xor.b32  	%r2810, %r519, %r2809;
	xor.b32  	%r2811, %r2810, %r523;
	// begin inline asm
	shf.r.clamp.b32 %r527, %r733, %r733, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r531, %r733, %r733, %r806;
	// end inline asm
	shr.u32 	%r2812, %r733, 10;
	xor.b32  	%r2813, %r527, %r2812;
	xor.b32  	%r2814, %r2813, %r531;
	add.s32 	%r2815, %r653, %r509;
	add.s32 	%r2816, %r2815, %r2811;
	add.s32 	%r765, %r2816, %r2814;
	// begin inline asm
	shf.r.clamp.b32 %r535, %r541, %r541, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r539, %r541, %r541, %r798;
	// end inline asm
	shr.u32 	%r2817, %r541, 3;
	xor.b32  	%r2818, %r535, %r2817;
	xor.b32  	%r2819, %r2818, %r539;
	// begin inline asm
	shf.r.clamp.b32 %r543, %r749, %r749, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r547, %r749, %r749, %r806;
	// end inline asm
	shr.u32 	%r2820, %r749, 10;
	xor.b32  	%r2821, %r543, %r2820;
	xor.b32  	%r2822, %r2821, %r547;
	add.s32 	%r2823, %r669, %r320;
	add.s32 	%r2824, %r2823, %r2819;
	add.s32 	%r781, %r2824, %r2822;
	// begin inline asm
	shf.r.clamp.b32 %r551, %r557, %r557, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r555, %r557, %r557, %r798;
	// end inline asm
	shr.u32 	%r2825, %r557, 3;
	xor.b32  	%r2826, %r551, %r2825;
	xor.b32  	%r2827, %r2826, %r555;
	// begin inline asm
	shf.r.clamp.b32 %r559, %r765, %r765, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r563, %r765, %r765, %r806;
	// end inline asm
	shr.u32 	%r2828, %r765, 10;
	xor.b32  	%r2829, %r559, %r2828;
	xor.b32  	%r2830, %r2829, %r563;
	add.s32 	%r2831, %r685, %r541;
	add.s32 	%r2832, %r2831, %r2827;
	add.s32 	%r797, %r2832, %r2830;
	// begin inline asm
	shf.r.clamp.b32 %r567, %r573, %r573, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r571, %r573, %r573, %r798;
	// end inline asm
	shr.u32 	%r2833, %r573, 3;
	xor.b32  	%r2834, %r567, %r2833;
	xor.b32  	%r2835, %r2834, %r571;
	// begin inline asm
	shf.r.clamp.b32 %r575, %r781, %r781, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r579, %r781, %r781, %r806;
	// end inline asm
	shr.u32 	%r2836, %r781, 10;
	xor.b32  	%r2837, %r575, %r2836;
	xor.b32  	%r2838, %r2837, %r579;
	add.s32 	%r2839, %r701, %r557;
	add.s32 	%r2840, %r2839, %r2835;
	add.s32 	%r613, %r2840, %r2838;
	// begin inline asm
	shf.r.clamp.b32 %r583, %r589, %r589, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r587, %r589, %r589, %r798;
	// end inline asm
	shr.u32 	%r2841, %r589, 3;
	xor.b32  	%r2842, %r583, %r2841;
	xor.b32  	%r2843, %r2842, %r587;
	// begin inline asm
	shf.r.clamp.b32 %r591, %r797, %r797, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r595, %r797, %r797, %r806;
	// end inline asm
	shr.u32 	%r2844, %r797, 10;
	xor.b32  	%r2845, %r591, %r2844;
	xor.b32  	%r2846, %r2845, %r595;
	add.s32 	%r2847, %r717, %r573;
	add.s32 	%r2848, %r2847, %r2843;
	add.s32 	%r629, %r2848, %r2846;
	// begin inline asm
	shf.r.clamp.b32 %r599, %r605, %r605, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r603, %r605, %r605, %r798;
	// end inline asm
	shr.u32 	%r2849, %r605, 3;
	xor.b32  	%r2850, %r599, %r2849;
	xor.b32  	%r2851, %r2850, %r603;
	// begin inline asm
	shf.r.clamp.b32 %r607, %r613, %r613, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r611, %r613, %r613, %r806;
	// end inline asm
	shr.u32 	%r2852, %r613, 10;
	xor.b32  	%r2853, %r607, %r2852;
	xor.b32  	%r2854, %r2853, %r611;
	add.s32 	%r2855, %r733, %r589;
	add.s32 	%r2856, %r2855, %r2851;
	add.s32 	%r645, %r2856, %r2854;
	// begin inline asm
	shf.r.clamp.b32 %r615, %r621, %r621, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r619, %r621, %r621, %r798;
	// end inline asm
	shr.u32 	%r2857, %r621, 3;
	xor.b32  	%r2858, %r615, %r2857;
	xor.b32  	%r2859, %r2858, %r619;
	// begin inline asm
	shf.r.clamp.b32 %r623, %r629, %r629, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r627, %r629, %r629, %r806;
	// end inline asm
	shr.u32 	%r2860, %r629, 10;
	xor.b32  	%r2861, %r623, %r2860;
	xor.b32  	%r2862, %r2861, %r627;
	add.s32 	%r2863, %r749, %r605;
	add.s32 	%r2864, %r2863, %r2859;
	add.s32 	%r661, %r2864, %r2862;
	// begin inline asm
	shf.r.clamp.b32 %r631, %r637, %r637, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r635, %r637, %r637, %r798;
	// end inline asm
	shr.u32 	%r2865, %r637, 3;
	xor.b32  	%r2866, %r631, %r2865;
	xor.b32  	%r2867, %r2866, %r635;
	// begin inline asm
	shf.r.clamp.b32 %r639, %r645, %r645, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r643, %r645, %r645, %r806;
	// end inline asm
	shr.u32 	%r2868, %r645, 10;
	xor.b32  	%r2869, %r639, %r2868;
	xor.b32  	%r2870, %r2869, %r643;
	add.s32 	%r2871, %r765, %r621;
	add.s32 	%r2872, %r2871, %r2867;
	add.s32 	%r677, %r2872, %r2870;
	// begin inline asm
	shf.r.clamp.b32 %r647, %r653, %r653, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r651, %r653, %r653, %r798;
	// end inline asm
	shr.u32 	%r2873, %r653, 3;
	xor.b32  	%r2874, %r647, %r2873;
	xor.b32  	%r2875, %r2874, %r651;
	// begin inline asm
	shf.r.clamp.b32 %r655, %r661, %r661, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r659, %r661, %r661, %r806;
	// end inline asm
	shr.u32 	%r2876, %r661, 10;
	xor.b32  	%r2877, %r655, %r2876;
	xor.b32  	%r2878, %r2877, %r659;
	add.s32 	%r2879, %r781, %r637;
	add.s32 	%r2880, %r2879, %r2875;
	add.s32 	%r693, %r2880, %r2878;
	// begin inline asm
	shf.r.clamp.b32 %r663, %r669, %r669, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r667, %r669, %r669, %r798;
	// end inline asm
	shr.u32 	%r2881, %r669, 3;
	xor.b32  	%r2882, %r663, %r2881;
	xor.b32  	%r2883, %r2882, %r667;
	// begin inline asm
	shf.r.clamp.b32 %r671, %r677, %r677, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r675, %r677, %r677, %r806;
	// end inline asm
	shr.u32 	%r2884, %r677, 10;
	xor.b32  	%r2885, %r671, %r2884;
	xor.b32  	%r2886, %r2885, %r675;
	add.s32 	%r2887, %r797, %r653;
	add.s32 	%r2888, %r2887, %r2883;
	add.s32 	%r709, %r2888, %r2886;
	// begin inline asm
	shf.r.clamp.b32 %r679, %r685, %r685, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r683, %r685, %r685, %r798;
	// end inline asm
	shr.u32 	%r2889, %r685, 3;
	xor.b32  	%r2890, %r679, %r2889;
	xor.b32  	%r2891, %r2890, %r683;
	// begin inline asm
	shf.r.clamp.b32 %r687, %r693, %r693, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r691, %r693, %r693, %r806;
	// end inline asm
	shr.u32 	%r2892, %r693, 10;
	xor.b32  	%r2893, %r687, %r2892;
	xor.b32  	%r2894, %r2893, %r691;
	add.s32 	%r2895, %r613, %r669;
	add.s32 	%r2896, %r2895, %r2891;
	add.s32 	%r725, %r2896, %r2894;
	// begin inline asm
	shf.r.clamp.b32 %r695, %r701, %r701, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r699, %r701, %r701, %r798;
	// end inline asm
	shr.u32 	%r2897, %r701, 3;
	xor.b32  	%r2898, %r695, %r2897;
	xor.b32  	%r2899, %r2898, %r699;
	// begin inline asm
	shf.r.clamp.b32 %r703, %r709, %r709, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r707, %r709, %r709, %r806;
	// end inline asm
	shr.u32 	%r2900, %r709, 10;
	xor.b32  	%r2901, %r703, %r2900;
	xor.b32  	%r2902, %r2901, %r707;
	add.s32 	%r2903, %r629, %r685;
	add.s32 	%r2904, %r2903, %r2899;
	add.s32 	%r741, %r2904, %r2902;
	// begin inline asm
	shf.r.clamp.b32 %r711, %r717, %r717, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r715, %r717, %r717, %r798;
	// end inline asm
	shr.u32 	%r2905, %r717, 3;
	xor.b32  	%r2906, %r711, %r2905;
	xor.b32  	%r2907, %r2906, %r715;
	// begin inline asm
	shf.r.clamp.b32 %r719, %r725, %r725, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r723, %r725, %r725, %r806;
	// end inline asm
	shr.u32 	%r2908, %r725, 10;
	xor.b32  	%r2909, %r719, %r2908;
	xor.b32  	%r2910, %r2909, %r723;
	add.s32 	%r2911, %r645, %r701;
	add.s32 	%r2912, %r2911, %r2907;
	add.s32 	%r757, %r2912, %r2910;
	// begin inline asm
	shf.r.clamp.b32 %r727, %r733, %r733, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r731, %r733, %r733, %r798;
	// end inline asm
	shr.u32 	%r2913, %r733, 3;
	xor.b32  	%r2914, %r727, %r2913;
	xor.b32  	%r2915, %r2914, %r731;
	// begin inline asm
	shf.r.clamp.b32 %r735, %r741, %r741, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r739, %r741, %r741, %r806;
	// end inline asm
	shr.u32 	%r2916, %r741, 10;
	xor.b32  	%r2917, %r735, %r2916;
	xor.b32  	%r2918, %r2917, %r739;
	add.s32 	%r2919, %r661, %r717;
	add.s32 	%r2920, %r2919, %r2915;
	add.s32 	%r773, %r2920, %r2918;
	// begin inline asm
	shf.r.clamp.b32 %r743, %r749, %r749, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r747, %r749, %r749, %r798;
	// end inline asm
	shr.u32 	%r2921, %r749, 3;
	xor.b32  	%r2922, %r743, %r2921;
	xor.b32  	%r2923, %r2922, %r747;
	// begin inline asm
	shf.r.clamp.b32 %r751, %r757, %r757, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r755, %r757, %r757, %r806;
	// end inline asm
	shr.u32 	%r2924, %r757, 10;
	xor.b32  	%r2925, %r751, %r2924;
	xor.b32  	%r2926, %r2925, %r755;
	add.s32 	%r2927, %r677, %r733;
	add.s32 	%r2928, %r2927, %r2923;
	add.s32 	%r789, %r2928, %r2926;
	// begin inline asm
	shf.r.clamp.b32 %r759, %r765, %r765, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r763, %r765, %r765, %r798;
	// end inline asm
	shr.u32 	%r2929, %r765, 3;
	xor.b32  	%r2930, %r759, %r2929;
	xor.b32  	%r2931, %r2930, %r763;
	// begin inline asm
	shf.r.clamp.b32 %r767, %r773, %r773, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r771, %r773, %r773, %r806;
	// end inline asm
	shr.u32 	%r2932, %r773, 10;
	xor.b32  	%r2933, %r767, %r2932;
	xor.b32  	%r2934, %r2933, %r771;
	add.s32 	%r2935, %r693, %r749;
	add.s32 	%r2936, %r2935, %r2931;
	add.s32 	%r805, %r2936, %r2934;
	// begin inline asm
	shf.r.clamp.b32 %r775, %r781, %r781, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r779, %r781, %r781, %r798;
	// end inline asm
	shr.u32 	%r2937, %r781, 3;
	xor.b32  	%r2938, %r775, %r2937;
	xor.b32  	%r2939, %r2938, %r779;
	// begin inline asm
	shf.r.clamp.b32 %r783, %r789, %r789, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r787, %r789, %r789, %r806;
	// end inline asm
	shr.u32 	%r2940, %r789, 10;
	xor.b32  	%r2941, %r783, %r2940;
	xor.b32  	%r2942, %r2941, %r787;
	// begin inline asm
	shf.r.clamp.b32 %r791, %r797, %r797, %r794;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r795, %r797, %r797, %r798;
	// end inline asm
	shr.u32 	%r2943, %r797, 3;
	xor.b32  	%r2944, %r791, %r2943;
	xor.b32  	%r2945, %r2944, %r795;
	// begin inline asm
	shf.r.clamp.b32 %r799, %r805, %r805, %r802;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r803, %r805, %r805, %r806;
	// end inline asm
	shr.u32 	%r2946, %r805, 10;
	xor.b32  	%r2947, %r799, %r2946;
	xor.b32  	%r2948, %r2947, %r803;
	mov.u32 	%r877, 1359893119;
	mov.u32 	%r2574, 6;
	// begin inline asm
	shf.r.clamp.b32 %r807, %r877, %r877, %r2574;
	// end inline asm
	mov.u32 	%r2578, 11;
	// begin inline asm
	shf.r.clamp.b32 %r811, %r877, %r877, %r2578;
	// end inline asm
	xor.b32  	%r2949, %r811, %r807;
	mov.u32 	%r2582, 25;
	// begin inline asm
	shf.r.clamp.b32 %r815, %r877, %r877, %r2582;
	// end inline asm
	xor.b32  	%r2950, %r2949, %r815;
	mov.u32 	%r821, 528734635;
	mov.u32 	%r820, %r877;
	// begin inline asm
	not.b32  %r820, %r820;     
	and.b32  %r819, %r820, %r821; 
	
	// end inline asm
	xor.b32  	%r2951, %r819, 285491212;
	add.s32 	%r2952, %r3913, %r2950;
	add.s32 	%r2953, %r2952, %r2951;
	mov.u32 	%r833, 1779033703;
	mov.u32 	%r2590, 2;
	// begin inline asm
	shf.r.clamp.b32 %r823, %r833, %r833, %r2590;
	// end inline asm
	mov.u32 	%r2594, 13;
	// begin inline asm
	shf.r.clamp.b32 %r827, %r833, %r833, %r2594;
	// end inline asm
	xor.b32  	%r2954, %r827, %r823;
	mov.u32 	%r2598, 22;
	// begin inline asm
	shf.r.clamp.b32 %r831, %r833, %r833, %r2598;
	// end inline asm
	xor.b32  	%r2955, %r2954, %r831;
	add.s32 	%r2956, %r2953, %r2955;
	add.s32 	%r836, %r2953, 1136325099;
	add.s32 	%r861, %r2956, -656743656;
	// begin inline asm
	shf.r.clamp.b32 %r835, %r836, %r836, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r839, %r836, %r836, %r2578;
	// end inline asm
	xor.b32  	%r2957, %r839, %r835;
	// begin inline asm
	shf.r.clamp.b32 %r843, %r836, %r836, %r2582;
	// end inline asm
	xor.b32  	%r2958, %r2957, %r843;
	and.b32  	%r2959, %r836, 1359893119;
	mov.u32 	%r849, -1694144372;
	mov.u32 	%r848, %r836;
	// begin inline asm
	not.b32  %r848, %r848;     
	and.b32  %r847, %r848, %r849; 
	
	// end inline asm
	xor.b32  	%r2960, %r847, %r2959;
	add.s32 	%r2961, %r3912, %r2958;
	add.s32 	%r2962, %r2961, %r2960;
	and.b32  	%r2963, %r861, -781301534;
	or.b32  	%r2964, %r2963, 704751109;
	add.s32 	%r2965, %r2962, %r2964;
	add.s32 	%r864, %r2962, -852880978;
	// begin inline asm
	shf.r.clamp.b32 %r851, %r861, %r861, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r855, %r861, %r861, %r2594;
	// end inline asm
	xor.b32  	%r2966, %r855, %r851;
	// begin inline asm
	shf.r.clamp.b32 %r859, %r861, %r861, %r2598;
	// end inline asm
	xor.b32  	%r2967, %r2966, %r859;
	add.s32 	%r2968, %r2965, %r2967;
	add.s32 	%r880, %r2968, -1866785220;
	// begin inline asm
	shf.r.clamp.b32 %r863, %r864, %r864, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r867, %r864, %r864, %r2578;
	// end inline asm
	xor.b32  	%r2969, %r867, %r863;
	// begin inline asm
	shf.r.clamp.b32 %r871, %r864, %r864, %r2582;
	// end inline asm
	xor.b32  	%r2970, %r2969, %r871;
	and.b32  	%r2971, %r864, %r836;
	mov.u32 	%r876, %r864;
	// begin inline asm
	not.b32  %r876, %r876;     
	and.b32  %r875, %r876, %r877; 
	
	// end inline asm
	xor.b32  	%r2972, %r875, %r2971;
	add.s32 	%r2973, %r3911, %r2970;
	add.s32 	%r2974, %r2973, %r2972;
	xor.b32  	%r2975, %r861, 1779033703;
	and.b32  	%r2976, %r880, %r2975;
	and.b32  	%r2977, %r861, 1779033703;
	xor.b32  	%r2978, %r2976, %r2977;
	add.s32 	%r2979, %r2974, %r2978;
	add.s32 	%r892, %r2974, 204346080;
	// begin inline asm
	shf.r.clamp.b32 %r879, %r880, %r880, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r883, %r880, %r880, %r2594;
	// end inline asm
	xor.b32  	%r2980, %r883, %r879;
	// begin inline asm
	shf.r.clamp.b32 %r887, %r880, %r880, %r2598;
	// end inline asm
	xor.b32  	%r2981, %r2980, %r887;
	add.s32 	%r2982, %r2979, %r2981;
	add.s32 	%r908, %r2982, 1355179099;
	// begin inline asm
	shf.r.clamp.b32 %r891, %r892, %r892, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r895, %r892, %r892, %r2578;
	// end inline asm
	xor.b32  	%r2983, %r895, %r891;
	// begin inline asm
	shf.r.clamp.b32 %r899, %r892, %r892, %r2582;
	// end inline asm
	xor.b32  	%r2984, %r2983, %r899;
	and.b32  	%r2985, %r892, %r864;
	mov.u32 	%r904, %r892;
	// begin inline asm
	not.b32  %r904, %r904;     
	and.b32  %r903, %r904, %r836; 
	
	// end inline asm
	xor.b32  	%r2986, %r903, %r2985;
	add.s32 	%r2987, %r3910, %r2984;
	add.s32 	%r2988, %r2987, %r2986;
	xor.b32  	%r2989, %r880, %r861;
	and.b32  	%r2990, %r908, %r2989;
	and.b32  	%r2991, %r880, %r861;
	xor.b32  	%r2992, %r2990, %r2991;
	add.s32 	%r2993, %r2988, %r2992;
	add.s32 	%r920, %r2988, -1529998197;
	// begin inline asm
	shf.r.clamp.b32 %r907, %r908, %r908, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r911, %r908, %r908, %r2594;
	// end inline asm
	xor.b32  	%r2994, %r911, %r907;
	// begin inline asm
	shf.r.clamp.b32 %r915, %r908, %r908, %r2598;
	// end inline asm
	xor.b32  	%r2995, %r2994, %r915;
	add.s32 	%r2996, %r2993, %r2995;
	add.s32 	%r936, %r2996, 985935396;
	// begin inline asm
	shf.r.clamp.b32 %r919, %r920, %r920, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r923, %r920, %r920, %r2578;
	// end inline asm
	xor.b32  	%r2997, %r923, %r919;
	// begin inline asm
	shf.r.clamp.b32 %r927, %r920, %r920, %r2582;
	// end inline asm
	xor.b32  	%r2998, %r2997, %r927;
	and.b32  	%r2999, %r920, %r892;
	mov.u32 	%r932, %r920;
	// begin inline asm
	not.b32  %r932, %r932;     
	and.b32  %r931, %r932, %r864; 
	
	// end inline asm
	xor.b32  	%r3000, %r931, %r2999;
	add.s32 	%r3001, %r3909, %r836;
	add.s32 	%r3002, %r3001, %r2998;
	add.s32 	%r3003, %r3002, %r3000;
	add.s32 	%r3004, %r3003, 961987163;
	add.s32 	%r1017, %r3004, %r861;
	// begin inline asm
	shf.r.clamp.b32 %r935, %r936, %r936, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r939, %r936, %r936, %r2594;
	// end inline asm
	xor.b32  	%r3005, %r939, %r935;
	// begin inline asm
	shf.r.clamp.b32 %r943, %r936, %r936, %r2598;
	// end inline asm
	xor.b32  	%r3006, %r3005, %r943;
	xor.b32  	%r3007, %r908, %r880;
	and.b32  	%r3008, %r936, %r3007;
	and.b32  	%r3009, %r908, %r880;
	xor.b32  	%r3010, %r3008, %r3009;
	add.s32 	%r3011, %r3004, %r3010;
	add.s32 	%r973, %r3011, %r3006;
	// begin inline asm
	shf.r.clamp.b32 %r947, %r1017, %r1017, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r951, %r1017, %r1017, %r2578;
	// end inline asm
	xor.b32  	%r3012, %r951, %r947;
	// begin inline asm
	shf.r.clamp.b32 %r955, %r1017, %r1017, %r2582;
	// end inline asm
	xor.b32  	%r3013, %r3012, %r955;
	and.b32  	%r3014, %r1017, %r920;
	mov.u32 	%r960, %r1017;
	// begin inline asm
	not.b32  %r960, %r960;     
	and.b32  %r959, %r960, %r892; 
	
	// end inline asm
	xor.b32  	%r3015, %r959, %r3014;
	add.s32 	%r3016, %r3914, %r864;
	add.s32 	%r3017, %r3016, %r3013;
	add.s32 	%r3018, %r3017, %r3015;
	add.s32 	%r3019, %r3018, 1508970993;
	add.s32 	%r1045, %r3019, %r880;
	// begin inline asm
	shf.r.clamp.b32 %r963, %r973, %r973, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r967, %r973, %r973, %r2594;
	// end inline asm
	xor.b32  	%r3020, %r967, %r963;
	// begin inline asm
	shf.r.clamp.b32 %r971, %r973, %r973, %r2598;
	// end inline asm
	xor.b32  	%r3021, %r3020, %r971;
	xor.b32  	%r3022, %r936, %r908;
	and.b32  	%r3023, %r973, %r3022;
	and.b32  	%r3024, %r936, %r908;
	xor.b32  	%r3025, %r3023, %r3024;
	add.s32 	%r3026, %r3019, %r3025;
	add.s32 	%r1001, %r3026, %r3021;
	// begin inline asm
	shf.r.clamp.b32 %r975, %r1045, %r1045, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r979, %r1045, %r1045, %r2578;
	// end inline asm
	xor.b32  	%r3027, %r979, %r975;
	// begin inline asm
	shf.r.clamp.b32 %r983, %r1045, %r1045, %r2582;
	// end inline asm
	xor.b32  	%r3028, %r3027, %r983;
	and.b32  	%r3029, %r1045, %r1017;
	mov.u32 	%r988, %r1045;
	// begin inline asm
	not.b32  %r988, %r988;     
	and.b32  %r987, %r988, %r920; 
	
	// end inline asm
	xor.b32  	%r3030, %r987, %r3029;
	add.s32 	%r3031, %r3915, %r892;
	add.s32 	%r3032, %r3031, %r3028;
	add.s32 	%r3033, %r3032, %r3030;
	add.s32 	%r3034, %r3033, -1841331548;
	add.s32 	%r1073, %r3034, %r908;
	// begin inline asm
	shf.r.clamp.b32 %r991, %r1001, %r1001, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r995, %r1001, %r1001, %r2594;
	// end inline asm
	xor.b32  	%r3035, %r995, %r991;
	// begin inline asm
	shf.r.clamp.b32 %r999, %r1001, %r1001, %r2598;
	// end inline asm
	xor.b32  	%r3036, %r3035, %r999;
	xor.b32  	%r3037, %r973, %r936;
	and.b32  	%r3038, %r1001, %r3037;
	and.b32  	%r3039, %r973, %r936;
	xor.b32  	%r3040, %r3038, %r3039;
	add.s32 	%r3041, %r3034, %r3040;
	add.s32 	%r1029, %r3041, %r3036;
	// begin inline asm
	shf.r.clamp.b32 %r1003, %r1073, %r1073, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1007, %r1073, %r1073, %r2578;
	// end inline asm
	xor.b32  	%r3042, %r1007, %r1003;
	// begin inline asm
	shf.r.clamp.b32 %r1011, %r1073, %r1073, %r2582;
	// end inline asm
	xor.b32  	%r3043, %r3042, %r1011;
	and.b32  	%r3044, %r1073, %r1045;
	mov.u32 	%r1016, %r1073;
	// begin inline asm
	not.b32  %r1016, %r1016;     
	and.b32  %r1015, %r1016, %r1017; 
	
	// end inline asm
	xor.b32  	%r3045, %r1015, %r3044;
	add.s32 	%r3046, %r3916, %r920;
	add.s32 	%r3047, %r3046, %r3043;
	add.s32 	%r3048, %r3047, %r3045;
	add.s32 	%r3049, %r3048, -1424204075;
	add.s32 	%r1101, %r3049, %r936;
	// begin inline asm
	shf.r.clamp.b32 %r1019, %r1029, %r1029, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1023, %r1029, %r1029, %r2594;
	// end inline asm
	xor.b32  	%r3050, %r1023, %r1019;
	// begin inline asm
	shf.r.clamp.b32 %r1027, %r1029, %r1029, %r2598;
	// end inline asm
	xor.b32  	%r3051, %r3050, %r1027;
	xor.b32  	%r3052, %r1001, %r973;
	and.b32  	%r3053, %r1029, %r3052;
	and.b32  	%r3054, %r1001, %r973;
	xor.b32  	%r3055, %r3053, %r3054;
	add.s32 	%r3056, %r3049, %r3055;
	add.s32 	%r1057, %r3056, %r3051;
	// begin inline asm
	shf.r.clamp.b32 %r1031, %r1101, %r1101, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1035, %r1101, %r1101, %r2578;
	// end inline asm
	xor.b32  	%r3057, %r1035, %r1031;
	// begin inline asm
	shf.r.clamp.b32 %r1039, %r1101, %r1101, %r2582;
	// end inline asm
	xor.b32  	%r3058, %r3057, %r1039;
	add.s32 	%r3059, %r1017, %r3058;
	and.b32  	%r3060, %r1101, %r1073;
	mov.u32 	%r1044, %r1101;
	// begin inline asm
	not.b32  %r1044, %r1044;     
	and.b32  %r1043, %r1044, %r1045; 
	
	// end inline asm
	xor.b32  	%r3061, %r1043, %r3060;
	add.s32 	%r3062, %r3059, %r3061;
	add.s32 	%r3063, %r3062, 1476897432;
	add.s32 	%r1129, %r3063, %r973;
	// begin inline asm
	shf.r.clamp.b32 %r1047, %r1057, %r1057, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1051, %r1057, %r1057, %r2594;
	// end inline asm
	xor.b32  	%r3064, %r1051, %r1047;
	// begin inline asm
	shf.r.clamp.b32 %r1055, %r1057, %r1057, %r2598;
	// end inline asm
	xor.b32  	%r3065, %r3064, %r1055;
	xor.b32  	%r3066, %r1029, %r1001;
	and.b32  	%r3067, %r1057, %r3066;
	and.b32  	%r3068, %r1029, %r1001;
	xor.b32  	%r3069, %r3067, %r3068;
	add.s32 	%r3070, %r3063, %r3069;
	add.s32 	%r1085, %r3070, %r3065;
	// begin inline asm
	shf.r.clamp.b32 %r1059, %r1129, %r1129, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1063, %r1129, %r1129, %r2578;
	// end inline asm
	xor.b32  	%r3071, %r1063, %r1059;
	// begin inline asm
	shf.r.clamp.b32 %r1067, %r1129, %r1129, %r2582;
	// end inline asm
	xor.b32  	%r3072, %r3071, %r1067;
	add.s32 	%r3073, %r1045, %r3072;
	and.b32  	%r3074, %r1129, %r1101;
	mov.u32 	%r1072, %r1129;
	// begin inline asm
	not.b32  %r1072, %r1072;     
	and.b32  %r1071, %r1072, %r1073; 
	
	// end inline asm
	xor.b32  	%r3075, %r1071, %r3074;
	add.s32 	%r3076, %r3073, %r3075;
	add.s32 	%r3077, %r3076, 310598401;
	add.s32 	%r1157, %r3077, %r1001;
	// begin inline asm
	shf.r.clamp.b32 %r1075, %r1085, %r1085, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1079, %r1085, %r1085, %r2594;
	// end inline asm
	xor.b32  	%r3078, %r1079, %r1075;
	// begin inline asm
	shf.r.clamp.b32 %r1083, %r1085, %r1085, %r2598;
	// end inline asm
	xor.b32  	%r3079, %r3078, %r1083;
	xor.b32  	%r3080, %r1057, %r1029;
	and.b32  	%r3081, %r1085, %r3080;
	and.b32  	%r3082, %r1057, %r1029;
	xor.b32  	%r3083, %r3081, %r3082;
	add.s32 	%r3084, %r3077, %r3083;
	add.s32 	%r1113, %r3084, %r3079;
	// begin inline asm
	shf.r.clamp.b32 %r1087, %r1157, %r1157, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1091, %r1157, %r1157, %r2578;
	// end inline asm
	xor.b32  	%r3085, %r1091, %r1087;
	// begin inline asm
	shf.r.clamp.b32 %r1095, %r1157, %r1157, %r2582;
	// end inline asm
	xor.b32  	%r3086, %r3085, %r1095;
	add.s32 	%r3087, %r1073, %r3086;
	and.b32  	%r3088, %r1157, %r1129;
	mov.u32 	%r1100, %r1157;
	// begin inline asm
	not.b32  %r1100, %r1100;     
	and.b32  %r1099, %r1100, %r1101; 
	
	// end inline asm
	xor.b32  	%r3089, %r1099, %r3088;
	add.s32 	%r3090, %r3087, %r3089;
	add.s32 	%r3091, %r3090, 607225278;
	add.s32 	%r1185, %r3091, %r1029;
	// begin inline asm
	shf.r.clamp.b32 %r1103, %r1113, %r1113, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1107, %r1113, %r1113, %r2594;
	// end inline asm
	xor.b32  	%r3092, %r1107, %r1103;
	// begin inline asm
	shf.r.clamp.b32 %r1111, %r1113, %r1113, %r2598;
	// end inline asm
	xor.b32  	%r3093, %r3092, %r1111;
	xor.b32  	%r3094, %r1085, %r1057;
	and.b32  	%r3095, %r1113, %r3094;
	and.b32  	%r3096, %r1085, %r1057;
	xor.b32  	%r3097, %r3095, %r3096;
	add.s32 	%r3098, %r3091, %r3097;
	add.s32 	%r1141, %r3098, %r3093;
	// begin inline asm
	shf.r.clamp.b32 %r1115, %r1185, %r1185, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1119, %r1185, %r1185, %r2578;
	// end inline asm
	xor.b32  	%r3099, %r1119, %r1115;
	// begin inline asm
	shf.r.clamp.b32 %r1123, %r1185, %r1185, %r2582;
	// end inline asm
	xor.b32  	%r3100, %r3099, %r1123;
	add.s32 	%r3101, %r1101, %r3100;
	and.b32  	%r3102, %r1185, %r1157;
	mov.u32 	%r1128, %r1185;
	// begin inline asm
	not.b32  %r1128, %r1128;     
	and.b32  %r1127, %r1128, %r1129; 
	
	// end inline asm
	xor.b32  	%r3103, %r1127, %r3102;
	add.s32 	%r3104, %r3101, %r3103;
	add.s32 	%r3105, %r3104, 1426881987;
	add.s32 	%r1213, %r3105, %r1057;
	// begin inline asm
	shf.r.clamp.b32 %r1131, %r1141, %r1141, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1135, %r1141, %r1141, %r2594;
	// end inline asm
	xor.b32  	%r3106, %r1135, %r1131;
	// begin inline asm
	shf.r.clamp.b32 %r1139, %r1141, %r1141, %r2598;
	// end inline asm
	xor.b32  	%r3107, %r3106, %r1139;
	xor.b32  	%r3108, %r1113, %r1085;
	and.b32  	%r3109, %r1141, %r3108;
	and.b32  	%r3110, %r1113, %r1085;
	xor.b32  	%r3111, %r3109, %r3110;
	add.s32 	%r3112, %r3105, %r3111;
	add.s32 	%r1169, %r3112, %r3107;
	// begin inline asm
	shf.r.clamp.b32 %r1143, %r1213, %r1213, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1147, %r1213, %r1213, %r2578;
	// end inline asm
	xor.b32  	%r3113, %r1147, %r1143;
	// begin inline asm
	shf.r.clamp.b32 %r1151, %r1213, %r1213, %r2582;
	// end inline asm
	xor.b32  	%r3114, %r3113, %r1151;
	add.s32 	%r3115, %r1129, %r3114;
	and.b32  	%r3116, %r1213, %r1185;
	mov.u32 	%r1156, %r1213;
	// begin inline asm
	not.b32  %r1156, %r1156;     
	and.b32  %r1155, %r1156, %r1157; 
	
	// end inline asm
	xor.b32  	%r3117, %r1155, %r3116;
	add.s32 	%r3118, %r3115, %r3117;
	add.s32 	%r3119, %r3118, 1925078388;
	add.s32 	%r1241, %r3119, %r1085;
	// begin inline asm
	shf.r.clamp.b32 %r1159, %r1169, %r1169, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1163, %r1169, %r1169, %r2594;
	// end inline asm
	xor.b32  	%r3120, %r1163, %r1159;
	// begin inline asm
	shf.r.clamp.b32 %r1167, %r1169, %r1169, %r2598;
	// end inline asm
	xor.b32  	%r3121, %r3120, %r1167;
	xor.b32  	%r3122, %r1141, %r1113;
	and.b32  	%r3123, %r1169, %r3122;
	and.b32  	%r3124, %r1141, %r1113;
	xor.b32  	%r3125, %r3123, %r3124;
	add.s32 	%r3126, %r3119, %r3125;
	add.s32 	%r1197, %r3126, %r3121;
	// begin inline asm
	shf.r.clamp.b32 %r1171, %r1241, %r1241, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1175, %r1241, %r1241, %r2578;
	// end inline asm
	xor.b32  	%r3127, %r1175, %r1171;
	// begin inline asm
	shf.r.clamp.b32 %r1179, %r1241, %r1241, %r2582;
	// end inline asm
	xor.b32  	%r3128, %r3127, %r1179;
	add.s32 	%r3129, %r1157, %r3128;
	and.b32  	%r3130, %r1241, %r1213;
	mov.u32 	%r1184, %r1241;
	// begin inline asm
	not.b32  %r1184, %r1184;     
	and.b32  %r1183, %r1184, %r1185; 
	
	// end inline asm
	xor.b32  	%r3131, %r1183, %r3130;
	add.s32 	%r3132, %r3129, %r3131;
	add.s32 	%r3133, %r3132, -2132889090;
	add.s32 	%r1269, %r3133, %r1113;
	// begin inline asm
	shf.r.clamp.b32 %r1187, %r1197, %r1197, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1191, %r1197, %r1197, %r2594;
	// end inline asm
	xor.b32  	%r3134, %r1191, %r1187;
	// begin inline asm
	shf.r.clamp.b32 %r1195, %r1197, %r1197, %r2598;
	// end inline asm
	xor.b32  	%r3135, %r3134, %r1195;
	xor.b32  	%r3136, %r1169, %r1141;
	and.b32  	%r3137, %r1197, %r3136;
	and.b32  	%r3138, %r1169, %r1141;
	xor.b32  	%r3139, %r3137, %r3138;
	add.s32 	%r3140, %r3133, %r3139;
	add.s32 	%r1225, %r3140, %r3135;
	// begin inline asm
	shf.r.clamp.b32 %r1199, %r1269, %r1269, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1203, %r1269, %r1269, %r2578;
	// end inline asm
	xor.b32  	%r3141, %r1203, %r1199;
	// begin inline asm
	shf.r.clamp.b32 %r1207, %r1269, %r1269, %r2582;
	// end inline asm
	xor.b32  	%r3142, %r3141, %r1207;
	add.s32 	%r3143, %r1185, %r3142;
	and.b32  	%r3144, %r1269, %r1241;
	mov.u32 	%r1212, %r1269;
	// begin inline asm
	not.b32  %r1212, %r1212;     
	and.b32  %r1211, %r1212, %r1213; 
	
	// end inline asm
	xor.b32  	%r3145, %r1211, %r3144;
	add.s32 	%r3146, %r3143, %r3145;
	add.s32 	%r3147, %r3146, -1680079193;
	add.s32 	%r1297, %r3147, %r1141;
	// begin inline asm
	shf.r.clamp.b32 %r1215, %r1225, %r1225, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1219, %r1225, %r1225, %r2594;
	// end inline asm
	xor.b32  	%r3148, %r1219, %r1215;
	// begin inline asm
	shf.r.clamp.b32 %r1223, %r1225, %r1225, %r2598;
	// end inline asm
	xor.b32  	%r3149, %r3148, %r1223;
	xor.b32  	%r3150, %r1197, %r1169;
	and.b32  	%r3151, %r1225, %r3150;
	and.b32  	%r3152, %r1197, %r1169;
	xor.b32  	%r3153, %r3151, %r3152;
	add.s32 	%r3154, %r3147, %r3153;
	add.s32 	%r1253, %r3154, %r3149;
	// begin inline asm
	shf.r.clamp.b32 %r1227, %r1297, %r1297, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1231, %r1297, %r1297, %r2578;
	// end inline asm
	xor.b32  	%r3155, %r1231, %r1227;
	// begin inline asm
	shf.r.clamp.b32 %r1235, %r1297, %r1297, %r2582;
	// end inline asm
	xor.b32  	%r3156, %r3155, %r1235;
	add.s32 	%r3157, %r1213, %r3156;
	and.b32  	%r3158, %r1297, %r1269;
	mov.u32 	%r1240, %r1297;
	// begin inline asm
	not.b32  %r1240, %r1240;     
	and.b32  %r1239, %r1240, %r1241; 
	
	// end inline asm
	xor.b32  	%r3159, %r1239, %r3158;
	add.s32 	%r3160, %r3157, %r3159;
	add.s32 	%r3161, %r3160, -1046744460;
	add.s32 	%r1325, %r3161, %r1169;
	// begin inline asm
	shf.r.clamp.b32 %r1243, %r1253, %r1253, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1247, %r1253, %r1253, %r2594;
	// end inline asm
	xor.b32  	%r3162, %r1247, %r1243;
	// begin inline asm
	shf.r.clamp.b32 %r1251, %r1253, %r1253, %r2598;
	// end inline asm
	xor.b32  	%r3163, %r3162, %r1251;
	xor.b32  	%r3164, %r1225, %r1197;
	and.b32  	%r3165, %r1253, %r3164;
	and.b32  	%r3166, %r1225, %r1197;
	xor.b32  	%r3167, %r3165, %r3166;
	add.s32 	%r3168, %r3161, %r3167;
	add.s32 	%r1281, %r3168, %r3163;
	// begin inline asm
	shf.r.clamp.b32 %r1255, %r1325, %r1325, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1259, %r1325, %r1325, %r2578;
	// end inline asm
	xor.b32  	%r3169, %r1259, %r1255;
	// begin inline asm
	shf.r.clamp.b32 %r1263, %r1325, %r1325, %r2582;
	// end inline asm
	xor.b32  	%r3170, %r3169, %r1263;
	and.b32  	%r3171, %r1325, %r1297;
	mov.u32 	%r1268, %r1325;
	// begin inline asm
	not.b32  %r1268, %r1268;     
	and.b32  %r1267, %r1268, %r1269; 
	
	// end inline asm
	xor.b32  	%r3172, %r1267, %r3171;
	add.s32 	%r3173, %r285, %r1241;
	add.s32 	%r3174, %r3173, %r3170;
	add.s32 	%r3175, %r3174, %r3172;
	add.s32 	%r3176, %r3175, -459576895;
	add.s32 	%r1353, %r3176, %r1197;
	// begin inline asm
	shf.r.clamp.b32 %r1271, %r1281, %r1281, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1275, %r1281, %r1281, %r2594;
	// end inline asm
	xor.b32  	%r3177, %r1275, %r1271;
	// begin inline asm
	shf.r.clamp.b32 %r1279, %r1281, %r1281, %r2598;
	// end inline asm
	xor.b32  	%r3178, %r3177, %r1279;
	xor.b32  	%r3179, %r1253, %r1225;
	and.b32  	%r3180, %r1281, %r3179;
	and.b32  	%r3181, %r1253, %r1225;
	xor.b32  	%r3182, %r3180, %r3181;
	add.s32 	%r3183, %r3176, %r3182;
	add.s32 	%r1309, %r3183, %r3178;
	// begin inline asm
	shf.r.clamp.b32 %r1283, %r1353, %r1353, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1287, %r1353, %r1353, %r2578;
	// end inline asm
	xor.b32  	%r3184, %r1287, %r1283;
	// begin inline asm
	shf.r.clamp.b32 %r1291, %r1353, %r1353, %r2582;
	// end inline asm
	xor.b32  	%r3185, %r3184, %r1291;
	and.b32  	%r3186, %r1353, %r1325;
	mov.u32 	%r1296, %r1353;
	// begin inline asm
	not.b32  %r1296, %r1296;     
	and.b32  %r1295, %r1296, %r1297; 
	
	// end inline asm
	xor.b32  	%r3187, %r1295, %r3186;
	add.s32 	%r3188, %r301, %r1269;
	add.s32 	%r3189, %r3188, %r3185;
	add.s32 	%r3190, %r3189, %r3187;
	add.s32 	%r3191, %r3190, -272742522;
	add.s32 	%r1381, %r3191, %r1225;
	// begin inline asm
	shf.r.clamp.b32 %r1299, %r1309, %r1309, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1303, %r1309, %r1309, %r2594;
	// end inline asm
	xor.b32  	%r3192, %r1303, %r1299;
	// begin inline asm
	shf.r.clamp.b32 %r1307, %r1309, %r1309, %r2598;
	// end inline asm
	xor.b32  	%r3193, %r3192, %r1307;
	xor.b32  	%r3194, %r1281, %r1253;
	and.b32  	%r3195, %r1309, %r3194;
	and.b32  	%r3196, %r1281, %r1253;
	xor.b32  	%r3197, %r3195, %r3196;
	add.s32 	%r3198, %r3191, %r3197;
	add.s32 	%r1337, %r3198, %r3193;
	// begin inline asm
	shf.r.clamp.b32 %r1311, %r1381, %r1381, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1315, %r1381, %r1381, %r2578;
	// end inline asm
	xor.b32  	%r3199, %r1315, %r1311;
	// begin inline asm
	shf.r.clamp.b32 %r1319, %r1381, %r1381, %r2582;
	// end inline asm
	xor.b32  	%r3200, %r3199, %r1319;
	and.b32  	%r3201, %r1381, %r1353;
	mov.u32 	%r1324, %r1381;
	// begin inline asm
	not.b32  %r1324, %r1324;     
	and.b32  %r1323, %r1324, %r1325; 
	
	// end inline asm
	xor.b32  	%r3202, %r1323, %r3201;
	add.s32 	%r3203, %r317, %r1297;
	add.s32 	%r3204, %r3203, %r3200;
	add.s32 	%r3205, %r3204, %r3202;
	add.s32 	%r3206, %r3205, 264347078;
	add.s32 	%r1409, %r3206, %r1253;
	// begin inline asm
	shf.r.clamp.b32 %r1327, %r1337, %r1337, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1331, %r1337, %r1337, %r2594;
	// end inline asm
	xor.b32  	%r3207, %r1331, %r1327;
	// begin inline asm
	shf.r.clamp.b32 %r1335, %r1337, %r1337, %r2598;
	// end inline asm
	xor.b32  	%r3208, %r3207, %r1335;
	xor.b32  	%r3209, %r1309, %r1281;
	and.b32  	%r3210, %r1337, %r3209;
	and.b32  	%r3211, %r1309, %r1281;
	xor.b32  	%r3212, %r3210, %r3211;
	add.s32 	%r3213, %r3206, %r3212;
	add.s32 	%r1365, %r3213, %r3208;
	// begin inline asm
	shf.r.clamp.b32 %r1339, %r1409, %r1409, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1343, %r1409, %r1409, %r2578;
	// end inline asm
	xor.b32  	%r3214, %r1343, %r1339;
	// begin inline asm
	shf.r.clamp.b32 %r1347, %r1409, %r1409, %r2582;
	// end inline asm
	xor.b32  	%r3215, %r3214, %r1347;
	and.b32  	%r3216, %r1409, %r1381;
	mov.u32 	%r1352, %r1409;
	// begin inline asm
	not.b32  %r1352, %r1352;     
	and.b32  %r1351, %r1352, %r1353; 
	
	// end inline asm
	xor.b32  	%r3217, %r1351, %r3216;
	add.s32 	%r3218, %r333, %r1325;
	add.s32 	%r3219, %r3218, %r3215;
	add.s32 	%r3220, %r3219, %r3217;
	add.s32 	%r3221, %r3220, 604807628;
	add.s32 	%r1437, %r3221, %r1281;
	// begin inline asm
	shf.r.clamp.b32 %r1355, %r1365, %r1365, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1359, %r1365, %r1365, %r2594;
	// end inline asm
	xor.b32  	%r3222, %r1359, %r1355;
	// begin inline asm
	shf.r.clamp.b32 %r1363, %r1365, %r1365, %r2598;
	// end inline asm
	xor.b32  	%r3223, %r3222, %r1363;
	xor.b32  	%r3224, %r1337, %r1309;
	and.b32  	%r3225, %r1365, %r3224;
	and.b32  	%r3226, %r1337, %r1309;
	xor.b32  	%r3227, %r3225, %r3226;
	add.s32 	%r3228, %r3221, %r3227;
	add.s32 	%r1393, %r3228, %r3223;
	// begin inline asm
	shf.r.clamp.b32 %r1367, %r1437, %r1437, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1371, %r1437, %r1437, %r2578;
	// end inline asm
	xor.b32  	%r3229, %r1371, %r1367;
	// begin inline asm
	shf.r.clamp.b32 %r1375, %r1437, %r1437, %r2582;
	// end inline asm
	xor.b32  	%r3230, %r3229, %r1375;
	and.b32  	%r3231, %r1437, %r1409;
	mov.u32 	%r1380, %r1437;
	// begin inline asm
	not.b32  %r1380, %r1380;     
	and.b32  %r1379, %r1380, %r1381; 
	
	// end inline asm
	xor.b32  	%r3232, %r1379, %r3231;
	add.s32 	%r3233, %r349, %r1353;
	add.s32 	%r3234, %r3233, %r3230;
	add.s32 	%r3235, %r3234, %r3232;
	add.s32 	%r3236, %r3235, 770255983;
	add.s32 	%r1465, %r3236, %r1309;
	// begin inline asm
	shf.r.clamp.b32 %r1383, %r1393, %r1393, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1387, %r1393, %r1393, %r2594;
	// end inline asm
	xor.b32  	%r3237, %r1387, %r1383;
	// begin inline asm
	shf.r.clamp.b32 %r1391, %r1393, %r1393, %r2598;
	// end inline asm
	xor.b32  	%r3238, %r3237, %r1391;
	xor.b32  	%r3239, %r1365, %r1337;
	and.b32  	%r3240, %r1393, %r3239;
	and.b32  	%r3241, %r1365, %r1337;
	xor.b32  	%r3242, %r3240, %r3241;
	add.s32 	%r3243, %r3236, %r3242;
	add.s32 	%r1421, %r3243, %r3238;
	// begin inline asm
	shf.r.clamp.b32 %r1395, %r1465, %r1465, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1399, %r1465, %r1465, %r2578;
	// end inline asm
	xor.b32  	%r3244, %r1399, %r1395;
	// begin inline asm
	shf.r.clamp.b32 %r1403, %r1465, %r1465, %r2582;
	// end inline asm
	xor.b32  	%r3245, %r3244, %r1403;
	and.b32  	%r3246, %r1465, %r1437;
	mov.u32 	%r1408, %r1465;
	// begin inline asm
	not.b32  %r1408, %r1408;     
	and.b32  %r1407, %r1408, %r1409; 
	
	// end inline asm
	xor.b32  	%r3247, %r1407, %r3246;
	add.s32 	%r3248, %r365, %r1381;
	add.s32 	%r3249, %r3248, %r3245;
	add.s32 	%r3250, %r3249, %r3247;
	add.s32 	%r3251, %r3250, 1249150122;
	add.s32 	%r1493, %r3251, %r1337;
	// begin inline asm
	shf.r.clamp.b32 %r1411, %r1421, %r1421, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1415, %r1421, %r1421, %r2594;
	// end inline asm
	xor.b32  	%r3252, %r1415, %r1411;
	// begin inline asm
	shf.r.clamp.b32 %r1419, %r1421, %r1421, %r2598;
	// end inline asm
	xor.b32  	%r3253, %r3252, %r1419;
	xor.b32  	%r3254, %r1393, %r1365;
	and.b32  	%r3255, %r1421, %r3254;
	and.b32  	%r3256, %r1393, %r1365;
	xor.b32  	%r3257, %r3255, %r3256;
	add.s32 	%r3258, %r3251, %r3257;
	add.s32 	%r1449, %r3258, %r3253;
	// begin inline asm
	shf.r.clamp.b32 %r1423, %r1493, %r1493, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1427, %r1493, %r1493, %r2578;
	// end inline asm
	xor.b32  	%r3259, %r1427, %r1423;
	// begin inline asm
	shf.r.clamp.b32 %r1431, %r1493, %r1493, %r2582;
	// end inline asm
	xor.b32  	%r3260, %r3259, %r1431;
	and.b32  	%r3261, %r1493, %r1465;
	mov.u32 	%r1436, %r1493;
	// begin inline asm
	not.b32  %r1436, %r1436;     
	and.b32  %r1435, %r1436, %r1437; 
	
	// end inline asm
	xor.b32  	%r3262, %r1435, %r3261;
	add.s32 	%r3263, %r176, %r1409;
	add.s32 	%r3264, %r3263, %r3260;
	add.s32 	%r3265, %r3264, %r3262;
	add.s32 	%r3266, %r3265, 1555081692;
	add.s32 	%r1521, %r3266, %r1365;
	// begin inline asm
	shf.r.clamp.b32 %r1439, %r1449, %r1449, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1443, %r1449, %r1449, %r2594;
	// end inline asm
	xor.b32  	%r3267, %r1443, %r1439;
	// begin inline asm
	shf.r.clamp.b32 %r1447, %r1449, %r1449, %r2598;
	// end inline asm
	xor.b32  	%r3268, %r3267, %r1447;
	xor.b32  	%r3269, %r1421, %r1393;
	and.b32  	%r3270, %r1449, %r3269;
	and.b32  	%r3271, %r1421, %r1393;
	xor.b32  	%r3272, %r3270, %r3271;
	add.s32 	%r3273, %r3266, %r3272;
	add.s32 	%r1477, %r3273, %r3268;
	// begin inline asm
	shf.r.clamp.b32 %r1451, %r1521, %r1521, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1455, %r1521, %r1521, %r2578;
	// end inline asm
	xor.b32  	%r3274, %r1455, %r1451;
	// begin inline asm
	shf.r.clamp.b32 %r1459, %r1521, %r1521, %r2582;
	// end inline asm
	xor.b32  	%r3275, %r3274, %r1459;
	and.b32  	%r3276, %r1521, %r1493;
	mov.u32 	%r1464, %r1521;
	// begin inline asm
	not.b32  %r1464, %r1464;     
	and.b32  %r1463, %r1464, %r1465; 
	
	// end inline asm
	xor.b32  	%r3277, %r1463, %r3276;
	add.s32 	%r3278, %r397, %r1437;
	add.s32 	%r3279, %r3278, %r3275;
	add.s32 	%r3280, %r3279, %r3277;
	add.s32 	%r3281, %r3280, 1996064986;
	add.s32 	%r1549, %r3281, %r1393;
	// begin inline asm
	shf.r.clamp.b32 %r1467, %r1477, %r1477, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1471, %r1477, %r1477, %r2594;
	// end inline asm
	xor.b32  	%r3282, %r1471, %r1467;
	// begin inline asm
	shf.r.clamp.b32 %r1475, %r1477, %r1477, %r2598;
	// end inline asm
	xor.b32  	%r3283, %r3282, %r1475;
	xor.b32  	%r3284, %r1449, %r1421;
	and.b32  	%r3285, %r1477, %r3284;
	and.b32  	%r3286, %r1449, %r1421;
	xor.b32  	%r3287, %r3285, %r3286;
	add.s32 	%r3288, %r3281, %r3287;
	add.s32 	%r1505, %r3288, %r3283;
	// begin inline asm
	shf.r.clamp.b32 %r1479, %r1549, %r1549, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1483, %r1549, %r1549, %r2578;
	// end inline asm
	xor.b32  	%r3289, %r1483, %r1479;
	// begin inline asm
	shf.r.clamp.b32 %r1487, %r1549, %r1549, %r2582;
	// end inline asm
	xor.b32  	%r3290, %r3289, %r1487;
	and.b32  	%r3291, %r1549, %r1521;
	mov.u32 	%r1492, %r1549;
	// begin inline asm
	not.b32  %r1492, %r1492;     
	and.b32  %r1491, %r1492, %r1493; 
	
	// end inline asm
	xor.b32  	%r3292, %r1491, %r3291;
	add.s32 	%r3293, %r2657, %r1465;
	add.s32 	%r3294, %r3293, %r3290;
	add.s32 	%r3295, %r3294, %r3292;
	add.s32 	%r3296, %r3295, 406737234;
	add.s32 	%r1577, %r3296, %r1421;
	// begin inline asm
	shf.r.clamp.b32 %r1495, %r1505, %r1505, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1499, %r1505, %r1505, %r2594;
	// end inline asm
	xor.b32  	%r3297, %r1499, %r1495;
	// begin inline asm
	shf.r.clamp.b32 %r1503, %r1505, %r1505, %r2598;
	// end inline asm
	xor.b32  	%r3298, %r3297, %r1503;
	xor.b32  	%r3299, %r1477, %r1449;
	and.b32  	%r3300, %r1505, %r3299;
	and.b32  	%r3301, %r1477, %r1449;
	xor.b32  	%r3302, %r3300, %r3301;
	add.s32 	%r3303, %r3296, %r3302;
	add.s32 	%r1533, %r3303, %r3298;
	// begin inline asm
	shf.r.clamp.b32 %r1507, %r1577, %r1577, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1511, %r1577, %r1577, %r2578;
	// end inline asm
	xor.b32  	%r3304, %r1511, %r1507;
	// begin inline asm
	shf.r.clamp.b32 %r1515, %r1577, %r1577, %r2582;
	// end inline asm
	xor.b32  	%r3305, %r3304, %r1515;
	and.b32  	%r3306, %r1577, %r1549;
	mov.u32 	%r1520, %r1577;
	// begin inline asm
	not.b32  %r1520, %r1520;     
	and.b32  %r1519, %r1520, %r1521; 
	
	// end inline asm
	xor.b32  	%r3307, %r1519, %r3306;
	add.s32 	%r3308, %r429, %r1493;
	add.s32 	%r3309, %r3308, %r3305;
	add.s32 	%r3310, %r3309, %r3307;
	add.s32 	%r3311, %r3310, -1473132947;
	add.s32 	%r1605, %r3311, %r1449;
	// begin inline asm
	shf.r.clamp.b32 %r1523, %r1533, %r1533, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1527, %r1533, %r1533, %r2594;
	// end inline asm
	xor.b32  	%r3312, %r1527, %r1523;
	// begin inline asm
	shf.r.clamp.b32 %r1531, %r1533, %r1533, %r2598;
	// end inline asm
	xor.b32  	%r3313, %r3312, %r1531;
	xor.b32  	%r3314, %r1505, %r1477;
	and.b32  	%r3315, %r1533, %r3314;
	and.b32  	%r3316, %r1505, %r1477;
	xor.b32  	%r3317, %r3315, %r3316;
	add.s32 	%r3318, %r3311, %r3317;
	add.s32 	%r1561, %r3318, %r3313;
	// begin inline asm
	shf.r.clamp.b32 %r1535, %r1605, %r1605, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1539, %r1605, %r1605, %r2578;
	// end inline asm
	xor.b32  	%r3319, %r1539, %r1535;
	// begin inline asm
	shf.r.clamp.b32 %r1543, %r1605, %r1605, %r2582;
	// end inline asm
	xor.b32  	%r3320, %r3319, %r1543;
	and.b32  	%r3321, %r1605, %r1577;
	mov.u32 	%r1548, %r1605;
	// begin inline asm
	not.b32  %r1548, %r1548;     
	and.b32  %r1547, %r1548, %r1549; 
	
	// end inline asm
	xor.b32  	%r3322, %r1547, %r3321;
	add.s32 	%r3323, %r445, %r1521;
	add.s32 	%r3324, %r3323, %r3320;
	add.s32 	%r3325, %r3324, %r3322;
	add.s32 	%r3326, %r3325, -1341970488;
	add.s32 	%r1633, %r3326, %r1477;
	// begin inline asm
	shf.r.clamp.b32 %r1551, %r1561, %r1561, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1555, %r1561, %r1561, %r2594;
	// end inline asm
	xor.b32  	%r3327, %r1555, %r1551;
	// begin inline asm
	shf.r.clamp.b32 %r1559, %r1561, %r1561, %r2598;
	// end inline asm
	xor.b32  	%r3328, %r3327, %r1559;
	xor.b32  	%r3329, %r1533, %r1505;
	and.b32  	%r3330, %r1561, %r3329;
	and.b32  	%r3331, %r1533, %r1505;
	xor.b32  	%r3332, %r3330, %r3331;
	add.s32 	%r3333, %r3326, %r3332;
	add.s32 	%r1589, %r3333, %r3328;
	// begin inline asm
	shf.r.clamp.b32 %r1563, %r1633, %r1633, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1567, %r1633, %r1633, %r2578;
	// end inline asm
	xor.b32  	%r3334, %r1567, %r1563;
	// begin inline asm
	shf.r.clamp.b32 %r1571, %r1633, %r1633, %r2582;
	// end inline asm
	xor.b32  	%r3335, %r3334, %r1571;
	and.b32  	%r3336, %r1633, %r1605;
	mov.u32 	%r1576, %r1633;
	// begin inline asm
	not.b32  %r1576, %r1576;     
	and.b32  %r1575, %r1576, %r1577; 
	
	// end inline asm
	xor.b32  	%r3337, %r1575, %r3336;
	add.s32 	%r3338, %r461, %r1549;
	add.s32 	%r3339, %r3338, %r3335;
	add.s32 	%r3340, %r3339, %r3337;
	add.s32 	%r3341, %r3340, -1084653625;
	add.s32 	%r1661, %r3341, %r1505;
	// begin inline asm
	shf.r.clamp.b32 %r1579, %r1589, %r1589, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1583, %r1589, %r1589, %r2594;
	// end inline asm
	xor.b32  	%r3342, %r1583, %r1579;
	// begin inline asm
	shf.r.clamp.b32 %r1587, %r1589, %r1589, %r2598;
	// end inline asm
	xor.b32  	%r3343, %r3342, %r1587;
	xor.b32  	%r3344, %r1561, %r1533;
	and.b32  	%r3345, %r1589, %r3344;
	and.b32  	%r3346, %r1561, %r1533;
	xor.b32  	%r3347, %r3345, %r3346;
	add.s32 	%r3348, %r3341, %r3347;
	add.s32 	%r1617, %r3348, %r3343;
	// begin inline asm
	shf.r.clamp.b32 %r1591, %r1661, %r1661, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1595, %r1661, %r1661, %r2578;
	// end inline asm
	xor.b32  	%r3349, %r1595, %r1591;
	// begin inline asm
	shf.r.clamp.b32 %r1599, %r1661, %r1661, %r2582;
	// end inline asm
	xor.b32  	%r3350, %r3349, %r1599;
	and.b32  	%r3351, %r1661, %r1633;
	mov.u32 	%r1604, %r1661;
	// begin inline asm
	not.b32  %r1604, %r1604;     
	and.b32  %r1603, %r1604, %r1605; 
	
	// end inline asm
	xor.b32  	%r3352, %r1603, %r3351;
	add.s32 	%r3353, %r477, %r1577;
	add.s32 	%r3354, %r3353, %r3350;
	add.s32 	%r3355, %r3354, %r3352;
	add.s32 	%r3356, %r3355, -958395405;
	add.s32 	%r1689, %r3356, %r1533;
	// begin inline asm
	shf.r.clamp.b32 %r1607, %r1617, %r1617, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1611, %r1617, %r1617, %r2594;
	// end inline asm
	xor.b32  	%r3357, %r1611, %r1607;
	// begin inline asm
	shf.r.clamp.b32 %r1615, %r1617, %r1617, %r2598;
	// end inline asm
	xor.b32  	%r3358, %r3357, %r1615;
	xor.b32  	%r3359, %r1589, %r1561;
	and.b32  	%r3360, %r1617, %r3359;
	and.b32  	%r3361, %r1589, %r1561;
	xor.b32  	%r3362, %r3360, %r3361;
	add.s32 	%r3363, %r3356, %r3362;
	add.s32 	%r1645, %r3363, %r3358;
	// begin inline asm
	shf.r.clamp.b32 %r1619, %r1689, %r1689, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1623, %r1689, %r1689, %r2578;
	// end inline asm
	xor.b32  	%r3364, %r1623, %r1619;
	// begin inline asm
	shf.r.clamp.b32 %r1627, %r1689, %r1689, %r2582;
	// end inline asm
	xor.b32  	%r3365, %r3364, %r1627;
	and.b32  	%r3366, %r1689, %r1661;
	mov.u32 	%r1632, %r1689;
	// begin inline asm
	not.b32  %r1632, %r1632;     
	and.b32  %r1631, %r1632, %r1633; 
	
	// end inline asm
	xor.b32  	%r3367, %r1631, %r3366;
	add.s32 	%r3368, %r493, %r1605;
	add.s32 	%r3369, %r3368, %r3365;
	add.s32 	%r3370, %r3369, %r3367;
	add.s32 	%r3371, %r3370, -710438585;
	add.s32 	%r1717, %r3371, %r1561;
	// begin inline asm
	shf.r.clamp.b32 %r1635, %r1645, %r1645, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1639, %r1645, %r1645, %r2594;
	// end inline asm
	xor.b32  	%r3372, %r1639, %r1635;
	// begin inline asm
	shf.r.clamp.b32 %r1643, %r1645, %r1645, %r2598;
	// end inline asm
	xor.b32  	%r3373, %r3372, %r1643;
	xor.b32  	%r3374, %r1617, %r1589;
	and.b32  	%r3375, %r1645, %r3374;
	and.b32  	%r3376, %r1617, %r1589;
	xor.b32  	%r3377, %r3375, %r3376;
	add.s32 	%r3378, %r3371, %r3377;
	add.s32 	%r1673, %r3378, %r3373;
	// begin inline asm
	shf.r.clamp.b32 %r1647, %r1717, %r1717, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1651, %r1717, %r1717, %r2578;
	// end inline asm
	xor.b32  	%r3379, %r1651, %r1647;
	// begin inline asm
	shf.r.clamp.b32 %r1655, %r1717, %r1717, %r2582;
	// end inline asm
	xor.b32  	%r3380, %r3379, %r1655;
	and.b32  	%r3381, %r1717, %r1689;
	mov.u32 	%r1660, %r1717;
	// begin inline asm
	not.b32  %r1660, %r1660;     
	and.b32  %r1659, %r1660, %r1661; 
	
	// end inline asm
	xor.b32  	%r3382, %r1659, %r3381;
	add.s32 	%r3383, %r509, %r1633;
	add.s32 	%r3384, %r3383, %r3380;
	add.s32 	%r3385, %r3384, %r3382;
	add.s32 	%r3386, %r3385, 113926993;
	add.s32 	%r1745, %r3386, %r1589;
	// begin inline asm
	shf.r.clamp.b32 %r1663, %r1673, %r1673, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1667, %r1673, %r1673, %r2594;
	// end inline asm
	xor.b32  	%r3387, %r1667, %r1663;
	// begin inline asm
	shf.r.clamp.b32 %r1671, %r1673, %r1673, %r2598;
	// end inline asm
	xor.b32  	%r3388, %r3387, %r1671;
	xor.b32  	%r3389, %r1645, %r1617;
	and.b32  	%r3390, %r1673, %r3389;
	and.b32  	%r3391, %r1645, %r1617;
	xor.b32  	%r3392, %r3390, %r3391;
	add.s32 	%r3393, %r3386, %r3392;
	add.s32 	%r1701, %r3393, %r3388;
	// begin inline asm
	shf.r.clamp.b32 %r1675, %r1745, %r1745, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1679, %r1745, %r1745, %r2578;
	// end inline asm
	xor.b32  	%r3394, %r1679, %r1675;
	// begin inline asm
	shf.r.clamp.b32 %r1683, %r1745, %r1745, %r2582;
	// end inline asm
	xor.b32  	%r3395, %r3394, %r1683;
	and.b32  	%r3396, %r1745, %r1717;
	mov.u32 	%r1688, %r1745;
	// begin inline asm
	not.b32  %r1688, %r1688;     
	and.b32  %r1687, %r1688, %r1689; 
	
	// end inline asm
	xor.b32  	%r3397, %r1687, %r3396;
	add.s32 	%r3398, %r320, %r1661;
	add.s32 	%r3399, %r3398, %r3395;
	add.s32 	%r3400, %r3399, %r3397;
	add.s32 	%r3401, %r3400, 338241895;
	add.s32 	%r1773, %r3401, %r1617;
	// begin inline asm
	shf.r.clamp.b32 %r1691, %r1701, %r1701, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1695, %r1701, %r1701, %r2594;
	// end inline asm
	xor.b32  	%r3402, %r1695, %r1691;
	// begin inline asm
	shf.r.clamp.b32 %r1699, %r1701, %r1701, %r2598;
	// end inline asm
	xor.b32  	%r3403, %r3402, %r1699;
	xor.b32  	%r3404, %r1673, %r1645;
	and.b32  	%r3405, %r1701, %r3404;
	and.b32  	%r3406, %r1673, %r1645;
	xor.b32  	%r3407, %r3405, %r3406;
	add.s32 	%r3408, %r3401, %r3407;
	add.s32 	%r1729, %r3408, %r3403;
	// begin inline asm
	shf.r.clamp.b32 %r1703, %r1773, %r1773, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1707, %r1773, %r1773, %r2578;
	// end inline asm
	xor.b32  	%r3409, %r1707, %r1703;
	// begin inline asm
	shf.r.clamp.b32 %r1711, %r1773, %r1773, %r2582;
	// end inline asm
	xor.b32  	%r3410, %r3409, %r1711;
	and.b32  	%r3411, %r1773, %r1745;
	mov.u32 	%r1716, %r1773;
	// begin inline asm
	not.b32  %r1716, %r1716;     
	and.b32  %r1715, %r1716, %r1717; 
	
	// end inline asm
	xor.b32  	%r3412, %r1715, %r3411;
	add.s32 	%r3413, %r541, %r1689;
	add.s32 	%r3414, %r3413, %r3410;
	add.s32 	%r3415, %r3414, %r3412;
	add.s32 	%r3416, %r3415, 666307205;
	add.s32 	%r1801, %r3416, %r1645;
	// begin inline asm
	shf.r.clamp.b32 %r1719, %r1729, %r1729, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1723, %r1729, %r1729, %r2594;
	// end inline asm
	xor.b32  	%r3417, %r1723, %r1719;
	// begin inline asm
	shf.r.clamp.b32 %r1727, %r1729, %r1729, %r2598;
	// end inline asm
	xor.b32  	%r3418, %r3417, %r1727;
	xor.b32  	%r3419, %r1701, %r1673;
	and.b32  	%r3420, %r1729, %r3419;
	and.b32  	%r3421, %r1701, %r1673;
	xor.b32  	%r3422, %r3420, %r3421;
	add.s32 	%r3423, %r3416, %r3422;
	add.s32 	%r1757, %r3423, %r3418;
	// begin inline asm
	shf.r.clamp.b32 %r1731, %r1801, %r1801, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1735, %r1801, %r1801, %r2578;
	// end inline asm
	xor.b32  	%r3424, %r1735, %r1731;
	// begin inline asm
	shf.r.clamp.b32 %r1739, %r1801, %r1801, %r2582;
	// end inline asm
	xor.b32  	%r3425, %r3424, %r1739;
	and.b32  	%r3426, %r1801, %r1773;
	mov.u32 	%r1744, %r1801;
	// begin inline asm
	not.b32  %r1744, %r1744;     
	and.b32  %r1743, %r1744, %r1745; 
	
	// end inline asm
	xor.b32  	%r3427, %r1743, %r3426;
	add.s32 	%r3428, %r557, %r1717;
	add.s32 	%r3429, %r3428, %r3425;
	add.s32 	%r3430, %r3429, %r3427;
	add.s32 	%r3431, %r3430, 773529912;
	add.s32 	%r1829, %r3431, %r1673;
	// begin inline asm
	shf.r.clamp.b32 %r1747, %r1757, %r1757, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1751, %r1757, %r1757, %r2594;
	// end inline asm
	xor.b32  	%r3432, %r1751, %r1747;
	// begin inline asm
	shf.r.clamp.b32 %r1755, %r1757, %r1757, %r2598;
	// end inline asm
	xor.b32  	%r3433, %r3432, %r1755;
	xor.b32  	%r3434, %r1729, %r1701;
	and.b32  	%r3435, %r1757, %r3434;
	and.b32  	%r3436, %r1729, %r1701;
	xor.b32  	%r3437, %r3435, %r3436;
	add.s32 	%r3438, %r3431, %r3437;
	add.s32 	%r1785, %r3438, %r3433;
	// begin inline asm
	shf.r.clamp.b32 %r1759, %r1829, %r1829, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1763, %r1829, %r1829, %r2578;
	// end inline asm
	xor.b32  	%r3439, %r1763, %r1759;
	// begin inline asm
	shf.r.clamp.b32 %r1767, %r1829, %r1829, %r2582;
	// end inline asm
	xor.b32  	%r3440, %r3439, %r1767;
	and.b32  	%r3441, %r1829, %r1801;
	mov.u32 	%r1772, %r1829;
	// begin inline asm
	not.b32  %r1772, %r1772;     
	and.b32  %r1771, %r1772, %r1773; 
	
	// end inline asm
	xor.b32  	%r3442, %r1771, %r3441;
	add.s32 	%r3443, %r573, %r1745;
	add.s32 	%r3444, %r3443, %r3440;
	add.s32 	%r3445, %r3444, %r3442;
	add.s32 	%r3446, %r3445, 1294757372;
	add.s32 	%r1857, %r3446, %r1701;
	// begin inline asm
	shf.r.clamp.b32 %r1775, %r1785, %r1785, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1779, %r1785, %r1785, %r2594;
	// end inline asm
	xor.b32  	%r3447, %r1779, %r1775;
	// begin inline asm
	shf.r.clamp.b32 %r1783, %r1785, %r1785, %r2598;
	// end inline asm
	xor.b32  	%r3448, %r3447, %r1783;
	xor.b32  	%r3449, %r1757, %r1729;
	and.b32  	%r3450, %r1785, %r3449;
	and.b32  	%r3451, %r1757, %r1729;
	xor.b32  	%r3452, %r3450, %r3451;
	add.s32 	%r3453, %r3446, %r3452;
	add.s32 	%r1813, %r3453, %r3448;
	// begin inline asm
	shf.r.clamp.b32 %r1787, %r1857, %r1857, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1791, %r1857, %r1857, %r2578;
	// end inline asm
	xor.b32  	%r3454, %r1791, %r1787;
	// begin inline asm
	shf.r.clamp.b32 %r1795, %r1857, %r1857, %r2582;
	// end inline asm
	xor.b32  	%r3455, %r3454, %r1795;
	and.b32  	%r3456, %r1857, %r1829;
	mov.u32 	%r1800, %r1857;
	// begin inline asm
	not.b32  %r1800, %r1800;     
	and.b32  %r1799, %r1800, %r1801; 
	
	// end inline asm
	xor.b32  	%r3457, %r1799, %r3456;
	add.s32 	%r3458, %r589, %r1773;
	add.s32 	%r3459, %r3458, %r3455;
	add.s32 	%r3460, %r3459, %r3457;
	add.s32 	%r3461, %r3460, 1396182291;
	add.s32 	%r1885, %r3461, %r1729;
	// begin inline asm
	shf.r.clamp.b32 %r1803, %r1813, %r1813, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1807, %r1813, %r1813, %r2594;
	// end inline asm
	xor.b32  	%r3462, %r1807, %r1803;
	// begin inline asm
	shf.r.clamp.b32 %r1811, %r1813, %r1813, %r2598;
	// end inline asm
	xor.b32  	%r3463, %r3462, %r1811;
	xor.b32  	%r3464, %r1785, %r1757;
	and.b32  	%r3465, %r1813, %r3464;
	and.b32  	%r3466, %r1785, %r1757;
	xor.b32  	%r3467, %r3465, %r3466;
	add.s32 	%r3468, %r3461, %r3467;
	add.s32 	%r1841, %r3468, %r3463;
	// begin inline asm
	shf.r.clamp.b32 %r1815, %r1885, %r1885, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1819, %r1885, %r1885, %r2578;
	// end inline asm
	xor.b32  	%r3469, %r1819, %r1815;
	// begin inline asm
	shf.r.clamp.b32 %r1823, %r1885, %r1885, %r2582;
	// end inline asm
	xor.b32  	%r3470, %r3469, %r1823;
	and.b32  	%r3471, %r1885, %r1857;
	mov.u32 	%r1828, %r1885;
	// begin inline asm
	not.b32  %r1828, %r1828;     
	and.b32  %r1827, %r1828, %r1829; 
	
	// end inline asm
	xor.b32  	%r3472, %r1827, %r3471;
	add.s32 	%r3473, %r605, %r1801;
	add.s32 	%r3474, %r3473, %r3470;
	add.s32 	%r3475, %r3474, %r3472;
	add.s32 	%r3476, %r3475, 1695183700;
	add.s32 	%r1913, %r3476, %r1757;
	// begin inline asm
	shf.r.clamp.b32 %r1831, %r1841, %r1841, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1835, %r1841, %r1841, %r2594;
	// end inline asm
	xor.b32  	%r3477, %r1835, %r1831;
	// begin inline asm
	shf.r.clamp.b32 %r1839, %r1841, %r1841, %r2598;
	// end inline asm
	xor.b32  	%r3478, %r3477, %r1839;
	xor.b32  	%r3479, %r1813, %r1785;
	and.b32  	%r3480, %r1841, %r3479;
	and.b32  	%r3481, %r1813, %r1785;
	xor.b32  	%r3482, %r3480, %r3481;
	add.s32 	%r3483, %r3476, %r3482;
	add.s32 	%r1869, %r3483, %r3478;
	// begin inline asm
	shf.r.clamp.b32 %r1843, %r1913, %r1913, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1847, %r1913, %r1913, %r2578;
	// end inline asm
	xor.b32  	%r3484, %r1847, %r1843;
	// begin inline asm
	shf.r.clamp.b32 %r1851, %r1913, %r1913, %r2582;
	// end inline asm
	xor.b32  	%r3485, %r3484, %r1851;
	and.b32  	%r3486, %r1913, %r1885;
	mov.u32 	%r1856, %r1913;
	// begin inline asm
	not.b32  %r1856, %r1856;     
	and.b32  %r1855, %r1856, %r1857; 
	
	// end inline asm
	xor.b32  	%r3487, %r1855, %r3486;
	add.s32 	%r3488, %r621, %r1829;
	add.s32 	%r3489, %r3488, %r3485;
	add.s32 	%r3490, %r3489, %r3487;
	add.s32 	%r3491, %r3490, 1986661051;
	add.s32 	%r1941, %r3491, %r1785;
	// begin inline asm
	shf.r.clamp.b32 %r1859, %r1869, %r1869, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1863, %r1869, %r1869, %r2594;
	// end inline asm
	xor.b32  	%r3492, %r1863, %r1859;
	// begin inline asm
	shf.r.clamp.b32 %r1867, %r1869, %r1869, %r2598;
	// end inline asm
	xor.b32  	%r3493, %r3492, %r1867;
	xor.b32  	%r3494, %r1841, %r1813;
	and.b32  	%r3495, %r1869, %r3494;
	and.b32  	%r3496, %r1841, %r1813;
	xor.b32  	%r3497, %r3495, %r3496;
	add.s32 	%r3498, %r3491, %r3497;
	add.s32 	%r1897, %r3498, %r3493;
	// begin inline asm
	shf.r.clamp.b32 %r1871, %r1941, %r1941, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1875, %r1941, %r1941, %r2578;
	// end inline asm
	xor.b32  	%r3499, %r1875, %r1871;
	// begin inline asm
	shf.r.clamp.b32 %r1879, %r1941, %r1941, %r2582;
	// end inline asm
	xor.b32  	%r3500, %r3499, %r1879;
	and.b32  	%r3501, %r1941, %r1913;
	mov.u32 	%r1884, %r1941;
	// begin inline asm
	not.b32  %r1884, %r1884;     
	and.b32  %r1883, %r1884, %r1885; 
	
	// end inline asm
	xor.b32  	%r3502, %r1883, %r3501;
	add.s32 	%r3503, %r637, %r1857;
	add.s32 	%r3504, %r3503, %r3500;
	add.s32 	%r3505, %r3504, %r3502;
	add.s32 	%r3506, %r3505, -2117940946;
	add.s32 	%r1969, %r3506, %r1813;
	// begin inline asm
	shf.r.clamp.b32 %r1887, %r1897, %r1897, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1891, %r1897, %r1897, %r2594;
	// end inline asm
	xor.b32  	%r3507, %r1891, %r1887;
	// begin inline asm
	shf.r.clamp.b32 %r1895, %r1897, %r1897, %r2598;
	// end inline asm
	xor.b32  	%r3508, %r3507, %r1895;
	xor.b32  	%r3509, %r1869, %r1841;
	and.b32  	%r3510, %r1897, %r3509;
	and.b32  	%r3511, %r1869, %r1841;
	xor.b32  	%r3512, %r3510, %r3511;
	add.s32 	%r3513, %r3506, %r3512;
	add.s32 	%r1925, %r3513, %r3508;
	// begin inline asm
	shf.r.clamp.b32 %r1899, %r1969, %r1969, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1903, %r1969, %r1969, %r2578;
	// end inline asm
	xor.b32  	%r3514, %r1903, %r1899;
	// begin inline asm
	shf.r.clamp.b32 %r1907, %r1969, %r1969, %r2582;
	// end inline asm
	xor.b32  	%r3515, %r3514, %r1907;
	and.b32  	%r3516, %r1969, %r1941;
	mov.u32 	%r1912, %r1969;
	// begin inline asm
	not.b32  %r1912, %r1912;     
	and.b32  %r1911, %r1912, %r1913; 
	
	// end inline asm
	xor.b32  	%r3517, %r1911, %r3516;
	add.s32 	%r3518, %r653, %r1885;
	add.s32 	%r3519, %r3518, %r3515;
	add.s32 	%r3520, %r3519, %r3517;
	add.s32 	%r3521, %r3520, -1838011259;
	add.s32 	%r1997, %r3521, %r1841;
	// begin inline asm
	shf.r.clamp.b32 %r1915, %r1925, %r1925, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1919, %r1925, %r1925, %r2594;
	// end inline asm
	xor.b32  	%r3522, %r1919, %r1915;
	// begin inline asm
	shf.r.clamp.b32 %r1923, %r1925, %r1925, %r2598;
	// end inline asm
	xor.b32  	%r3523, %r3522, %r1923;
	xor.b32  	%r3524, %r1897, %r1869;
	and.b32  	%r3525, %r1925, %r3524;
	and.b32  	%r3526, %r1897, %r1869;
	xor.b32  	%r3527, %r3525, %r3526;
	add.s32 	%r3528, %r3521, %r3527;
	add.s32 	%r1953, %r3528, %r3523;
	// begin inline asm
	shf.r.clamp.b32 %r1927, %r1997, %r1997, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1931, %r1997, %r1997, %r2578;
	// end inline asm
	xor.b32  	%r3529, %r1931, %r1927;
	// begin inline asm
	shf.r.clamp.b32 %r1935, %r1997, %r1997, %r2582;
	// end inline asm
	xor.b32  	%r3530, %r3529, %r1935;
	and.b32  	%r3531, %r1997, %r1969;
	mov.u32 	%r1940, %r1997;
	// begin inline asm
	not.b32  %r1940, %r1940;     
	and.b32  %r1939, %r1940, %r1941; 
	
	// end inline asm
	xor.b32  	%r3532, %r1939, %r3531;
	add.s32 	%r3533, %r669, %r1913;
	add.s32 	%r3534, %r3533, %r3530;
	add.s32 	%r3535, %r3534, %r3532;
	add.s32 	%r3536, %r3535, -1564481375;
	add.s32 	%r2025, %r3536, %r1869;
	// begin inline asm
	shf.r.clamp.b32 %r1943, %r1953, %r1953, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1947, %r1953, %r1953, %r2594;
	// end inline asm
	xor.b32  	%r3537, %r1947, %r1943;
	// begin inline asm
	shf.r.clamp.b32 %r1951, %r1953, %r1953, %r2598;
	// end inline asm
	xor.b32  	%r3538, %r3537, %r1951;
	xor.b32  	%r3539, %r1925, %r1897;
	and.b32  	%r3540, %r1953, %r3539;
	and.b32  	%r3541, %r1925, %r1897;
	xor.b32  	%r3542, %r3540, %r3541;
	add.s32 	%r3543, %r3536, %r3542;
	add.s32 	%r1981, %r3543, %r3538;
	// begin inline asm
	shf.r.clamp.b32 %r1955, %r2025, %r2025, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1959, %r2025, %r2025, %r2578;
	// end inline asm
	xor.b32  	%r3544, %r1959, %r1955;
	// begin inline asm
	shf.r.clamp.b32 %r1963, %r2025, %r2025, %r2582;
	// end inline asm
	xor.b32  	%r3545, %r3544, %r1963;
	and.b32  	%r3546, %r2025, %r1997;
	mov.u32 	%r1968, %r2025;
	// begin inline asm
	not.b32  %r1968, %r1968;     
	and.b32  %r1967, %r1968, %r1969; 
	
	// end inline asm
	xor.b32  	%r3547, %r1967, %r3546;
	add.s32 	%r3548, %r685, %r1941;
	add.s32 	%r3549, %r3548, %r3545;
	add.s32 	%r3550, %r3549, %r3547;
	add.s32 	%r3551, %r3550, -1474664885;
	add.s32 	%r2053, %r3551, %r1897;
	// begin inline asm
	shf.r.clamp.b32 %r1971, %r1981, %r1981, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1975, %r1981, %r1981, %r2594;
	// end inline asm
	xor.b32  	%r3552, %r1975, %r1971;
	// begin inline asm
	shf.r.clamp.b32 %r1979, %r1981, %r1981, %r2598;
	// end inline asm
	xor.b32  	%r3553, %r3552, %r1979;
	xor.b32  	%r3554, %r1953, %r1925;
	and.b32  	%r3555, %r1981, %r3554;
	and.b32  	%r3556, %r1953, %r1925;
	xor.b32  	%r3557, %r3555, %r3556;
	add.s32 	%r3558, %r3551, %r3557;
	add.s32 	%r2009, %r3558, %r3553;
	// begin inline asm
	shf.r.clamp.b32 %r1983, %r2053, %r2053, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1987, %r2053, %r2053, %r2578;
	// end inline asm
	xor.b32  	%r3559, %r1987, %r1983;
	// begin inline asm
	shf.r.clamp.b32 %r1991, %r2053, %r2053, %r2582;
	// end inline asm
	xor.b32  	%r3560, %r3559, %r1991;
	and.b32  	%r3561, %r2053, %r2025;
	mov.u32 	%r1996, %r2053;
	// begin inline asm
	not.b32  %r1996, %r1996;     
	and.b32  %r1995, %r1996, %r1997; 
	
	// end inline asm
	xor.b32  	%r3562, %r1995, %r3561;
	add.s32 	%r3563, %r701, %r1969;
	add.s32 	%r3564, %r3563, %r3560;
	add.s32 	%r3565, %r3564, %r3562;
	add.s32 	%r3566, %r3565, -1035236496;
	add.s32 	%r2081, %r3566, %r1925;
	// begin inline asm
	shf.r.clamp.b32 %r1999, %r2009, %r2009, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2003, %r2009, %r2009, %r2594;
	// end inline asm
	xor.b32  	%r3567, %r2003, %r1999;
	// begin inline asm
	shf.r.clamp.b32 %r2007, %r2009, %r2009, %r2598;
	// end inline asm
	xor.b32  	%r3568, %r3567, %r2007;
	xor.b32  	%r3569, %r1981, %r1953;
	and.b32  	%r3570, %r2009, %r3569;
	and.b32  	%r3571, %r1981, %r1953;
	xor.b32  	%r3572, %r3570, %r3571;
	add.s32 	%r3573, %r3566, %r3572;
	add.s32 	%r2037, %r3573, %r3568;
	// begin inline asm
	shf.r.clamp.b32 %r2011, %r2081, %r2081, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2015, %r2081, %r2081, %r2578;
	// end inline asm
	xor.b32  	%r3574, %r2015, %r2011;
	// begin inline asm
	shf.r.clamp.b32 %r2019, %r2081, %r2081, %r2582;
	// end inline asm
	xor.b32  	%r3575, %r3574, %r2019;
	and.b32  	%r3576, %r2081, %r2053;
	mov.u32 	%r2024, %r2081;
	// begin inline asm
	not.b32  %r2024, %r2024;     
	and.b32  %r2023, %r2024, %r2025; 
	
	// end inline asm
	xor.b32  	%r3577, %r2023, %r3576;
	add.s32 	%r3578, %r717, %r1997;
	add.s32 	%r3579, %r3578, %r3575;
	add.s32 	%r3580, %r3579, %r3577;
	add.s32 	%r3581, %r3580, -949202525;
	add.s32 	%r2109, %r3581, %r1953;
	// begin inline asm
	shf.r.clamp.b32 %r2027, %r2037, %r2037, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2031, %r2037, %r2037, %r2594;
	// end inline asm
	xor.b32  	%r3582, %r2031, %r2027;
	// begin inline asm
	shf.r.clamp.b32 %r2035, %r2037, %r2037, %r2598;
	// end inline asm
	xor.b32  	%r3583, %r3582, %r2035;
	xor.b32  	%r3584, %r2009, %r1981;
	and.b32  	%r3585, %r2037, %r3584;
	and.b32  	%r3586, %r2009, %r1981;
	xor.b32  	%r3587, %r3585, %r3586;
	add.s32 	%r3588, %r3581, %r3587;
	add.s32 	%r2065, %r3588, %r3583;
	// begin inline asm
	shf.r.clamp.b32 %r2039, %r2109, %r2109, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2043, %r2109, %r2109, %r2578;
	// end inline asm
	xor.b32  	%r3589, %r2043, %r2039;
	// begin inline asm
	shf.r.clamp.b32 %r2047, %r2109, %r2109, %r2582;
	// end inline asm
	xor.b32  	%r3590, %r3589, %r2047;
	and.b32  	%r3591, %r2109, %r2081;
	mov.u32 	%r2052, %r2109;
	// begin inline asm
	not.b32  %r2052, %r2052;     
	and.b32  %r2051, %r2052, %r2053; 
	
	// end inline asm
	xor.b32  	%r3592, %r2051, %r3591;
	add.s32 	%r3593, %r733, %r2025;
	add.s32 	%r3594, %r3593, %r3590;
	add.s32 	%r3595, %r3594, %r3592;
	add.s32 	%r3596, %r3595, -778901479;
	add.s32 	%r2137, %r3596, %r1981;
	// begin inline asm
	shf.r.clamp.b32 %r2055, %r2065, %r2065, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2059, %r2065, %r2065, %r2594;
	// end inline asm
	xor.b32  	%r3597, %r2059, %r2055;
	// begin inline asm
	shf.r.clamp.b32 %r2063, %r2065, %r2065, %r2598;
	// end inline asm
	xor.b32  	%r3598, %r3597, %r2063;
	xor.b32  	%r3599, %r2037, %r2009;
	and.b32  	%r3600, %r2065, %r3599;
	and.b32  	%r3601, %r2037, %r2009;
	xor.b32  	%r3602, %r3600, %r3601;
	add.s32 	%r3603, %r3596, %r3602;
	add.s32 	%r2093, %r3603, %r3598;
	// begin inline asm
	shf.r.clamp.b32 %r2067, %r2137, %r2137, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2071, %r2137, %r2137, %r2578;
	// end inline asm
	xor.b32  	%r3604, %r2071, %r2067;
	// begin inline asm
	shf.r.clamp.b32 %r2075, %r2137, %r2137, %r2582;
	// end inline asm
	xor.b32  	%r3605, %r3604, %r2075;
	and.b32  	%r3606, %r2137, %r2109;
	mov.u32 	%r2080, %r2137;
	// begin inline asm
	not.b32  %r2080, %r2080;     
	and.b32  %r2079, %r2080, %r2081; 
	
	// end inline asm
	xor.b32  	%r3607, %r2079, %r3606;
	add.s32 	%r3608, %r749, %r2053;
	add.s32 	%r3609, %r3608, %r3605;
	add.s32 	%r3610, %r3609, %r3607;
	add.s32 	%r3611, %r3610, -694614492;
	add.s32 	%r2165, %r3611, %r2009;
	// begin inline asm
	shf.r.clamp.b32 %r2083, %r2093, %r2093, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2087, %r2093, %r2093, %r2594;
	// end inline asm
	xor.b32  	%r3612, %r2087, %r2083;
	// begin inline asm
	shf.r.clamp.b32 %r2091, %r2093, %r2093, %r2598;
	// end inline asm
	xor.b32  	%r3613, %r3612, %r2091;
	xor.b32  	%r3614, %r2065, %r2037;
	and.b32  	%r3615, %r2093, %r3614;
	and.b32  	%r3616, %r2065, %r2037;
	xor.b32  	%r3617, %r3615, %r3616;
	add.s32 	%r3618, %r3611, %r3617;
	add.s32 	%r2121, %r3618, %r3613;
	// begin inline asm
	shf.r.clamp.b32 %r2095, %r2165, %r2165, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2099, %r2165, %r2165, %r2578;
	// end inline asm
	xor.b32  	%r3619, %r2099, %r2095;
	// begin inline asm
	shf.r.clamp.b32 %r2103, %r2165, %r2165, %r2582;
	// end inline asm
	xor.b32  	%r3620, %r3619, %r2103;
	and.b32  	%r3621, %r2165, %r2137;
	mov.u32 	%r2108, %r2165;
	// begin inline asm
	not.b32  %r2108, %r2108;     
	and.b32  %r2107, %r2108, %r2109; 
	
	// end inline asm
	xor.b32  	%r3622, %r2107, %r3621;
	add.s32 	%r3623, %r765, %r2081;
	add.s32 	%r3624, %r3623, %r3620;
	add.s32 	%r3625, %r3624, %r3622;
	add.s32 	%r3626, %r3625, -200395387;
	add.s32 	%r2193, %r3626, %r2037;
	// begin inline asm
	shf.r.clamp.b32 %r2111, %r2121, %r2121, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2115, %r2121, %r2121, %r2594;
	// end inline asm
	xor.b32  	%r3627, %r2115, %r2111;
	// begin inline asm
	shf.r.clamp.b32 %r2119, %r2121, %r2121, %r2598;
	// end inline asm
	xor.b32  	%r3628, %r3627, %r2119;
	xor.b32  	%r3629, %r2093, %r2065;
	and.b32  	%r3630, %r2121, %r3629;
	and.b32  	%r3631, %r2093, %r2065;
	xor.b32  	%r3632, %r3630, %r3631;
	add.s32 	%r3633, %r3626, %r3632;
	add.s32 	%r2149, %r3633, %r3628;
	// begin inline asm
	shf.r.clamp.b32 %r2123, %r2193, %r2193, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2127, %r2193, %r2193, %r2578;
	// end inline asm
	xor.b32  	%r3634, %r2127, %r2123;
	// begin inline asm
	shf.r.clamp.b32 %r2131, %r2193, %r2193, %r2582;
	// end inline asm
	xor.b32  	%r3635, %r3634, %r2131;
	and.b32  	%r3636, %r2193, %r2165;
	mov.u32 	%r2136, %r2193;
	// begin inline asm
	not.b32  %r2136, %r2136;     
	and.b32  %r2135, %r2136, %r2137; 
	
	// end inline asm
	xor.b32  	%r3637, %r2135, %r3636;
	add.s32 	%r3638, %r781, %r2109;
	add.s32 	%r3639, %r3638, %r3635;
	add.s32 	%r3640, %r3639, %r3637;
	add.s32 	%r3641, %r3640, 275423344;
	add.s32 	%r2221, %r3641, %r2065;
	// begin inline asm
	shf.r.clamp.b32 %r2139, %r2149, %r2149, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2143, %r2149, %r2149, %r2594;
	// end inline asm
	xor.b32  	%r3642, %r2143, %r2139;
	// begin inline asm
	shf.r.clamp.b32 %r2147, %r2149, %r2149, %r2598;
	// end inline asm
	xor.b32  	%r3643, %r3642, %r2147;
	xor.b32  	%r3644, %r2121, %r2093;
	and.b32  	%r3645, %r2149, %r3644;
	and.b32  	%r3646, %r2121, %r2093;
	xor.b32  	%r3647, %r3645, %r3646;
	add.s32 	%r3648, %r3641, %r3647;
	add.s32 	%r2177, %r3648, %r3643;
	// begin inline asm
	shf.r.clamp.b32 %r2151, %r2221, %r2221, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2155, %r2221, %r2221, %r2578;
	// end inline asm
	xor.b32  	%r3649, %r2155, %r2151;
	// begin inline asm
	shf.r.clamp.b32 %r2159, %r2221, %r2221, %r2582;
	// end inline asm
	xor.b32  	%r3650, %r3649, %r2159;
	and.b32  	%r3651, %r2221, %r2193;
	mov.u32 	%r2164, %r2221;
	// begin inline asm
	not.b32  %r2164, %r2164;     
	and.b32  %r2163, %r2164, %r2165; 
	
	// end inline asm
	xor.b32  	%r3652, %r2163, %r3651;
	add.s32 	%r3653, %r797, %r2137;
	add.s32 	%r3654, %r3653, %r3650;
	add.s32 	%r3655, %r3654, %r3652;
	add.s32 	%r3656, %r3655, 430227734;
	add.s32 	%r2249, %r3656, %r2093;
	// begin inline asm
	shf.r.clamp.b32 %r2167, %r2177, %r2177, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2171, %r2177, %r2177, %r2594;
	// end inline asm
	xor.b32  	%r3657, %r2171, %r2167;
	// begin inline asm
	shf.r.clamp.b32 %r2175, %r2177, %r2177, %r2598;
	// end inline asm
	xor.b32  	%r3658, %r3657, %r2175;
	xor.b32  	%r3659, %r2149, %r2121;
	and.b32  	%r3660, %r2177, %r3659;
	and.b32  	%r3661, %r2149, %r2121;
	xor.b32  	%r3662, %r3660, %r3661;
	add.s32 	%r3663, %r3656, %r3662;
	add.s32 	%r2205, %r3663, %r3658;
	// begin inline asm
	shf.r.clamp.b32 %r2179, %r2249, %r2249, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2183, %r2249, %r2249, %r2578;
	// end inline asm
	xor.b32  	%r3664, %r2183, %r2179;
	// begin inline asm
	shf.r.clamp.b32 %r2187, %r2249, %r2249, %r2582;
	// end inline asm
	xor.b32  	%r3665, %r3664, %r2187;
	and.b32  	%r3666, %r2249, %r2221;
	mov.u32 	%r2192, %r2249;
	// begin inline asm
	not.b32  %r2192, %r2192;     
	and.b32  %r2191, %r2192, %r2193; 
	
	// end inline asm
	xor.b32  	%r3667, %r2191, %r3666;
	add.s32 	%r3668, %r613, %r2165;
	add.s32 	%r3669, %r3668, %r3665;
	add.s32 	%r3670, %r3669, %r3667;
	add.s32 	%r3671, %r3670, 506948616;
	add.s32 	%r2277, %r3671, %r2121;
	// begin inline asm
	shf.r.clamp.b32 %r2195, %r2205, %r2205, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2199, %r2205, %r2205, %r2594;
	// end inline asm
	xor.b32  	%r3672, %r2199, %r2195;
	// begin inline asm
	shf.r.clamp.b32 %r2203, %r2205, %r2205, %r2598;
	// end inline asm
	xor.b32  	%r3673, %r3672, %r2203;
	xor.b32  	%r3674, %r2177, %r2149;
	and.b32  	%r3675, %r2205, %r3674;
	and.b32  	%r3676, %r2177, %r2149;
	xor.b32  	%r3677, %r3675, %r3676;
	add.s32 	%r3678, %r3671, %r3677;
	add.s32 	%r2233, %r3678, %r3673;
	// begin inline asm
	shf.r.clamp.b32 %r2207, %r2277, %r2277, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2211, %r2277, %r2277, %r2578;
	// end inline asm
	xor.b32  	%r3679, %r2211, %r2207;
	// begin inline asm
	shf.r.clamp.b32 %r2215, %r2277, %r2277, %r2582;
	// end inline asm
	xor.b32  	%r3680, %r3679, %r2215;
	and.b32  	%r3681, %r2277, %r2249;
	mov.u32 	%r2220, %r2277;
	// begin inline asm
	not.b32  %r2220, %r2220;     
	and.b32  %r2219, %r2220, %r2221; 
	
	// end inline asm
	xor.b32  	%r3682, %r2219, %r3681;
	add.s32 	%r3683, %r629, %r2193;
	add.s32 	%r3684, %r3683, %r3680;
	add.s32 	%r3685, %r3684, %r3682;
	add.s32 	%r3686, %r3685, 659060556;
	add.s32 	%r2305, %r3686, %r2149;
	// begin inline asm
	shf.r.clamp.b32 %r2223, %r2233, %r2233, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2227, %r2233, %r2233, %r2594;
	// end inline asm
	xor.b32  	%r3687, %r2227, %r2223;
	// begin inline asm
	shf.r.clamp.b32 %r2231, %r2233, %r2233, %r2598;
	// end inline asm
	xor.b32  	%r3688, %r3687, %r2231;
	xor.b32  	%r3689, %r2205, %r2177;
	and.b32  	%r3690, %r2233, %r3689;
	and.b32  	%r3691, %r2205, %r2177;
	xor.b32  	%r3692, %r3690, %r3691;
	add.s32 	%r3693, %r3686, %r3692;
	add.s32 	%r2261, %r3693, %r3688;
	// begin inline asm
	shf.r.clamp.b32 %r2235, %r2305, %r2305, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2239, %r2305, %r2305, %r2578;
	// end inline asm
	xor.b32  	%r3694, %r2239, %r2235;
	// begin inline asm
	shf.r.clamp.b32 %r2243, %r2305, %r2305, %r2582;
	// end inline asm
	xor.b32  	%r3695, %r3694, %r2243;
	and.b32  	%r3696, %r2305, %r2277;
	mov.u32 	%r2248, %r2305;
	// begin inline asm
	not.b32  %r2248, %r2248;     
	and.b32  %r2247, %r2248, %r2249; 
	
	// end inline asm
	xor.b32  	%r3697, %r2247, %r3696;
	add.s32 	%r3698, %r645, %r2221;
	add.s32 	%r3699, %r3698, %r3695;
	add.s32 	%r3700, %r3699, %r3697;
	add.s32 	%r3701, %r3700, 883997877;
	add.s32 	%r2333, %r3701, %r2177;
	// begin inline asm
	shf.r.clamp.b32 %r2251, %r2261, %r2261, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2255, %r2261, %r2261, %r2594;
	// end inline asm
	xor.b32  	%r3702, %r2255, %r2251;
	// begin inline asm
	shf.r.clamp.b32 %r2259, %r2261, %r2261, %r2598;
	// end inline asm
	xor.b32  	%r3703, %r3702, %r2259;
	xor.b32  	%r3704, %r2233, %r2205;
	and.b32  	%r3705, %r2261, %r3704;
	and.b32  	%r3706, %r2233, %r2205;
	xor.b32  	%r3707, %r3705, %r3706;
	add.s32 	%r3708, %r3701, %r3707;
	add.s32 	%r2289, %r3708, %r3703;
	// begin inline asm
	shf.r.clamp.b32 %r2263, %r2333, %r2333, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2267, %r2333, %r2333, %r2578;
	// end inline asm
	xor.b32  	%r3709, %r2267, %r2263;
	// begin inline asm
	shf.r.clamp.b32 %r2271, %r2333, %r2333, %r2582;
	// end inline asm
	xor.b32  	%r3710, %r3709, %r2271;
	and.b32  	%r3711, %r2333, %r2305;
	mov.u32 	%r2276, %r2333;
	// begin inline asm
	not.b32  %r2276, %r2276;     
	and.b32  %r2275, %r2276, %r2277; 
	
	// end inline asm
	xor.b32  	%r3712, %r2275, %r3711;
	add.s32 	%r3713, %r661, %r2249;
	add.s32 	%r3714, %r3713, %r3710;
	add.s32 	%r3715, %r3714, %r3712;
	add.s32 	%r3716, %r3715, 958139571;
	add.s32 	%r2361, %r3716, %r2205;
	// begin inline asm
	shf.r.clamp.b32 %r2279, %r2289, %r2289, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2283, %r2289, %r2289, %r2594;
	// end inline asm
	xor.b32  	%r3717, %r2283, %r2279;
	// begin inline asm
	shf.r.clamp.b32 %r2287, %r2289, %r2289, %r2598;
	// end inline asm
	xor.b32  	%r3718, %r3717, %r2287;
	xor.b32  	%r3719, %r2261, %r2233;
	and.b32  	%r3720, %r2289, %r3719;
	and.b32  	%r3721, %r2261, %r2233;
	xor.b32  	%r3722, %r3720, %r3721;
	add.s32 	%r3723, %r3716, %r3722;
	add.s32 	%r2317, %r3723, %r3718;
	// begin inline asm
	shf.r.clamp.b32 %r2291, %r2361, %r2361, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2295, %r2361, %r2361, %r2578;
	// end inline asm
	xor.b32  	%r3724, %r2295, %r2291;
	// begin inline asm
	shf.r.clamp.b32 %r2299, %r2361, %r2361, %r2582;
	// end inline asm
	xor.b32  	%r3725, %r3724, %r2299;
	and.b32  	%r3726, %r2361, %r2333;
	mov.u32 	%r2304, %r2361;
	// begin inline asm
	not.b32  %r2304, %r2304;     
	and.b32  %r2303, %r2304, %r2305; 
	
	// end inline asm
	xor.b32  	%r3727, %r2303, %r3726;
	add.s32 	%r3728, %r677, %r2277;
	add.s32 	%r3729, %r3728, %r3725;
	add.s32 	%r3730, %r3729, %r3727;
	add.s32 	%r3731, %r3730, 1322822218;
	add.s32 	%r2389, %r3731, %r2233;
	// begin inline asm
	shf.r.clamp.b32 %r2307, %r2317, %r2317, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2311, %r2317, %r2317, %r2594;
	// end inline asm
	xor.b32  	%r3732, %r2311, %r2307;
	// begin inline asm
	shf.r.clamp.b32 %r2315, %r2317, %r2317, %r2598;
	// end inline asm
	xor.b32  	%r3733, %r3732, %r2315;
	xor.b32  	%r3734, %r2289, %r2261;
	and.b32  	%r3735, %r2317, %r3734;
	and.b32  	%r3736, %r2289, %r2261;
	xor.b32  	%r3737, %r3735, %r3736;
	add.s32 	%r3738, %r3731, %r3737;
	add.s32 	%r2345, %r3738, %r3733;
	// begin inline asm
	shf.r.clamp.b32 %r2319, %r2389, %r2389, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2323, %r2389, %r2389, %r2578;
	// end inline asm
	xor.b32  	%r3739, %r2323, %r2319;
	// begin inline asm
	shf.r.clamp.b32 %r2327, %r2389, %r2389, %r2582;
	// end inline asm
	xor.b32  	%r3740, %r3739, %r2327;
	and.b32  	%r3741, %r2389, %r2361;
	mov.u32 	%r2332, %r2389;
	// begin inline asm
	not.b32  %r2332, %r2332;     
	and.b32  %r2331, %r2332, %r2333; 
	
	// end inline asm
	xor.b32  	%r3742, %r2331, %r3741;
	add.s32 	%r3743, %r693, %r2305;
	add.s32 	%r3744, %r3743, %r3740;
	add.s32 	%r3745, %r3744, %r3742;
	add.s32 	%r3746, %r3745, 1537002063;
	add.s32 	%r2417, %r3746, %r2261;
	// begin inline asm
	shf.r.clamp.b32 %r2335, %r2345, %r2345, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2339, %r2345, %r2345, %r2594;
	// end inline asm
	xor.b32  	%r3747, %r2339, %r2335;
	// begin inline asm
	shf.r.clamp.b32 %r2343, %r2345, %r2345, %r2598;
	// end inline asm
	xor.b32  	%r3748, %r3747, %r2343;
	xor.b32  	%r3749, %r2317, %r2289;
	and.b32  	%r3750, %r2345, %r3749;
	and.b32  	%r3751, %r2317, %r2289;
	xor.b32  	%r3752, %r3750, %r3751;
	add.s32 	%r3753, %r3746, %r3752;
	add.s32 	%r2373, %r3753, %r3748;
	// begin inline asm
	shf.r.clamp.b32 %r2347, %r2417, %r2417, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2351, %r2417, %r2417, %r2578;
	// end inline asm
	xor.b32  	%r3754, %r2351, %r2347;
	// begin inline asm
	shf.r.clamp.b32 %r2355, %r2417, %r2417, %r2582;
	// end inline asm
	xor.b32  	%r3755, %r3754, %r2355;
	and.b32  	%r3756, %r2417, %r2389;
	mov.u32 	%r2360, %r2417;
	// begin inline asm
	not.b32  %r2360, %r2360;     
	and.b32  %r2359, %r2360, %r2361; 
	
	// end inline asm
	xor.b32  	%r3757, %r2359, %r3756;
	add.s32 	%r3758, %r709, %r2333;
	add.s32 	%r3759, %r3758, %r3755;
	add.s32 	%r3760, %r3759, %r3757;
	add.s32 	%r3761, %r3760, 1747873779;
	add.s32 	%r2445, %r3761, %r2289;
	// begin inline asm
	shf.r.clamp.b32 %r2363, %r2373, %r2373, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2367, %r2373, %r2373, %r2594;
	// end inline asm
	xor.b32  	%r3762, %r2367, %r2363;
	// begin inline asm
	shf.r.clamp.b32 %r2371, %r2373, %r2373, %r2598;
	// end inline asm
	xor.b32  	%r3763, %r3762, %r2371;
	xor.b32  	%r3764, %r2345, %r2317;
	and.b32  	%r3765, %r2373, %r3764;
	and.b32  	%r3766, %r2345, %r2317;
	xor.b32  	%r3767, %r3765, %r3766;
	add.s32 	%r3768, %r3761, %r3767;
	add.s32 	%r2401, %r3768, %r3763;
	// begin inline asm
	shf.r.clamp.b32 %r2375, %r2445, %r2445, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2379, %r2445, %r2445, %r2578;
	// end inline asm
	xor.b32  	%r3769, %r2379, %r2375;
	// begin inline asm
	shf.r.clamp.b32 %r2383, %r2445, %r2445, %r2582;
	// end inline asm
	xor.b32  	%r3770, %r3769, %r2383;
	and.b32  	%r3771, %r2445, %r2417;
	mov.u32 	%r2388, %r2445;
	// begin inline asm
	not.b32  %r2388, %r2388;     
	and.b32  %r2387, %r2388, %r2389; 
	
	// end inline asm
	xor.b32  	%r3772, %r2387, %r3771;
	add.s32 	%r3773, %r725, %r2361;
	add.s32 	%r3774, %r3773, %r3770;
	add.s32 	%r3775, %r3774, %r3772;
	add.s32 	%r3776, %r3775, 1955562222;
	add.s32 	%r2473, %r3776, %r2317;
	// begin inline asm
	shf.r.clamp.b32 %r2391, %r2401, %r2401, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2395, %r2401, %r2401, %r2594;
	// end inline asm
	xor.b32  	%r3777, %r2395, %r2391;
	// begin inline asm
	shf.r.clamp.b32 %r2399, %r2401, %r2401, %r2598;
	// end inline asm
	xor.b32  	%r3778, %r3777, %r2399;
	xor.b32  	%r3779, %r2373, %r2345;
	and.b32  	%r3780, %r2401, %r3779;
	and.b32  	%r3781, %r2373, %r2345;
	xor.b32  	%r3782, %r3780, %r3781;
	add.s32 	%r3783, %r3776, %r3782;
	add.s32 	%r2429, %r3783, %r3778;
	// begin inline asm
	shf.r.clamp.b32 %r2403, %r2473, %r2473, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2407, %r2473, %r2473, %r2578;
	// end inline asm
	xor.b32  	%r3784, %r2407, %r2403;
	// begin inline asm
	shf.r.clamp.b32 %r2411, %r2473, %r2473, %r2582;
	// end inline asm
	xor.b32  	%r3785, %r3784, %r2411;
	and.b32  	%r3786, %r2473, %r2445;
	mov.u32 	%r2416, %r2473;
	// begin inline asm
	not.b32  %r2416, %r2416;     
	and.b32  %r2415, %r2416, %r2417; 
	
	// end inline asm
	xor.b32  	%r3787, %r2415, %r3786;
	add.s32 	%r3788, %r741, %r2389;
	add.s32 	%r3789, %r3788, %r3785;
	add.s32 	%r3790, %r3789, %r3787;
	add.s32 	%r3791, %r3790, 2024104815;
	add.s32 	%r2501, %r3791, %r2345;
	// begin inline asm
	shf.r.clamp.b32 %r2419, %r2429, %r2429, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2423, %r2429, %r2429, %r2594;
	// end inline asm
	xor.b32  	%r3792, %r2423, %r2419;
	// begin inline asm
	shf.r.clamp.b32 %r2427, %r2429, %r2429, %r2598;
	// end inline asm
	xor.b32  	%r3793, %r3792, %r2427;
	xor.b32  	%r3794, %r2401, %r2373;
	and.b32  	%r3795, %r2429, %r3794;
	and.b32  	%r3796, %r2401, %r2373;
	xor.b32  	%r3797, %r3795, %r3796;
	add.s32 	%r3798, %r3791, %r3797;
	add.s32 	%r2457, %r3798, %r3793;
	// begin inline asm
	shf.r.clamp.b32 %r2431, %r2501, %r2501, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2435, %r2501, %r2501, %r2578;
	// end inline asm
	xor.b32  	%r3799, %r2435, %r2431;
	// begin inline asm
	shf.r.clamp.b32 %r2439, %r2501, %r2501, %r2582;
	// end inline asm
	xor.b32  	%r3800, %r3799, %r2439;
	and.b32  	%r3801, %r2501, %r2473;
	mov.u32 	%r2444, %r2501;
	// begin inline asm
	not.b32  %r2444, %r2444;     
	and.b32  %r2443, %r2444, %r2445; 
	
	// end inline asm
	xor.b32  	%r3802, %r2443, %r3801;
	add.s32 	%r3803, %r757, %r2417;
	add.s32 	%r3804, %r3803, %r3800;
	add.s32 	%r3805, %r3804, %r3802;
	add.s32 	%r3806, %r3805, -2067236844;
	add.s32 	%r2529, %r3806, %r2373;
	// begin inline asm
	shf.r.clamp.b32 %r2447, %r2457, %r2457, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2451, %r2457, %r2457, %r2594;
	// end inline asm
	xor.b32  	%r3807, %r2451, %r2447;
	// begin inline asm
	shf.r.clamp.b32 %r2455, %r2457, %r2457, %r2598;
	// end inline asm
	xor.b32  	%r3808, %r3807, %r2455;
	xor.b32  	%r3809, %r2429, %r2401;
	and.b32  	%r3810, %r2457, %r3809;
	and.b32  	%r3811, %r2429, %r2401;
	xor.b32  	%r3812, %r3810, %r3811;
	add.s32 	%r3813, %r3806, %r3812;
	add.s32 	%r2485, %r3813, %r3808;
	// begin inline asm
	shf.r.clamp.b32 %r2459, %r2529, %r2529, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2463, %r2529, %r2529, %r2578;
	// end inline asm
	xor.b32  	%r3814, %r2463, %r2459;
	// begin inline asm
	shf.r.clamp.b32 %r2467, %r2529, %r2529, %r2582;
	// end inline asm
	xor.b32  	%r3815, %r3814, %r2467;
	and.b32  	%r3816, %r2529, %r2501;
	mov.u32 	%r2472, %r2529;
	// begin inline asm
	not.b32  %r2472, %r2472;     
	and.b32  %r2471, %r2472, %r2473; 
	
	// end inline asm
	xor.b32  	%r3817, %r2471, %r3816;
	add.s32 	%r3818, %r773, %r2445;
	add.s32 	%r3819, %r3818, %r3815;
	add.s32 	%r3820, %r3819, %r3817;
	add.s32 	%r3821, %r3820, -1933114872;
	add.s32 	%r2557, %r3821, %r2401;
	// begin inline asm
	shf.r.clamp.b32 %r2475, %r2485, %r2485, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2479, %r2485, %r2485, %r2594;
	// end inline asm
	xor.b32  	%r3822, %r2479, %r2475;
	// begin inline asm
	shf.r.clamp.b32 %r2483, %r2485, %r2485, %r2598;
	// end inline asm
	xor.b32  	%r3823, %r3822, %r2483;
	xor.b32  	%r3824, %r2457, %r2429;
	and.b32  	%r3825, %r2485, %r3824;
	and.b32  	%r3826, %r2457, %r2429;
	xor.b32  	%r3827, %r3825, %r3826;
	add.s32 	%r3828, %r3821, %r3827;
	add.s32 	%r2513, %r3828, %r3823;
	// begin inline asm
	shf.r.clamp.b32 %r2487, %r2557, %r2557, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2491, %r2557, %r2557, %r2578;
	// end inline asm
	xor.b32  	%r3829, %r2491, %r2487;
	// begin inline asm
	shf.r.clamp.b32 %r2495, %r2557, %r2557, %r2582;
	// end inline asm
	xor.b32  	%r3830, %r3829, %r2495;
	and.b32  	%r3831, %r2557, %r2529;
	mov.u32 	%r2500, %r2557;
	// begin inline asm
	not.b32  %r2500, %r2500;     
	and.b32  %r2499, %r2500, %r2501; 
	
	// end inline asm
	xor.b32  	%r3832, %r2499, %r3831;
	add.s32 	%r3833, %r789, %r2473;
	add.s32 	%r3834, %r3833, %r3830;
	add.s32 	%r3835, %r3834, %r3832;
	add.s32 	%r3836, %r3835, -1866530822;
	add.s32 	%r2585, %r3836, %r2429;
	// begin inline asm
	shf.r.clamp.b32 %r2503, %r2513, %r2513, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2507, %r2513, %r2513, %r2594;
	// end inline asm
	xor.b32  	%r3837, %r2507, %r2503;
	// begin inline asm
	shf.r.clamp.b32 %r2511, %r2513, %r2513, %r2598;
	// end inline asm
	xor.b32  	%r3838, %r3837, %r2511;
	xor.b32  	%r3839, %r2485, %r2457;
	and.b32  	%r3840, %r2513, %r3839;
	and.b32  	%r3841, %r2485, %r2457;
	xor.b32  	%r3842, %r3840, %r3841;
	add.s32 	%r3843, %r3836, %r3842;
	add.s32 	%r2541, %r3843, %r3838;
	// begin inline asm
	shf.r.clamp.b32 %r2515, %r2585, %r2585, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2519, %r2585, %r2585, %r2578;
	// end inline asm
	xor.b32  	%r3844, %r2519, %r2515;
	// begin inline asm
	shf.r.clamp.b32 %r2523, %r2585, %r2585, %r2582;
	// end inline asm
	xor.b32  	%r3845, %r3844, %r2523;
	and.b32  	%r3846, %r2585, %r2557;
	mov.u32 	%r2528, %r2585;
	// begin inline asm
	not.b32  %r2528, %r2528;     
	and.b32  %r2527, %r2528, %r2529; 
	
	// end inline asm
	xor.b32  	%r3847, %r2527, %r3846;
	add.s32 	%r3848, %r805, %r2501;
	add.s32 	%r3849, %r3848, %r3845;
	add.s32 	%r3850, %r3849, %r3847;
	add.s32 	%r3851, %r3850, -1538233109;
	add.s32 	%r2558, %r3851, %r2457;
	// begin inline asm
	shf.r.clamp.b32 %r2531, %r2541, %r2541, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2535, %r2541, %r2541, %r2594;
	// end inline asm
	xor.b32  	%r3852, %r2535, %r2531;
	// begin inline asm
	shf.r.clamp.b32 %r2539, %r2541, %r2541, %r2598;
	// end inline asm
	xor.b32  	%r3853, %r3852, %r2539;
	xor.b32  	%r3854, %r2513, %r2485;
	and.b32  	%r3855, %r2541, %r3854;
	and.b32  	%r3856, %r2513, %r2485;
	xor.b32  	%r3857, %r3855, %r3856;
	add.s32 	%r3858, %r3851, %r3857;
	add.s32 	%r2569, %r3858, %r3853;
	// begin inline asm
	shf.r.clamp.b32 %r2543, %r2558, %r2558, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2547, %r2558, %r2558, %r2578;
	// end inline asm
	xor.b32  	%r3859, %r2547, %r2543;
	// begin inline asm
	shf.r.clamp.b32 %r2551, %r2558, %r2558, %r2582;
	// end inline asm
	xor.b32  	%r3860, %r3859, %r2551;
	and.b32  	%r3861, %r2558, %r2585;
	mov.u32 	%r2556, %r2558;
	// begin inline asm
	not.b32  %r2556, %r2556;     
	and.b32  %r2555, %r2556, %r2557; 
	
	// end inline asm
	xor.b32  	%r3862, %r2555, %r3861;
	add.s32 	%r3863, %r765, %r709;
	add.s32 	%r3864, %r3863, %r2939;
	add.s32 	%r3865, %r3864, %r2942;
	add.s32 	%r3866, %r3865, %r2529;
	add.s32 	%r3867, %r3866, %r3860;
	add.s32 	%r3868, %r3867, %r3862;
	add.s32 	%r3869, %r3868, -1090935817;
	add.s32 	%r2586, %r3869, %r2485;
	// begin inline asm
	shf.r.clamp.b32 %r2559, %r2569, %r2569, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2563, %r2569, %r2569, %r2594;
	// end inline asm
	xor.b32  	%r3870, %r2563, %r2559;
	// begin inline asm
	shf.r.clamp.b32 %r2567, %r2569, %r2569, %r2598;
	// end inline asm
	xor.b32  	%r3871, %r3870, %r2567;
	xor.b32  	%r3872, %r2541, %r2513;
	and.b32  	%r3873, %r2569, %r3872;
	and.b32  	%r3874, %r2541, %r2513;
	xor.b32  	%r3875, %r3873, %r3874;
	add.s32 	%r3876, %r3869, %r3875;
	add.s32 	%r2597, %r3876, %r3871;
	// begin inline asm
	shf.r.clamp.b32 %r2571, %r2586, %r2586, %r2574;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2575, %r2586, %r2586, %r2578;
	// end inline asm
	xor.b32  	%r3877, %r2575, %r2571;
	// begin inline asm
	shf.r.clamp.b32 %r2579, %r2586, %r2586, %r2582;
	// end inline asm
	xor.b32  	%r3878, %r3877, %r2579;
	and.b32  	%r3879, %r2586, %r2558;
	mov.u32 	%r2584, %r2586;
	// begin inline asm
	not.b32  %r2584, %r2584;     
	and.b32  %r2583, %r2584, %r2585; 
	
	// end inline asm
	xor.b32  	%r3880, %r2583, %r3879;
	add.s32 	%r3881, %r781, %r725;
	add.s32 	%r3882, %r3881, %r2945;
	add.s32 	%r3883, %r3882, %r2948;
	add.s32 	%r3884, %r3883, %r2557;
	add.s32 	%r3885, %r3884, %r3878;
	add.s32 	%r3886, %r3885, %r3880;
	add.s32 	%r3887, %r3886, -965641998;
	// begin inline asm
	shf.r.clamp.b32 %r2587, %r2597, %r2597, %r2590;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2591, %r2597, %r2597, %r2594;
	// end inline asm
	xor.b32  	%r3888, %r2591, %r2587;
	// begin inline asm
	shf.r.clamp.b32 %r2595, %r2597, %r2597, %r2598;
	// end inline asm
	xor.b32  	%r3889, %r3888, %r2595;
	xor.b32  	%r3890, %r2569, %r2541;
	and.b32  	%r3891, %r2597, %r3890;
	and.b32  	%r3892, %r2569, %r2541;
	xor.b32  	%r3893, %r3891, %r3892;
	add.s32 	%r3894, %r3893, %r3887;
	add.s32 	%r3895, %r3894, %r3889;
	add.s32 	%r3913, %r3895, 1779033703;
	add.s32 	%r3912, %r2597, -1150833019;
	add.s32 	%r3911, %r2569, 1013904242;
	add.s32 	%r3910, %r2541, -1521486534;
	add.s32 	%r3896, %r2513, %r3887;
	add.s32 	%r3909, %r3896, 1359893119;
	add.s32 	%r3914, %r2586, -1694144372;
	add.s32 	%r3915, %r2558, 528734635;
	add.s32 	%r3916, %r2585, 1541459225;
	add.s32 	%r3900, %r3900, 1;
	setp.lt.s32 	%p2, %r3900, %r3897;
	@%p2 bra 	LBB0_2;

LBB0_3:
	mov.u32 	%r3899, %tid.x;
	shl.b32 	%r3898, %r3899, 3;
	mul.wide.s32 	%rd10, %r3898, 4;
	ld.param.u64 	%rd9, [sha256_iter_param_2];
	cvta.to.global.u64 	%rd6, %rd9;
	add.s64 	%rd8, %rd6, %rd10;
	st.global.u32 	[%rd8], %r3913;
	st.global.u32 	[%rd8+4], %r3912;
	st.global.u32 	[%rd8+8], %r3911;
	st.global.u32 	[%rd8+12], %r3910;
	st.global.u32 	[%rd8+16], %r3909;
	st.global.u32 	[%rd8+20], %r3914;
	st.global.u32 	[%rd8+24], %r3915;
	st.global.u32 	[%rd8+28], %r3916;
	ret;

}
	// .globl	sha256TestKernel
.visible .entry sha256TestKernel(
	.param .u64 sha256TestKernel_param_0,
	.param .u32 sha256TestKernel_param_1,
	.param .u32 sha256TestKernel_param_2,
	.param .u32 sha256TestKernel_param_3,
	.param .u32 sha256TestKernel_param_4,
	.param .u32 sha256TestKernel_param_5,
	.param .u32 sha256TestKernel_param_6,
	.param .u32 sha256TestKernel_param_7,
	.param .u32 sha256TestKernel_param_8,
	.param .u32 sha256TestKernel_param_9,
	.param .u32 sha256TestKernel_param_10,
	.param .u32 sha256TestKernel_param_11,
	.param .u32 sha256TestKernel_param_12,
	.param .u32 sha256TestKernel_param_13,
	.param .u32 sha256TestKernel_param_14,
	.param .u32 sha256TestKernel_param_15,
	.param .u32 sha256TestKernel_param_16
)
.maxntid 128, 1, 1
.minnctapersm 1
{
	.reg .b32 	%r<4020>;
	.reg .b64 	%rd<3>;


	ld.param.u64 	%rd1, [sha256TestKernel_param_0];
	cvta.to.global.u64 	%rd2, %rd1;
	ld.param.u32 	%r3984, [sha256TestKernel_param_2];
	mov.u32 	%r756, 7;
	// begin inline asm
	shf.r.clamp.b32 %r1, %r3984, %r3984, %r756;
	// end inline asm
	mov.u32 	%r760, 18;
	// begin inline asm
	shf.r.clamp.b32 %r5, %r3984, %r3984, %r760;
	// end inline asm
	shr.u32 	%r2562, %r3984, 3;
	xor.b32  	%r2563, %r1, %r2562;
	xor.b32  	%r2564, %r2563, %r5;
	ld.param.u32 	%r3983, [sha256TestKernel_param_15];
	mov.u32 	%r764, 17;
	// begin inline asm
	shf.r.clamp.b32 %r9, %r3983, %r3983, %r764;
	// end inline asm
	mov.u32 	%r768, 19;
	// begin inline asm
	shf.r.clamp.b32 %r13, %r3983, %r3983, %r768;
	// end inline asm
	shr.u32 	%r2565, %r3983, 10;
	xor.b32  	%r2566, %r9, %r2565;
	xor.b32  	%r2567, %r2566, %r13;
	ld.param.u32 	%r3982, [sha256TestKernel_param_10];
	ld.param.u32 	%r3981, [sha256TestKernel_param_1];
	add.s32 	%r2568, %r3982, %r3981;
	add.s32 	%r2569, %r2568, %r2564;
	add.s32 	%r247, %r2569, %r2567;
	ld.param.u32 	%r3980, [sha256TestKernel_param_3];
	// begin inline asm
	shf.r.clamp.b32 %r17, %r3980, %r3980, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r21, %r3980, %r3980, %r760;
	// end inline asm
	shr.u32 	%r2570, %r3980, 3;
	xor.b32  	%r2571, %r17, %r2570;
	xor.b32  	%r2572, %r2571, %r21;
	ld.param.u32 	%r3979, [sha256TestKernel_param_16];
	// begin inline asm
	shf.r.clamp.b32 %r25, %r3979, %r3979, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r29, %r3979, %r3979, %r768;
	// end inline asm
	shr.u32 	%r2573, %r3979, 10;
	xor.b32  	%r2574, %r25, %r2573;
	xor.b32  	%r2575, %r2574, %r29;
	ld.param.u32 	%r3978, [sha256TestKernel_param_11];
	add.s32 	%r2576, %r3978, %r3984;
	add.s32 	%r2577, %r2576, %r2572;
	add.s32 	%r263, %r2577, %r2575;
	ld.param.u32 	%r3977, [sha256TestKernel_param_4];
	// begin inline asm
	shf.r.clamp.b32 %r33, %r3977, %r3977, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r37, %r3977, %r3977, %r760;
	// end inline asm
	shr.u32 	%r2578, %r3977, 3;
	xor.b32  	%r2579, %r33, %r2578;
	xor.b32  	%r2580, %r2579, %r37;
	// begin inline asm
	shf.r.clamp.b32 %r41, %r247, %r247, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r45, %r247, %r247, %r768;
	// end inline asm
	shr.u32 	%r2581, %r247, 10;
	xor.b32  	%r2582, %r41, %r2581;
	xor.b32  	%r2583, %r2582, %r45;
	ld.param.u32 	%r3976, [sha256TestKernel_param_12];
	add.s32 	%r2584, %r3976, %r3980;
	add.s32 	%r2585, %r2584, %r2580;
	add.s32 	%r279, %r2585, %r2583;
	ld.param.u32 	%r3975, [sha256TestKernel_param_5];
	// begin inline asm
	shf.r.clamp.b32 %r49, %r3975, %r3975, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r53, %r3975, %r3975, %r760;
	// end inline asm
	shr.u32 	%r2586, %r3975, 3;
	xor.b32  	%r2587, %r49, %r2586;
	xor.b32  	%r2588, %r2587, %r53;
	// begin inline asm
	shf.r.clamp.b32 %r57, %r263, %r263, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r61, %r263, %r263, %r768;
	// end inline asm
	shr.u32 	%r2589, %r263, 10;
	xor.b32  	%r2590, %r57, %r2589;
	xor.b32  	%r2591, %r2590, %r61;
	ld.param.u32 	%r3974, [sha256TestKernel_param_13];
	add.s32 	%r2592, %r3974, %r3977;
	add.s32 	%r2593, %r2592, %r2588;
	add.s32 	%r295, %r2593, %r2591;
	ld.param.u32 	%r3973, [sha256TestKernel_param_6];
	// begin inline asm
	shf.r.clamp.b32 %r65, %r3973, %r3973, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r69, %r3973, %r3973, %r760;
	// end inline asm
	shr.u32 	%r2594, %r3973, 3;
	xor.b32  	%r2595, %r65, %r2594;
	xor.b32  	%r2596, %r2595, %r69;
	// begin inline asm
	shf.r.clamp.b32 %r73, %r279, %r279, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r77, %r279, %r279, %r768;
	// end inline asm
	shr.u32 	%r2597, %r279, 10;
	xor.b32  	%r2598, %r73, %r2597;
	xor.b32  	%r2599, %r2598, %r77;
	ld.param.u32 	%r3972, [sha256TestKernel_param_14];
	add.s32 	%r2600, %r3972, %r3975;
	add.s32 	%r2601, %r2600, %r2596;
	add.s32 	%r311, %r2601, %r2599;
	ld.param.u32 	%r3971, [sha256TestKernel_param_7];
	// begin inline asm
	shf.r.clamp.b32 %r81, %r3971, %r3971, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r85, %r3971, %r3971, %r760;
	// end inline asm
	shr.u32 	%r2602, %r3971, 3;
	xor.b32  	%r2603, %r81, %r2602;
	xor.b32  	%r2604, %r2603, %r85;
	// begin inline asm
	shf.r.clamp.b32 %r89, %r295, %r295, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r93, %r295, %r295, %r768;
	// end inline asm
	shr.u32 	%r2605, %r295, 10;
	xor.b32  	%r2606, %r89, %r2605;
	xor.b32  	%r2607, %r2606, %r93;
	add.s32 	%r2608, %r3983, %r3973;
	add.s32 	%r2609, %r2608, %r2604;
	add.s32 	%r327, %r2609, %r2607;
	ld.param.u32 	%r3970, [sha256TestKernel_param_8];
	// begin inline asm
	shf.r.clamp.b32 %r97, %r3970, %r3970, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r101, %r3970, %r3970, %r760;
	// end inline asm
	shr.u32 	%r2610, %r3970, 3;
	xor.b32  	%r2611, %r97, %r2610;
	xor.b32  	%r2612, %r2611, %r101;
	// begin inline asm
	shf.r.clamp.b32 %r105, %r311, %r311, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r109, %r311, %r311, %r768;
	// end inline asm
	shr.u32 	%r2613, %r311, 10;
	xor.b32  	%r2614, %r105, %r2613;
	xor.b32  	%r2615, %r2614, %r109;
	add.s32 	%r2616, %r3979, %r3971;
	add.s32 	%r2617, %r2616, %r2612;
	add.s32 	%r343, %r2617, %r2615;
	ld.param.u32 	%r3969, [sha256TestKernel_param_9];
	// begin inline asm
	shf.r.clamp.b32 %r113, %r3969, %r3969, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r117, %r3969, %r3969, %r760;
	// end inline asm
	shr.u32 	%r2618, %r3969, 3;
	xor.b32  	%r2619, %r113, %r2618;
	xor.b32  	%r2620, %r2619, %r117;
	// begin inline asm
	shf.r.clamp.b32 %r121, %r327, %r327, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r125, %r327, %r327, %r768;
	// end inline asm
	shr.u32 	%r2621, %r327, 10;
	xor.b32  	%r2622, %r121, %r2621;
	xor.b32  	%r2623, %r2622, %r125;
	add.s32 	%r2624, %r247, %r3970;
	add.s32 	%r2625, %r2624, %r2620;
	add.s32 	%r359, %r2625, %r2623;
	// begin inline asm
	shf.r.clamp.b32 %r129, %r3982, %r3982, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r133, %r3982, %r3982, %r760;
	// end inline asm
	shr.u32 	%r2626, %r3982, 3;
	xor.b32  	%r2627, %r129, %r2626;
	xor.b32  	%r2628, %r2627, %r133;
	// begin inline asm
	shf.r.clamp.b32 %r137, %r343, %r343, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r141, %r343, %r343, %r768;
	// end inline asm
	shr.u32 	%r2629, %r343, 10;
	xor.b32  	%r2630, %r137, %r2629;
	xor.b32  	%r2631, %r2630, %r141;
	add.s32 	%r2632, %r263, %r3969;
	add.s32 	%r2633, %r2632, %r2628;
	add.s32 	%r375, %r2633, %r2631;
	// begin inline asm
	shf.r.clamp.b32 %r145, %r3978, %r3978, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r149, %r3978, %r3978, %r760;
	// end inline asm
	shr.u32 	%r2634, %r3978, 3;
	xor.b32  	%r2635, %r145, %r2634;
	xor.b32  	%r2636, %r2635, %r149;
	// begin inline asm
	shf.r.clamp.b32 %r153, %r359, %r359, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r157, %r359, %r359, %r768;
	// end inline asm
	shr.u32 	%r2637, %r359, 10;
	xor.b32  	%r2638, %r153, %r2637;
	xor.b32  	%r2639, %r2638, %r157;
	add.s32 	%r2640, %r279, %r3982;
	add.s32 	%r2641, %r2640, %r2636;
	add.s32 	%r391, %r2641, %r2639;
	// begin inline asm
	shf.r.clamp.b32 %r161, %r3976, %r3976, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r165, %r3976, %r3976, %r760;
	// end inline asm
	shr.u32 	%r2642, %r3976, 3;
	xor.b32  	%r2643, %r161, %r2642;
	xor.b32  	%r2644, %r2643, %r165;
	// begin inline asm
	shf.r.clamp.b32 %r169, %r375, %r375, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r173, %r375, %r375, %r768;
	// end inline asm
	shr.u32 	%r2645, %r375, 10;
	xor.b32  	%r2646, %r169, %r2645;
	xor.b32  	%r2647, %r2646, %r173;
	add.s32 	%r2648, %r295, %r3978;
	add.s32 	%r2649, %r2648, %r2644;
	add.s32 	%r407, %r2649, %r2647;
	// begin inline asm
	shf.r.clamp.b32 %r177, %r3974, %r3974, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r181, %r3974, %r3974, %r760;
	// end inline asm
	shr.u32 	%r2650, %r3974, 3;
	xor.b32  	%r2651, %r177, %r2650;
	xor.b32  	%r2652, %r2651, %r181;
	// begin inline asm
	shf.r.clamp.b32 %r185, %r391, %r391, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r189, %r391, %r391, %r768;
	// end inline asm
	shr.u32 	%r2653, %r391, 10;
	xor.b32  	%r2654, %r185, %r2653;
	xor.b32  	%r2655, %r2654, %r189;
	add.s32 	%r2656, %r311, %r3976;
	add.s32 	%r2657, %r2656, %r2652;
	add.s32 	%r423, %r2657, %r2655;
	// begin inline asm
	shf.r.clamp.b32 %r193, %r3972, %r3972, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r197, %r3972, %r3972, %r760;
	// end inline asm
	shr.u32 	%r2658, %r3972, 3;
	xor.b32  	%r2659, %r193, %r2658;
	xor.b32  	%r2660, %r2659, %r197;
	// begin inline asm
	shf.r.clamp.b32 %r201, %r407, %r407, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r205, %r407, %r407, %r768;
	// end inline asm
	shr.u32 	%r2661, %r407, 10;
	xor.b32  	%r2662, %r201, %r2661;
	xor.b32  	%r2663, %r2662, %r205;
	add.s32 	%r2664, %r327, %r3974;
	add.s32 	%r2665, %r2664, %r2660;
	add.s32 	%r439, %r2665, %r2663;
	// begin inline asm
	shf.r.clamp.b32 %r209, %r3983, %r3983, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r213, %r3983, %r3983, %r760;
	// end inline asm
	shr.u32 	%r2666, %r3983, 3;
	xor.b32  	%r2667, %r209, %r2666;
	xor.b32  	%r2668, %r2667, %r213;
	// begin inline asm
	shf.r.clamp.b32 %r217, %r423, %r423, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r221, %r423, %r423, %r768;
	// end inline asm
	shr.u32 	%r2669, %r423, 10;
	xor.b32  	%r2670, %r217, %r2669;
	xor.b32  	%r2671, %r2670, %r221;
	add.s32 	%r2672, %r343, %r3972;
	add.s32 	%r2673, %r2672, %r2668;
	add.s32 	%r455, %r2673, %r2671;
	// begin inline asm
	shf.r.clamp.b32 %r225, %r3979, %r3979, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r229, %r3979, %r3979, %r760;
	// end inline asm
	shr.u32 	%r2674, %r3979, 3;
	xor.b32  	%r2675, %r225, %r2674;
	xor.b32  	%r2676, %r2675, %r229;
	// begin inline asm
	shf.r.clamp.b32 %r233, %r439, %r439, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r237, %r439, %r439, %r768;
	// end inline asm
	shr.u32 	%r2677, %r439, 10;
	xor.b32  	%r2678, %r233, %r2677;
	xor.b32  	%r2679, %r2678, %r237;
	add.s32 	%r2680, %r359, %r3983;
	add.s32 	%r2681, %r2680, %r2676;
	add.s32 	%r471, %r2681, %r2679;
	// begin inline asm
	shf.r.clamp.b32 %r241, %r247, %r247, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r245, %r247, %r247, %r760;
	// end inline asm
	shr.u32 	%r2682, %r247, 3;
	xor.b32  	%r2683, %r241, %r2682;
	xor.b32  	%r2684, %r2683, %r245;
	// begin inline asm
	shf.r.clamp.b32 %r249, %r455, %r455, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r253, %r455, %r455, %r768;
	// end inline asm
	shr.u32 	%r2685, %r455, 10;
	xor.b32  	%r2686, %r249, %r2685;
	xor.b32  	%r2687, %r2686, %r253;
	add.s32 	%r2688, %r375, %r3979;
	add.s32 	%r2689, %r2688, %r2684;
	add.s32 	%r487, %r2689, %r2687;
	// begin inline asm
	shf.r.clamp.b32 %r257, %r263, %r263, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r261, %r263, %r263, %r760;
	// end inline asm
	shr.u32 	%r2690, %r263, 3;
	xor.b32  	%r2691, %r257, %r2690;
	xor.b32  	%r2692, %r2691, %r261;
	// begin inline asm
	shf.r.clamp.b32 %r265, %r471, %r471, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r269, %r471, %r471, %r768;
	// end inline asm
	shr.u32 	%r2693, %r471, 10;
	xor.b32  	%r2694, %r265, %r2693;
	xor.b32  	%r2695, %r2694, %r269;
	add.s32 	%r2696, %r391, %r247;
	add.s32 	%r2697, %r2696, %r2692;
	add.s32 	%r503, %r2697, %r2695;
	// begin inline asm
	shf.r.clamp.b32 %r273, %r279, %r279, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r277, %r279, %r279, %r760;
	// end inline asm
	shr.u32 	%r2698, %r279, 3;
	xor.b32  	%r2699, %r273, %r2698;
	xor.b32  	%r2700, %r2699, %r277;
	// begin inline asm
	shf.r.clamp.b32 %r281, %r487, %r487, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r285, %r487, %r487, %r768;
	// end inline asm
	shr.u32 	%r2701, %r487, 10;
	xor.b32  	%r2702, %r281, %r2701;
	xor.b32  	%r2703, %r2702, %r285;
	add.s32 	%r2704, %r407, %r263;
	add.s32 	%r2705, %r2704, %r2700;
	add.s32 	%r519, %r2705, %r2703;
	// begin inline asm
	shf.r.clamp.b32 %r289, %r295, %r295, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r293, %r295, %r295, %r760;
	// end inline asm
	shr.u32 	%r2706, %r295, 3;
	xor.b32  	%r2707, %r289, %r2706;
	xor.b32  	%r2708, %r2707, %r293;
	// begin inline asm
	shf.r.clamp.b32 %r297, %r503, %r503, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r301, %r503, %r503, %r768;
	// end inline asm
	shr.u32 	%r2709, %r503, 10;
	xor.b32  	%r2710, %r297, %r2709;
	xor.b32  	%r2711, %r2710, %r301;
	add.s32 	%r2712, %r423, %r279;
	add.s32 	%r2713, %r2712, %r2708;
	add.s32 	%r535, %r2713, %r2711;
	// begin inline asm
	shf.r.clamp.b32 %r305, %r311, %r311, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r309, %r311, %r311, %r760;
	// end inline asm
	shr.u32 	%r2714, %r311, 3;
	xor.b32  	%r2715, %r305, %r2714;
	xor.b32  	%r2716, %r2715, %r309;
	// begin inline asm
	shf.r.clamp.b32 %r313, %r519, %r519, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r317, %r519, %r519, %r768;
	// end inline asm
	shr.u32 	%r2717, %r519, 10;
	xor.b32  	%r2718, %r313, %r2717;
	xor.b32  	%r2719, %r2718, %r317;
	add.s32 	%r2720, %r439, %r295;
	add.s32 	%r2721, %r2720, %r2716;
	add.s32 	%r551, %r2721, %r2719;
	// begin inline asm
	shf.r.clamp.b32 %r321, %r327, %r327, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r325, %r327, %r327, %r760;
	// end inline asm
	shr.u32 	%r2722, %r327, 3;
	xor.b32  	%r2723, %r321, %r2722;
	xor.b32  	%r2724, %r2723, %r325;
	// begin inline asm
	shf.r.clamp.b32 %r329, %r535, %r535, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r333, %r535, %r535, %r768;
	// end inline asm
	shr.u32 	%r2725, %r535, 10;
	xor.b32  	%r2726, %r329, %r2725;
	xor.b32  	%r2727, %r2726, %r333;
	add.s32 	%r2728, %r455, %r311;
	add.s32 	%r2729, %r2728, %r2724;
	add.s32 	%r567, %r2729, %r2727;
	// begin inline asm
	shf.r.clamp.b32 %r337, %r343, %r343, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r341, %r343, %r343, %r760;
	// end inline asm
	shr.u32 	%r2730, %r343, 3;
	xor.b32  	%r2731, %r337, %r2730;
	xor.b32  	%r2732, %r2731, %r341;
	// begin inline asm
	shf.r.clamp.b32 %r345, %r551, %r551, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r349, %r551, %r551, %r768;
	// end inline asm
	shr.u32 	%r2733, %r551, 10;
	xor.b32  	%r2734, %r345, %r2733;
	xor.b32  	%r2735, %r2734, %r349;
	add.s32 	%r2736, %r471, %r327;
	add.s32 	%r2737, %r2736, %r2732;
	add.s32 	%r583, %r2737, %r2735;
	// begin inline asm
	shf.r.clamp.b32 %r353, %r359, %r359, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r357, %r359, %r359, %r760;
	// end inline asm
	shr.u32 	%r2738, %r359, 3;
	xor.b32  	%r2739, %r353, %r2738;
	xor.b32  	%r2740, %r2739, %r357;
	// begin inline asm
	shf.r.clamp.b32 %r361, %r567, %r567, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r365, %r567, %r567, %r768;
	// end inline asm
	shr.u32 	%r2741, %r567, 10;
	xor.b32  	%r2742, %r361, %r2741;
	xor.b32  	%r2743, %r2742, %r365;
	add.s32 	%r2744, %r487, %r343;
	add.s32 	%r2745, %r2744, %r2740;
	add.s32 	%r599, %r2745, %r2743;
	// begin inline asm
	shf.r.clamp.b32 %r369, %r375, %r375, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r373, %r375, %r375, %r760;
	// end inline asm
	shr.u32 	%r2746, %r375, 3;
	xor.b32  	%r2747, %r369, %r2746;
	xor.b32  	%r2748, %r2747, %r373;
	// begin inline asm
	shf.r.clamp.b32 %r377, %r583, %r583, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r381, %r583, %r583, %r768;
	// end inline asm
	shr.u32 	%r2749, %r583, 10;
	xor.b32  	%r2750, %r377, %r2749;
	xor.b32  	%r2751, %r2750, %r381;
	add.s32 	%r2752, %r503, %r359;
	add.s32 	%r2753, %r2752, %r2748;
	add.s32 	%r615, %r2753, %r2751;
	// begin inline asm
	shf.r.clamp.b32 %r385, %r391, %r391, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r389, %r391, %r391, %r760;
	// end inline asm
	shr.u32 	%r2754, %r391, 3;
	xor.b32  	%r2755, %r385, %r2754;
	xor.b32  	%r2756, %r2755, %r389;
	// begin inline asm
	shf.r.clamp.b32 %r393, %r599, %r599, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r397, %r599, %r599, %r768;
	// end inline asm
	shr.u32 	%r2757, %r599, 10;
	xor.b32  	%r2758, %r393, %r2757;
	xor.b32  	%r2759, %r2758, %r397;
	add.s32 	%r2760, %r519, %r375;
	add.s32 	%r2761, %r2760, %r2756;
	add.s32 	%r631, %r2761, %r2759;
	// begin inline asm
	shf.r.clamp.b32 %r401, %r407, %r407, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r405, %r407, %r407, %r760;
	// end inline asm
	shr.u32 	%r2762, %r407, 3;
	xor.b32  	%r2763, %r401, %r2762;
	xor.b32  	%r2764, %r2763, %r405;
	// begin inline asm
	shf.r.clamp.b32 %r409, %r615, %r615, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r413, %r615, %r615, %r768;
	// end inline asm
	shr.u32 	%r2765, %r615, 10;
	xor.b32  	%r2766, %r409, %r2765;
	xor.b32  	%r2767, %r2766, %r413;
	add.s32 	%r2768, %r535, %r391;
	add.s32 	%r2769, %r2768, %r2764;
	add.s32 	%r647, %r2769, %r2767;
	// begin inline asm
	shf.r.clamp.b32 %r417, %r423, %r423, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r421, %r423, %r423, %r760;
	// end inline asm
	shr.u32 	%r2770, %r423, 3;
	xor.b32  	%r2771, %r417, %r2770;
	xor.b32  	%r2772, %r2771, %r421;
	// begin inline asm
	shf.r.clamp.b32 %r425, %r631, %r631, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r429, %r631, %r631, %r768;
	// end inline asm
	shr.u32 	%r2773, %r631, 10;
	xor.b32  	%r2774, %r425, %r2773;
	xor.b32  	%r2775, %r2774, %r429;
	add.s32 	%r2776, %r551, %r407;
	add.s32 	%r2777, %r2776, %r2772;
	add.s32 	%r663, %r2777, %r2775;
	// begin inline asm
	shf.r.clamp.b32 %r433, %r439, %r439, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r437, %r439, %r439, %r760;
	// end inline asm
	shr.u32 	%r2778, %r439, 3;
	xor.b32  	%r2779, %r433, %r2778;
	xor.b32  	%r2780, %r2779, %r437;
	// begin inline asm
	shf.r.clamp.b32 %r441, %r647, %r647, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r445, %r647, %r647, %r768;
	// end inline asm
	shr.u32 	%r2781, %r647, 10;
	xor.b32  	%r2782, %r441, %r2781;
	xor.b32  	%r2783, %r2782, %r445;
	add.s32 	%r2784, %r567, %r423;
	add.s32 	%r2785, %r2784, %r2780;
	add.s32 	%r679, %r2785, %r2783;
	// begin inline asm
	shf.r.clamp.b32 %r449, %r455, %r455, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r453, %r455, %r455, %r760;
	// end inline asm
	shr.u32 	%r2786, %r455, 3;
	xor.b32  	%r2787, %r449, %r2786;
	xor.b32  	%r2788, %r2787, %r453;
	// begin inline asm
	shf.r.clamp.b32 %r457, %r663, %r663, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r461, %r663, %r663, %r768;
	// end inline asm
	shr.u32 	%r2789, %r663, 10;
	xor.b32  	%r2790, %r457, %r2789;
	xor.b32  	%r2791, %r2790, %r461;
	add.s32 	%r2792, %r583, %r439;
	add.s32 	%r2793, %r2792, %r2788;
	add.s32 	%r695, %r2793, %r2791;
	// begin inline asm
	shf.r.clamp.b32 %r465, %r471, %r471, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r469, %r471, %r471, %r760;
	// end inline asm
	shr.u32 	%r2794, %r471, 3;
	xor.b32  	%r2795, %r465, %r2794;
	xor.b32  	%r2796, %r2795, %r469;
	// begin inline asm
	shf.r.clamp.b32 %r473, %r679, %r679, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r477, %r679, %r679, %r768;
	// end inline asm
	shr.u32 	%r2797, %r679, 10;
	xor.b32  	%r2798, %r473, %r2797;
	xor.b32  	%r2799, %r2798, %r477;
	add.s32 	%r2800, %r599, %r455;
	add.s32 	%r2801, %r2800, %r2796;
	add.s32 	%r711, %r2801, %r2799;
	// begin inline asm
	shf.r.clamp.b32 %r481, %r487, %r487, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r485, %r487, %r487, %r760;
	// end inline asm
	shr.u32 	%r2802, %r487, 3;
	xor.b32  	%r2803, %r481, %r2802;
	xor.b32  	%r2804, %r2803, %r485;
	// begin inline asm
	shf.r.clamp.b32 %r489, %r695, %r695, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r493, %r695, %r695, %r768;
	// end inline asm
	shr.u32 	%r2805, %r695, 10;
	xor.b32  	%r2806, %r489, %r2805;
	xor.b32  	%r2807, %r2806, %r493;
	add.s32 	%r2808, %r615, %r471;
	add.s32 	%r2809, %r2808, %r2804;
	add.s32 	%r727, %r2809, %r2807;
	// begin inline asm
	shf.r.clamp.b32 %r497, %r503, %r503, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r501, %r503, %r503, %r760;
	// end inline asm
	shr.u32 	%r2810, %r503, 3;
	xor.b32  	%r2811, %r497, %r2810;
	xor.b32  	%r2812, %r2811, %r501;
	// begin inline asm
	shf.r.clamp.b32 %r505, %r711, %r711, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r509, %r711, %r711, %r768;
	// end inline asm
	shr.u32 	%r2813, %r711, 10;
	xor.b32  	%r2814, %r505, %r2813;
	xor.b32  	%r2815, %r2814, %r509;
	add.s32 	%r2816, %r631, %r487;
	add.s32 	%r2817, %r2816, %r2812;
	add.s32 	%r743, %r2817, %r2815;
	// begin inline asm
	shf.r.clamp.b32 %r513, %r519, %r519, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r517, %r519, %r519, %r760;
	// end inline asm
	shr.u32 	%r2818, %r519, 3;
	xor.b32  	%r2819, %r513, %r2818;
	xor.b32  	%r2820, %r2819, %r517;
	// begin inline asm
	shf.r.clamp.b32 %r521, %r727, %r727, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r525, %r727, %r727, %r768;
	// end inline asm
	shr.u32 	%r2821, %r727, 10;
	xor.b32  	%r2822, %r521, %r2821;
	xor.b32  	%r2823, %r2822, %r525;
	add.s32 	%r2824, %r647, %r503;
	add.s32 	%r2825, %r2824, %r2820;
	add.s32 	%r759, %r2825, %r2823;
	// begin inline asm
	shf.r.clamp.b32 %r529, %r535, %r535, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r533, %r535, %r535, %r760;
	// end inline asm
	shr.u32 	%r2826, %r535, 3;
	xor.b32  	%r2827, %r529, %r2826;
	xor.b32  	%r2828, %r2827, %r533;
	// begin inline asm
	shf.r.clamp.b32 %r537, %r743, %r743, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r541, %r743, %r743, %r768;
	// end inline asm
	shr.u32 	%r2829, %r743, 10;
	xor.b32  	%r2830, %r537, %r2829;
	xor.b32  	%r2831, %r2830, %r541;
	add.s32 	%r2832, %r663, %r519;
	add.s32 	%r2833, %r2832, %r2828;
	add.s32 	%r575, %r2833, %r2831;
	// begin inline asm
	shf.r.clamp.b32 %r545, %r551, %r551, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r549, %r551, %r551, %r760;
	// end inline asm
	shr.u32 	%r2834, %r551, 3;
	xor.b32  	%r2835, %r545, %r2834;
	xor.b32  	%r2836, %r2835, %r549;
	// begin inline asm
	shf.r.clamp.b32 %r553, %r759, %r759, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r557, %r759, %r759, %r768;
	// end inline asm
	shr.u32 	%r2837, %r759, 10;
	xor.b32  	%r2838, %r553, %r2837;
	xor.b32  	%r2839, %r2838, %r557;
	add.s32 	%r2840, %r679, %r535;
	add.s32 	%r2841, %r2840, %r2836;
	add.s32 	%r591, %r2841, %r2839;
	// begin inline asm
	shf.r.clamp.b32 %r561, %r567, %r567, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r565, %r567, %r567, %r760;
	// end inline asm
	shr.u32 	%r2842, %r567, 3;
	xor.b32  	%r2843, %r561, %r2842;
	xor.b32  	%r2844, %r2843, %r565;
	// begin inline asm
	shf.r.clamp.b32 %r569, %r575, %r575, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r573, %r575, %r575, %r768;
	// end inline asm
	shr.u32 	%r2845, %r575, 10;
	xor.b32  	%r2846, %r569, %r2845;
	xor.b32  	%r2847, %r2846, %r573;
	add.s32 	%r2848, %r695, %r551;
	add.s32 	%r2849, %r2848, %r2844;
	add.s32 	%r607, %r2849, %r2847;
	// begin inline asm
	shf.r.clamp.b32 %r577, %r583, %r583, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r581, %r583, %r583, %r760;
	// end inline asm
	shr.u32 	%r2850, %r583, 3;
	xor.b32  	%r2851, %r577, %r2850;
	xor.b32  	%r2852, %r2851, %r581;
	// begin inline asm
	shf.r.clamp.b32 %r585, %r591, %r591, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r589, %r591, %r591, %r768;
	// end inline asm
	shr.u32 	%r2853, %r591, 10;
	xor.b32  	%r2854, %r585, %r2853;
	xor.b32  	%r2855, %r2854, %r589;
	add.s32 	%r2856, %r711, %r567;
	add.s32 	%r2857, %r2856, %r2852;
	add.s32 	%r623, %r2857, %r2855;
	// begin inline asm
	shf.r.clamp.b32 %r593, %r599, %r599, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r597, %r599, %r599, %r760;
	// end inline asm
	shr.u32 	%r2858, %r599, 3;
	xor.b32  	%r2859, %r593, %r2858;
	xor.b32  	%r2860, %r2859, %r597;
	// begin inline asm
	shf.r.clamp.b32 %r601, %r607, %r607, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r605, %r607, %r607, %r768;
	// end inline asm
	shr.u32 	%r2861, %r607, 10;
	xor.b32  	%r2862, %r601, %r2861;
	xor.b32  	%r2863, %r2862, %r605;
	add.s32 	%r2864, %r727, %r583;
	add.s32 	%r2865, %r2864, %r2860;
	add.s32 	%r639, %r2865, %r2863;
	// begin inline asm
	shf.r.clamp.b32 %r609, %r615, %r615, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r613, %r615, %r615, %r760;
	// end inline asm
	shr.u32 	%r2866, %r615, 3;
	xor.b32  	%r2867, %r609, %r2866;
	xor.b32  	%r2868, %r2867, %r613;
	// begin inline asm
	shf.r.clamp.b32 %r617, %r623, %r623, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r621, %r623, %r623, %r768;
	// end inline asm
	shr.u32 	%r2869, %r623, 10;
	xor.b32  	%r2870, %r617, %r2869;
	xor.b32  	%r2871, %r2870, %r621;
	add.s32 	%r2872, %r743, %r599;
	add.s32 	%r2873, %r2872, %r2868;
	add.s32 	%r655, %r2873, %r2871;
	// begin inline asm
	shf.r.clamp.b32 %r625, %r631, %r631, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r629, %r631, %r631, %r760;
	// end inline asm
	shr.u32 	%r2874, %r631, 3;
	xor.b32  	%r2875, %r625, %r2874;
	xor.b32  	%r2876, %r2875, %r629;
	// begin inline asm
	shf.r.clamp.b32 %r633, %r639, %r639, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r637, %r639, %r639, %r768;
	// end inline asm
	shr.u32 	%r2877, %r639, 10;
	xor.b32  	%r2878, %r633, %r2877;
	xor.b32  	%r2879, %r2878, %r637;
	add.s32 	%r2880, %r759, %r615;
	add.s32 	%r2881, %r2880, %r2876;
	add.s32 	%r671, %r2881, %r2879;
	// begin inline asm
	shf.r.clamp.b32 %r641, %r647, %r647, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r645, %r647, %r647, %r760;
	// end inline asm
	shr.u32 	%r2882, %r647, 3;
	xor.b32  	%r2883, %r641, %r2882;
	xor.b32  	%r2884, %r2883, %r645;
	// begin inline asm
	shf.r.clamp.b32 %r649, %r655, %r655, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r653, %r655, %r655, %r768;
	// end inline asm
	shr.u32 	%r2885, %r655, 10;
	xor.b32  	%r2886, %r649, %r2885;
	xor.b32  	%r2887, %r2886, %r653;
	add.s32 	%r2888, %r575, %r631;
	add.s32 	%r2889, %r2888, %r2884;
	add.s32 	%r687, %r2889, %r2887;
	// begin inline asm
	shf.r.clamp.b32 %r657, %r663, %r663, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r661, %r663, %r663, %r760;
	// end inline asm
	shr.u32 	%r2890, %r663, 3;
	xor.b32  	%r2891, %r657, %r2890;
	xor.b32  	%r2892, %r2891, %r661;
	// begin inline asm
	shf.r.clamp.b32 %r665, %r671, %r671, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r669, %r671, %r671, %r768;
	// end inline asm
	shr.u32 	%r2893, %r671, 10;
	xor.b32  	%r2894, %r665, %r2893;
	xor.b32  	%r2895, %r2894, %r669;
	add.s32 	%r2896, %r591, %r647;
	add.s32 	%r2897, %r2896, %r2892;
	add.s32 	%r703, %r2897, %r2895;
	// begin inline asm
	shf.r.clamp.b32 %r673, %r679, %r679, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r677, %r679, %r679, %r760;
	// end inline asm
	shr.u32 	%r2898, %r679, 3;
	xor.b32  	%r2899, %r673, %r2898;
	xor.b32  	%r2900, %r2899, %r677;
	// begin inline asm
	shf.r.clamp.b32 %r681, %r687, %r687, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r685, %r687, %r687, %r768;
	// end inline asm
	shr.u32 	%r2901, %r687, 10;
	xor.b32  	%r2902, %r681, %r2901;
	xor.b32  	%r2903, %r2902, %r685;
	add.s32 	%r2904, %r607, %r663;
	add.s32 	%r2905, %r2904, %r2900;
	add.s32 	%r719, %r2905, %r2903;
	// begin inline asm
	shf.r.clamp.b32 %r689, %r695, %r695, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r693, %r695, %r695, %r760;
	// end inline asm
	shr.u32 	%r2906, %r695, 3;
	xor.b32  	%r2907, %r689, %r2906;
	xor.b32  	%r2908, %r2907, %r693;
	// begin inline asm
	shf.r.clamp.b32 %r697, %r703, %r703, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r701, %r703, %r703, %r768;
	// end inline asm
	shr.u32 	%r2909, %r703, 10;
	xor.b32  	%r2910, %r697, %r2909;
	xor.b32  	%r2911, %r2910, %r701;
	add.s32 	%r2912, %r623, %r679;
	add.s32 	%r2913, %r2912, %r2908;
	add.s32 	%r735, %r2913, %r2911;
	// begin inline asm
	shf.r.clamp.b32 %r705, %r711, %r711, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r709, %r711, %r711, %r760;
	// end inline asm
	shr.u32 	%r2914, %r711, 3;
	xor.b32  	%r2915, %r705, %r2914;
	xor.b32  	%r2916, %r2915, %r709;
	// begin inline asm
	shf.r.clamp.b32 %r713, %r719, %r719, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r717, %r719, %r719, %r768;
	// end inline asm
	shr.u32 	%r2917, %r719, 10;
	xor.b32  	%r2918, %r713, %r2917;
	xor.b32  	%r2919, %r2918, %r717;
	add.s32 	%r2920, %r639, %r695;
	add.s32 	%r2921, %r2920, %r2916;
	add.s32 	%r751, %r2921, %r2919;
	// begin inline asm
	shf.r.clamp.b32 %r721, %r727, %r727, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r725, %r727, %r727, %r760;
	// end inline asm
	shr.u32 	%r2922, %r727, 3;
	xor.b32  	%r2923, %r721, %r2922;
	xor.b32  	%r2924, %r2923, %r725;
	// begin inline asm
	shf.r.clamp.b32 %r729, %r735, %r735, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r733, %r735, %r735, %r768;
	// end inline asm
	shr.u32 	%r2925, %r735, 10;
	xor.b32  	%r2926, %r729, %r2925;
	xor.b32  	%r2927, %r2926, %r733;
	add.s32 	%r2928, %r655, %r711;
	add.s32 	%r2929, %r2928, %r2924;
	add.s32 	%r767, %r2929, %r2927;
	// begin inline asm
	shf.r.clamp.b32 %r737, %r743, %r743, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r741, %r743, %r743, %r760;
	// end inline asm
	shr.u32 	%r2930, %r743, 3;
	xor.b32  	%r2931, %r737, %r2930;
	xor.b32  	%r2932, %r2931, %r741;
	// begin inline asm
	shf.r.clamp.b32 %r745, %r751, %r751, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r749, %r751, %r751, %r768;
	// end inline asm
	shr.u32 	%r2933, %r751, 10;
	xor.b32  	%r2934, %r745, %r2933;
	xor.b32  	%r2935, %r2934, %r749;
	// begin inline asm
	shf.r.clamp.b32 %r753, %r759, %r759, %r756;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r757, %r759, %r759, %r760;
	// end inline asm
	shr.u32 	%r2936, %r759, 3;
	xor.b32  	%r2937, %r753, %r2936;
	xor.b32  	%r2938, %r2937, %r757;
	// begin inline asm
	shf.r.clamp.b32 %r761, %r767, %r767, %r764;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r765, %r767, %r767, %r768;
	// end inline asm
	shr.u32 	%r2939, %r767, 10;
	xor.b32  	%r2940, %r761, %r2939;
	xor.b32  	%r2941, %r2940, %r765;
	mov.u32 	%r839, 1359893119;
	mov.u32 	%r2536, 6;
	// begin inline asm
	shf.r.clamp.b32 %r769, %r839, %r839, %r2536;
	// end inline asm
	mov.u32 	%r2540, 11;
	// begin inline asm
	shf.r.clamp.b32 %r773, %r839, %r839, %r2540;
	// end inline asm
	xor.b32  	%r2942, %r773, %r769;
	mov.u32 	%r2544, 25;
	// begin inline asm
	shf.r.clamp.b32 %r777, %r839, %r839, %r2544;
	// end inline asm
	xor.b32  	%r2943, %r2942, %r777;
	add.s32 	%r2944, %r3981, %r2943;
	mov.u32 	%r783, 528734635;
	mov.u32 	%r782, %r839;
	// begin inline asm
	not.b32  %r782, %r782;     
	and.b32  %r781, %r782, %r783; 
	
	// end inline asm
	xor.b32  	%r2945, %r781, 285491212;
	add.s32 	%r2946, %r2944, %r2945;
	mov.u32 	%r795, 1779033703;
	mov.u32 	%r2552, 2;
	// begin inline asm
	shf.r.clamp.b32 %r785, %r795, %r795, %r2552;
	// end inline asm
	mov.u32 	%r2556, 13;
	// begin inline asm
	shf.r.clamp.b32 %r789, %r795, %r795, %r2556;
	// end inline asm
	xor.b32  	%r2947, %r789, %r785;
	mov.u32 	%r2560, 22;
	// begin inline asm
	shf.r.clamp.b32 %r793, %r795, %r795, %r2560;
	// end inline asm
	xor.b32  	%r2948, %r2947, %r793;
	add.s32 	%r2949, %r2946, %r2948;
	add.s32 	%r798, %r2946, 1136325099;
	add.s32 	%r823, %r2949, -656743656;
	// begin inline asm
	shf.r.clamp.b32 %r797, %r798, %r798, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r801, %r798, %r798, %r2540;
	// end inline asm
	xor.b32  	%r2950, %r801, %r797;
	// begin inline asm
	shf.r.clamp.b32 %r805, %r798, %r798, %r2544;
	// end inline asm
	xor.b32  	%r2951, %r2950, %r805;
	add.s32 	%r2952, %r3984, %r2951;
	mov.u32 	%r811, -1694144372;
	mov.u32 	%r810, %r798;
	// begin inline asm
	not.b32  %r810, %r810;     
	and.b32  %r809, %r810, %r811; 
	
	// end inline asm
	and.b32  	%r3968, %r798, 1359893119;
	xor.b32  	%r2954, %r809, %r3968;
	add.s32 	%r2955, %r2952, %r2954;
	and.b32  	%r2956, %r823, -781301534;
	or.b32  	%r2957, %r2956, 704751109;
	add.s32 	%r2958, %r2955, %r2957;
	add.s32 	%r826, %r2955, -852880978;
	// begin inline asm
	shf.r.clamp.b32 %r813, %r823, %r823, %r2552;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r817, %r823, %r823, %r2556;
	// end inline asm
	xor.b32  	%r2959, %r817, %r813;
	// begin inline asm
	shf.r.clamp.b32 %r821, %r823, %r823, %r2560;
	// end inline asm
	xor.b32  	%r2960, %r2959, %r821;
	add.s32 	%r2961, %r2958, %r2960;
	add.s32 	%r842, %r2961, -1866785220;
	// begin inline asm
	shf.r.clamp.b32 %r825, %r826, %r826, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r829, %r826, %r826, %r2540;
	// end inline asm
	xor.b32  	%r2962, %r829, %r825;
	// begin inline asm
	shf.r.clamp.b32 %r833, %r826, %r826, %r2544;
	// end inline asm
	xor.b32  	%r2963, %r2962, %r833;
	add.s32 	%r2964, %r3980, %r2963;
	mov.u32 	%r838, %r826;
	// begin inline asm
	not.b32  %r838, %r838;     
	and.b32  %r837, %r838, %r839; 
	
	// end inline asm
	and.b32  	%r3967, %r826, %r798;
	xor.b32  	%r2966, %r837, %r3967;
	add.s32 	%r2967, %r2964, %r2966;
	xor.b32  	%r2968, %r823, 1779033703;
	and.b32  	%r2969, %r842, %r2968;
	and.b32  	%r2970, %r823, 1779033703;
	xor.b32  	%r2971, %r2969, %r2970;
	add.s32 	%r2972, %r2967, %r2971;
	add.s32 	%r854, %r2967, 204346080;
	// begin inline asm
	shf.r.clamp.b32 %r841, %r842, %r842, %r2552;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r845, %r842, %r842, %r2556;
	// end inline asm
	xor.b32  	%r2973, %r845, %r841;
	// begin inline asm
	shf.r.clamp.b32 %r849, %r842, %r842, %r2560;
	// end inline asm
	xor.b32  	%r2974, %r2973, %r849;
	add.s32 	%r2975, %r2972, %r2974;
	add.s32 	%r870, %r2975, 1355179099;
	// begin inline asm
	shf.r.clamp.b32 %r853, %r854, %r854, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r857, %r854, %r854, %r2540;
	// end inline asm
	xor.b32  	%r2976, %r857, %r853;
	// begin inline asm
	shf.r.clamp.b32 %r861, %r854, %r854, %r2544;
	// end inline asm
	xor.b32  	%r2977, %r2976, %r861;
	add.s32 	%r2978, %r3977, %r2977;
	mov.u32 	%r866, %r854;
	// begin inline asm
	not.b32  %r866, %r866;     
	and.b32  %r865, %r866, %r798; 
	
	// end inline asm
	and.b32  	%r3966, %r854, %r826;
	xor.b32  	%r2980, %r865, %r3966;
	add.s32 	%r2981, %r2978, %r2980;
	xor.b32  	%r2982, %r842, %r823;
	and.b32  	%r2983, %r870, %r2982;
	and.b32  	%r2984, %r842, %r823;
	xor.b32  	%r2985, %r2983, %r2984;
	add.s32 	%r2986, %r2981, %r2985;
	add.s32 	%r882, %r2981, -1529998197;
	// begin inline asm
	shf.r.clamp.b32 %r869, %r870, %r870, %r2552;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r873, %r870, %r870, %r2556;
	// end inline asm
	xor.b32  	%r2987, %r873, %r869;
	// begin inline asm
	shf.r.clamp.b32 %r877, %r870, %r870, %r2560;
	// end inline asm
	xor.b32  	%r2988, %r2987, %r877;
	add.s32 	%r2989, %r2986, %r2988;
	add.s32 	%r898, %r2989, 985935396;
	// begin inline asm
	shf.r.clamp.b32 %r881, %r882, %r882, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r885, %r882, %r882, %r2540;
	// end inline asm
	xor.b32  	%r2990, %r885, %r881;
	// begin inline asm
	shf.r.clamp.b32 %r889, %r882, %r882, %r2544;
	// end inline asm
	xor.b32  	%r2991, %r2990, %r889;
	mov.u32 	%r894, %r882;
	// begin inline asm
	not.b32  %r894, %r894;     
	and.b32  %r893, %r894, %r826; 
	
	// end inline asm
	and.b32  	%r3965, %r882, %r854;
	xor.b32  	%r2993, %r893, %r3965;
	ld.param.u32 	%r4001, [sha256TestKernel_param_5];
	add.s32 	%r2994, %r4001, %r798;
	mov.u32 	%r4016, 2;
	add.s32 	%r2995, %r2994, %r2991;
	add.s32 	%r2996, %r2995, %r2993;
	add.s32 	%r2997, %r2996, 961987163;
	add.s32 	%r979, %r2997, %r823;
	// begin inline asm
	shf.r.clamp.b32 %r897, %r898, %r898, %r4016;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r901, %r898, %r898, %r2556;
	// end inline asm
	xor.b32  	%r2998, %r901, %r897;
	// begin inline asm
	shf.r.clamp.b32 %r905, %r898, %r898, %r2560;
	// end inline asm
	xor.b32  	%r2999, %r2998, %r905;
	xor.b32  	%r3000, %r870, %r842;
	and.b32  	%r3001, %r898, %r3000;
	and.b32  	%r3002, %r870, %r842;
	xor.b32  	%r3003, %r3001, %r3002;
	mov.u32 	%r4015, 25;
	add.s32 	%r3004, %r2997, %r3003;
	add.s32 	%r935, %r3004, %r2999;
	// begin inline asm
	shf.r.clamp.b32 %r909, %r979, %r979, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r913, %r979, %r979, %r2540;
	// end inline asm
	xor.b32  	%r3005, %r913, %r909;
	// begin inline asm
	shf.r.clamp.b32 %r917, %r979, %r979, %r4015;
	// end inline asm
	xor.b32  	%r3006, %r3005, %r917;
	mov.u32 	%r922, %r979;
	// begin inline asm
	not.b32  %r922, %r922;     
	and.b32  %r921, %r922, %r854; 
	
	// end inline asm
	and.b32  	%r3964, %r979, %r882;
	xor.b32  	%r3008, %r921, %r3964;
	mov.u32 	%r4014, 25;
	add.s32 	%r3009, %r3973, %r826;
	mov.u32 	%r4006, 2;
	add.s32 	%r3010, %r3009, %r3006;
	add.s32 	%r3011, %r3010, %r3008;
	add.s32 	%r3012, %r3011, 1508970993;
	add.s32 	%r1007, %r3012, %r842;
	// begin inline asm
	shf.r.clamp.b32 %r925, %r935, %r935, %r4006;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r929, %r935, %r935, %r2556;
	// end inline asm
	xor.b32  	%r3013, %r929, %r925;
	// begin inline asm
	shf.r.clamp.b32 %r933, %r935, %r935, %r2560;
	// end inline asm
	xor.b32  	%r3014, %r3013, %r933;
	xor.b32  	%r3015, %r898, %r870;
	and.b32  	%r3016, %r935, %r3015;
	and.b32  	%r3017, %r898, %r870;
	xor.b32  	%r3018, %r3016, %r3017;
	add.s32 	%r3019, %r3012, %r3018;
	add.s32 	%r963, %r3019, %r3014;
	// begin inline asm
	shf.r.clamp.b32 %r937, %r1007, %r1007, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r941, %r1007, %r1007, %r2540;
	// end inline asm
	xor.b32  	%r3020, %r941, %r937;
	// begin inline asm
	shf.r.clamp.b32 %r945, %r1007, %r1007, %r4014;
	// end inline asm
	xor.b32  	%r3021, %r3020, %r945;
	mov.u32 	%r950, %r1007;
	// begin inline asm
	not.b32  %r950, %r950;     
	and.b32  %r949, %r950, %r882; 
	
	// end inline asm
	and.b32  	%r3963, %r1007, %r979;
	xor.b32  	%r3023, %r949, %r3963;
	ld.param.u32 	%r3991, [sha256TestKernel_param_7];
	add.s32 	%r3024, %r3991, %r854;
	mov.u32 	%r4005, 2;
	add.s32 	%r3025, %r3024, %r3021;
	add.s32 	%r3026, %r3025, %r3023;
	add.s32 	%r3027, %r3026, -1841331548;
	add.s32 	%r1035, %r3027, %r870;
	// begin inline asm
	shf.r.clamp.b32 %r953, %r963, %r963, %r4005;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r957, %r963, %r963, %r2556;
	// end inline asm
	xor.b32  	%r3028, %r957, %r953;
	// begin inline asm
	shf.r.clamp.b32 %r961, %r963, %r963, %r2560;
	// end inline asm
	xor.b32  	%r3029, %r3028, %r961;
	xor.b32  	%r3030, %r935, %r898;
	and.b32  	%r3031, %r963, %r3030;
	and.b32  	%r3032, %r935, %r898;
	xor.b32  	%r3033, %r3031, %r3032;
	add.s32 	%r3034, %r3027, %r3033;
	add.s32 	%r991, %r3034, %r3029;
	// begin inline asm
	shf.r.clamp.b32 %r965, %r1035, %r1035, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r969, %r1035, %r1035, %r2540;
	// end inline asm
	xor.b32  	%r3035, %r969, %r965;
	// begin inline asm
	shf.r.clamp.b32 %r973, %r1035, %r1035, %r4014;
	// end inline asm
	xor.b32  	%r3036, %r3035, %r973;
	mov.u32 	%r978, %r1035;
	// begin inline asm
	not.b32  %r978, %r978;     
	and.b32  %r977, %r978, %r979; 
	
	// end inline asm
	and.b32  	%r3962, %r1035, %r1007;
	xor.b32  	%r3038, %r977, %r3962;
	mov.u32 	%r4004, 2;
	add.s32 	%r3039, %r3970, %r882;
	add.s32 	%r3040, %r3039, %r3036;
	add.s32 	%r3041, %r3040, %r3038;
	add.s32 	%r3042, %r3041, -1424204075;
	add.s32 	%r1063, %r3042, %r898;
	// begin inline asm
	shf.r.clamp.b32 %r981, %r991, %r991, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r985, %r991, %r991, %r2556;
	// end inline asm
	xor.b32  	%r3043, %r985, %r981;
	// begin inline asm
	shf.r.clamp.b32 %r989, %r991, %r991, %r2560;
	// end inline asm
	xor.b32  	%r3044, %r3043, %r989;
	xor.b32  	%r3045, %r963, %r935;
	and.b32  	%r3046, %r991, %r3045;
	and.b32  	%r3047, %r963, %r935;
	xor.b32  	%r3048, %r3046, %r3047;
	add.s32 	%r3049, %r3042, %r3048;
	add.s32 	%r1019, %r3049, %r3044;
	// begin inline asm
	shf.r.clamp.b32 %r993, %r1063, %r1063, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r997, %r1063, %r1063, %r2540;
	// end inline asm
	xor.b32  	%r3050, %r997, %r993;
	// begin inline asm
	shf.r.clamp.b32 %r1001, %r1063, %r1063, %r4014;
	// end inline asm
	xor.b32  	%r3051, %r3050, %r1001;
	mov.u32 	%r1006, %r1063;
	// begin inline asm
	not.b32  %r1006, %r1006;     
	and.b32  %r1005, %r1006, %r1007; 
	
	// end inline asm
	and.b32  	%r3961, %r1063, %r1035;
	xor.b32  	%r3053, %r1005, %r3961;
	ld.param.u32 	%r4019, [sha256TestKernel_param_9];
	add.s32 	%r3054, %r4019, %r979;
	add.s32 	%r3055, %r3054, %r3051;
	add.s32 	%r3056, %r3055, %r3053;
	add.s32 	%r3057, %r3056, -670586216;
	add.s32 	%r1091, %r3057, %r935;
	// begin inline asm
	shf.r.clamp.b32 %r1009, %r1019, %r1019, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1013, %r1019, %r1019, %r2556;
	// end inline asm
	xor.b32  	%r3058, %r1013, %r1009;
	// begin inline asm
	shf.r.clamp.b32 %r1017, %r1019, %r1019, %r2560;
	// end inline asm
	xor.b32  	%r3059, %r3058, %r1017;
	xor.b32  	%r3060, %r991, %r963;
	and.b32  	%r3061, %r1019, %r3060;
	and.b32  	%r3062, %r991, %r963;
	xor.b32  	%r3063, %r3061, %r3062;
	add.s32 	%r3064, %r3057, %r3063;
	add.s32 	%r1047, %r3064, %r3059;
	// begin inline asm
	shf.r.clamp.b32 %r1021, %r1091, %r1091, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1025, %r1091, %r1091, %r2540;
	// end inline asm
	xor.b32  	%r3065, %r1025, %r1021;
	// begin inline asm
	shf.r.clamp.b32 %r1029, %r1091, %r1091, %r4014;
	// end inline asm
	xor.b32  	%r3066, %r3065, %r1029;
	mov.u32 	%r1034, %r1091;
	// begin inline asm
	not.b32  %r1034, %r1034;     
	and.b32  %r1033, %r1034, %r1035; 
	
	// end inline asm
	and.b32  	%r3960, %r1091, %r1063;
	xor.b32  	%r3068, %r1033, %r3960;
	ld.param.u32 	%r3996, [sha256TestKernel_param_10];
	add.s32 	%r3069, %r3996, %r1007;
	add.s32 	%r3070, %r3069, %r3066;
	add.s32 	%r3071, %r3070, %r3068;
	add.s32 	%r3072, %r3071, 310598401;
	add.s32 	%r1119, %r3072, %r963;
	// begin inline asm
	shf.r.clamp.b32 %r1037, %r1047, %r1047, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1041, %r1047, %r1047, %r2556;
	// end inline asm
	xor.b32  	%r3073, %r1041, %r1037;
	// begin inline asm
	shf.r.clamp.b32 %r1045, %r1047, %r1047, %r2560;
	// end inline asm
	xor.b32  	%r3074, %r3073, %r1045;
	xor.b32  	%r3075, %r1019, %r991;
	and.b32  	%r3076, %r1047, %r3075;
	and.b32  	%r3077, %r1019, %r991;
	xor.b32  	%r3078, %r3076, %r3077;
	add.s32 	%r3079, %r3072, %r3078;
	add.s32 	%r1075, %r3079, %r3074;
	// begin inline asm
	shf.r.clamp.b32 %r1049, %r1119, %r1119, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1053, %r1119, %r1119, %r2540;
	// end inline asm
	xor.b32  	%r3080, %r1053, %r1049;
	// begin inline asm
	shf.r.clamp.b32 %r1057, %r1119, %r1119, %r4014;
	// end inline asm
	xor.b32  	%r3081, %r3080, %r1057;
	mov.u32 	%r1062, %r1119;
	// begin inline asm
	not.b32  %r1062, %r1062;     
	and.b32  %r1061, %r1062, %r1063; 
	
	// end inline asm
	and.b32  	%r3959, %r1119, %r1091;
	xor.b32  	%r3083, %r1061, %r3959;
	ld.param.u32 	%r4002, [sha256TestKernel_param_11];
	add.s32 	%r3084, %r4002, %r1035;
	add.s32 	%r3085, %r3084, %r3081;
	add.s32 	%r3086, %r3085, %r3083;
	add.s32 	%r3087, %r3086, 607225278;
	add.s32 	%r1147, %r3087, %r991;
	// begin inline asm
	shf.r.clamp.b32 %r1065, %r1075, %r1075, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1069, %r1075, %r1075, %r2556;
	// end inline asm
	xor.b32  	%r3088, %r1069, %r1065;
	// begin inline asm
	shf.r.clamp.b32 %r1073, %r1075, %r1075, %r2560;
	// end inline asm
	xor.b32  	%r3089, %r3088, %r1073;
	xor.b32  	%r3090, %r1047, %r1019;
	and.b32  	%r3091, %r1075, %r3090;
	and.b32  	%r3092, %r1047, %r1019;
	xor.b32  	%r3093, %r3091, %r3092;
	add.s32 	%r3094, %r3087, %r3093;
	add.s32 	%r1103, %r3094, %r3089;
	// begin inline asm
	shf.r.clamp.b32 %r1077, %r1147, %r1147, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1081, %r1147, %r1147, %r2540;
	// end inline asm
	xor.b32  	%r3095, %r1081, %r1077;
	// begin inline asm
	shf.r.clamp.b32 %r1085, %r1147, %r1147, %r4014;
	// end inline asm
	xor.b32  	%r3096, %r3095, %r1085;
	mov.u32 	%r1090, %r1147;
	// begin inline asm
	not.b32  %r1090, %r1090;     
	and.b32  %r1089, %r1090, %r1091; 
	
	// end inline asm
	and.b32  	%r3958, %r1147, %r1119;
	xor.b32  	%r3098, %r1089, %r3958;
	add.s32 	%r3099, %r3976, %r1063;
	add.s32 	%r3100, %r3099, %r3096;
	add.s32 	%r3101, %r3100, %r3098;
	add.s32 	%r3102, %r3101, 1426881987;
	add.s32 	%r1175, %r3102, %r1019;
	// begin inline asm
	shf.r.clamp.b32 %r1093, %r1103, %r1103, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1097, %r1103, %r1103, %r2556;
	// end inline asm
	xor.b32  	%r3103, %r1097, %r1093;
	// begin inline asm
	shf.r.clamp.b32 %r1101, %r1103, %r1103, %r2560;
	// end inline asm
	xor.b32  	%r3104, %r3103, %r1101;
	xor.b32  	%r3105, %r1075, %r1047;
	and.b32  	%r3106, %r1103, %r3105;
	and.b32  	%r3107, %r1075, %r1047;
	xor.b32  	%r3108, %r3106, %r3107;
	add.s32 	%r3109, %r3102, %r3108;
	add.s32 	%r1131, %r3109, %r3104;
	// begin inline asm
	shf.r.clamp.b32 %r1105, %r1175, %r1175, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1109, %r1175, %r1175, %r2540;
	// end inline asm
	xor.b32  	%r3110, %r1109, %r1105;
	// begin inline asm
	shf.r.clamp.b32 %r1113, %r1175, %r1175, %r4014;
	// end inline asm
	xor.b32  	%r3111, %r3110, %r1113;
	mov.u32 	%r1118, %r1175;
	// begin inline asm
	not.b32  %r1118, %r1118;     
	and.b32  %r1117, %r1118, %r1119; 
	
	// end inline asm
	and.b32  	%r3957, %r1175, %r1147;
	xor.b32  	%r3113, %r1117, %r3957;
	ld.param.u32 	%r4013, [sha256TestKernel_param_13];
	add.s32 	%r3114, %r4013, %r1091;
	add.s32 	%r3115, %r3114, %r3111;
	add.s32 	%r3116, %r3115, %r3113;
	add.s32 	%r3117, %r3116, 1925078388;
	add.s32 	%r1203, %r3117, %r1047;
	// begin inline asm
	shf.r.clamp.b32 %r1121, %r1131, %r1131, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1125, %r1131, %r1131, %r2556;
	// end inline asm
	xor.b32  	%r3118, %r1125, %r1121;
	// begin inline asm
	shf.r.clamp.b32 %r1129, %r1131, %r1131, %r2560;
	// end inline asm
	xor.b32  	%r3119, %r3118, %r1129;
	xor.b32  	%r3120, %r1103, %r1075;
	and.b32  	%r3121, %r1131, %r3120;
	and.b32  	%r3122, %r1103, %r1075;
	xor.b32  	%r3123, %r3121, %r3122;
	add.s32 	%r3124, %r3117, %r3123;
	add.s32 	%r1159, %r3124, %r3119;
	// begin inline asm
	shf.r.clamp.b32 %r1133, %r1203, %r1203, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1137, %r1203, %r1203, %r2540;
	// end inline asm
	xor.b32  	%r3125, %r1137, %r1133;
	// begin inline asm
	shf.r.clamp.b32 %r1141, %r1203, %r1203, %r4014;
	// end inline asm
	xor.b32  	%r3126, %r3125, %r1141;
	mov.u32 	%r1146, %r1203;
	// begin inline asm
	not.b32  %r1146, %r1146;     
	and.b32  %r1145, %r1146, %r1147; 
	
	// end inline asm
	and.b32  	%r3956, %r1203, %r1175;
	xor.b32  	%r3128, %r1145, %r3956;
	ld.param.u32 	%r4018, [sha256TestKernel_param_14];
	ld.param.u32 	%r4017, [sha256TestKernel_param_16];
	add.s32 	%r3129, %r4018, %r1119;
	add.s32 	%r3130, %r3129, %r3126;
	add.s32 	%r3131, %r3130, %r3128;
	add.s32 	%r3132, %r3131, -2132889090;
	add.s32 	%r1231, %r3132, %r1075;
	// begin inline asm
	shf.r.clamp.b32 %r1149, %r1159, %r1159, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1153, %r1159, %r1159, %r2556;
	// end inline asm
	xor.b32  	%r3133, %r1153, %r1149;
	// begin inline asm
	shf.r.clamp.b32 %r1157, %r1159, %r1159, %r2560;
	// end inline asm
	xor.b32  	%r3134, %r3133, %r1157;
	xor.b32  	%r3135, %r1131, %r1103;
	and.b32  	%r3136, %r1159, %r3135;
	and.b32  	%r3137, %r1131, %r1103;
	xor.b32  	%r3138, %r3136, %r3137;
	add.s32 	%r3139, %r3132, %r3138;
	add.s32 	%r1187, %r3139, %r3134;
	// begin inline asm
	shf.r.clamp.b32 %r1161, %r1231, %r1231, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1165, %r1231, %r1231, %r2540;
	// end inline asm
	xor.b32  	%r3140, %r1165, %r1161;
	// begin inline asm
	shf.r.clamp.b32 %r1169, %r1231, %r1231, %r4014;
	// end inline asm
	xor.b32  	%r3141, %r3140, %r1169;
	mov.u32 	%r1174, %r1231;
	// begin inline asm
	not.b32  %r1174, %r1174;     
	and.b32  %r1173, %r1174, %r1175; 
	
	// end inline asm
	and.b32  	%r3955, %r1231, %r1203;
	xor.b32  	%r3143, %r1173, %r3955;
	add.s32 	%r3144, %r3983, %r1147;
	add.s32 	%r3145, %r3144, %r3141;
	add.s32 	%r3146, %r3145, %r3143;
	add.s32 	%r3147, %r3146, -1680079193;
	add.s32 	%r1259, %r3147, %r1103;
	// begin inline asm
	shf.r.clamp.b32 %r1177, %r1187, %r1187, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1181, %r1187, %r1187, %r2556;
	// end inline asm
	xor.b32  	%r3148, %r1181, %r1177;
	// begin inline asm
	shf.r.clamp.b32 %r1185, %r1187, %r1187, %r2560;
	// end inline asm
	xor.b32  	%r3149, %r3148, %r1185;
	xor.b32  	%r3150, %r1159, %r1131;
	and.b32  	%r3151, %r1187, %r3150;
	and.b32  	%r3152, %r1159, %r1131;
	xor.b32  	%r3153, %r3151, %r3152;
	add.s32 	%r3154, %r3147, %r3153;
	add.s32 	%r1215, %r3154, %r3149;
	// begin inline asm
	shf.r.clamp.b32 %r1189, %r1259, %r1259, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1193, %r1259, %r1259, %r2540;
	// end inline asm
	xor.b32  	%r3155, %r1193, %r1189;
	// begin inline asm
	shf.r.clamp.b32 %r1197, %r1259, %r1259, %r4014;
	// end inline asm
	xor.b32  	%r3156, %r3155, %r1197;
	mov.u32 	%r1202, %r1259;
	// begin inline asm
	not.b32  %r1202, %r1202;     
	and.b32  %r1201, %r1202, %r1203; 
	
	// end inline asm
	and.b32  	%r3954, %r1259, %r1231;
	xor.b32  	%r3158, %r1201, %r3954;
	add.s32 	%r3159, %r4017, %r1175;
	add.s32 	%r3160, %r3159, %r3156;
	add.s32 	%r3161, %r3160, %r3158;
	add.s32 	%r3162, %r3161, -1046744716;
	add.s32 	%r1287, %r3162, %r1131;
	// begin inline asm
	shf.r.clamp.b32 %r1205, %r1215, %r1215, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1209, %r1215, %r1215, %r2556;
	// end inline asm
	xor.b32  	%r3163, %r1209, %r1205;
	// begin inline asm
	shf.r.clamp.b32 %r1213, %r1215, %r1215, %r2560;
	// end inline asm
	xor.b32  	%r3164, %r3163, %r1213;
	xor.b32  	%r3165, %r1187, %r1159;
	and.b32  	%r3166, %r1215, %r3165;
	and.b32  	%r3167, %r1187, %r1159;
	xor.b32  	%r3168, %r3166, %r3167;
	add.s32 	%r3169, %r3162, %r3168;
	add.s32 	%r1243, %r3169, %r3164;
	// begin inline asm
	shf.r.clamp.b32 %r1217, %r1287, %r1287, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1221, %r1287, %r1287, %r2540;
	// end inline asm
	xor.b32  	%r3170, %r1221, %r1217;
	// begin inline asm
	shf.r.clamp.b32 %r1225, %r1287, %r1287, %r4014;
	// end inline asm
	xor.b32  	%r3171, %r3170, %r1225;
	mov.u32 	%r1230, %r1287;
	// begin inline asm
	not.b32  %r1230, %r1230;     
	and.b32  %r1229, %r1230, %r1231; 
	
	// end inline asm
	and.b32  	%r3953, %r1287, %r1259;
	xor.b32  	%r3173, %r1229, %r3953;
	add.s32 	%r3174, %r247, %r1203;
	add.s32 	%r3175, %r3174, %r3171;
	add.s32 	%r3176, %r3175, %r3173;
	add.s32 	%r3177, %r3176, -459576895;
	add.s32 	%r1315, %r3177, %r1159;
	// begin inline asm
	shf.r.clamp.b32 %r1233, %r1243, %r1243, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1237, %r1243, %r1243, %r2556;
	// end inline asm
	xor.b32  	%r3178, %r1237, %r1233;
	// begin inline asm
	shf.r.clamp.b32 %r1241, %r1243, %r1243, %r2560;
	// end inline asm
	xor.b32  	%r3179, %r3178, %r1241;
	xor.b32  	%r3180, %r1215, %r1187;
	and.b32  	%r3181, %r1243, %r3180;
	and.b32  	%r3182, %r1215, %r1187;
	xor.b32  	%r3183, %r3181, %r3182;
	add.s32 	%r3184, %r3177, %r3183;
	add.s32 	%r1271, %r3184, %r3179;
	// begin inline asm
	shf.r.clamp.b32 %r1245, %r1315, %r1315, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1249, %r1315, %r1315, %r2540;
	// end inline asm
	xor.b32  	%r3185, %r1249, %r1245;
	// begin inline asm
	shf.r.clamp.b32 %r1253, %r1315, %r1315, %r4014;
	// end inline asm
	xor.b32  	%r3186, %r3185, %r1253;
	mov.u32 	%r1258, %r1315;
	// begin inline asm
	not.b32  %r1258, %r1258;     
	and.b32  %r1257, %r1258, %r1259; 
	
	// end inline asm
	and.b32  	%r3952, %r1315, %r1287;
	xor.b32  	%r3188, %r1257, %r3952;
	add.s32 	%r3189, %r263, %r1231;
	add.s32 	%r3190, %r3189, %r3186;
	add.s32 	%r3191, %r3190, %r3188;
	add.s32 	%r3192, %r3191, -272742522;
	add.s32 	%r1343, %r3192, %r1187;
	// begin inline asm
	shf.r.clamp.b32 %r1261, %r1271, %r1271, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1265, %r1271, %r1271, %r2556;
	// end inline asm
	xor.b32  	%r3193, %r1265, %r1261;
	// begin inline asm
	shf.r.clamp.b32 %r1269, %r1271, %r1271, %r2560;
	// end inline asm
	xor.b32  	%r3194, %r3193, %r1269;
	xor.b32  	%r3195, %r1243, %r1215;
	and.b32  	%r3196, %r1271, %r3195;
	and.b32  	%r3197, %r1243, %r1215;
	xor.b32  	%r3198, %r3196, %r3197;
	add.s32 	%r3199, %r3192, %r3198;
	add.s32 	%r1299, %r3199, %r3194;
	// begin inline asm
	shf.r.clamp.b32 %r1273, %r1343, %r1343, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1277, %r1343, %r1343, %r2540;
	// end inline asm
	xor.b32  	%r3200, %r1277, %r1273;
	// begin inline asm
	shf.r.clamp.b32 %r1281, %r1343, %r1343, %r4014;
	// end inline asm
	xor.b32  	%r3201, %r3200, %r1281;
	mov.u32 	%r1286, %r1343;
	// begin inline asm
	not.b32  %r1286, %r1286;     
	and.b32  %r1285, %r1286, %r1287; 
	
	// end inline asm
	and.b32  	%r3951, %r1343, %r1315;
	xor.b32  	%r3203, %r1285, %r3951;
	add.s32 	%r3204, %r279, %r1259;
	add.s32 	%r3205, %r3204, %r3201;
	add.s32 	%r3206, %r3205, %r3203;
	add.s32 	%r3207, %r3206, 264347078;
	add.s32 	%r1371, %r3207, %r1215;
	// begin inline asm
	shf.r.clamp.b32 %r1289, %r1299, %r1299, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1293, %r1299, %r1299, %r2556;
	// end inline asm
	xor.b32  	%r3208, %r1293, %r1289;
	// begin inline asm
	shf.r.clamp.b32 %r1297, %r1299, %r1299, %r2560;
	// end inline asm
	xor.b32  	%r3209, %r3208, %r1297;
	xor.b32  	%r3210, %r1271, %r1243;
	and.b32  	%r3211, %r1299, %r3210;
	and.b32  	%r3212, %r1271, %r1243;
	xor.b32  	%r3213, %r3211, %r3212;
	add.s32 	%r3214, %r3207, %r3213;
	add.s32 	%r1327, %r3214, %r3209;
	// begin inline asm
	shf.r.clamp.b32 %r1301, %r1371, %r1371, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1305, %r1371, %r1371, %r2540;
	// end inline asm
	xor.b32  	%r3215, %r1305, %r1301;
	// begin inline asm
	shf.r.clamp.b32 %r1309, %r1371, %r1371, %r4014;
	// end inline asm
	xor.b32  	%r3216, %r3215, %r1309;
	mov.u32 	%r1314, %r1371;
	// begin inline asm
	not.b32  %r1314, %r1314;     
	and.b32  %r1313, %r1314, %r1315; 
	
	// end inline asm
	and.b32  	%r3950, %r1371, %r1343;
	xor.b32  	%r3218, %r1313, %r3950;
	add.s32 	%r3219, %r295, %r1287;
	add.s32 	%r3220, %r3219, %r3216;
	add.s32 	%r3221, %r3220, %r3218;
	add.s32 	%r3222, %r3221, 604807628;
	add.s32 	%r1399, %r3222, %r1243;
	// begin inline asm
	shf.r.clamp.b32 %r1317, %r1327, %r1327, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1321, %r1327, %r1327, %r2556;
	// end inline asm
	xor.b32  	%r3223, %r1321, %r1317;
	// begin inline asm
	shf.r.clamp.b32 %r1325, %r1327, %r1327, %r2560;
	// end inline asm
	xor.b32  	%r3224, %r3223, %r1325;
	xor.b32  	%r3225, %r1299, %r1271;
	and.b32  	%r3226, %r1327, %r3225;
	and.b32  	%r3227, %r1299, %r1271;
	xor.b32  	%r3228, %r3226, %r3227;
	add.s32 	%r3229, %r3222, %r3228;
	add.s32 	%r1355, %r3229, %r3224;
	// begin inline asm
	shf.r.clamp.b32 %r1329, %r1399, %r1399, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1333, %r1399, %r1399, %r2540;
	// end inline asm
	xor.b32  	%r3230, %r1333, %r1329;
	// begin inline asm
	shf.r.clamp.b32 %r1337, %r1399, %r1399, %r4014;
	// end inline asm
	xor.b32  	%r3231, %r3230, %r1337;
	mov.u32 	%r1342, %r1399;
	// begin inline asm
	not.b32  %r1342, %r1342;     
	and.b32  %r1341, %r1342, %r1343; 
	
	// end inline asm
	and.b32  	%r3949, %r1399, %r1371;
	xor.b32  	%r3233, %r1341, %r3949;
	add.s32 	%r3234, %r311, %r1315;
	add.s32 	%r3235, %r3234, %r3231;
	add.s32 	%r3236, %r3235, %r3233;
	add.s32 	%r3237, %r3236, 770255983;
	add.s32 	%r1427, %r3237, %r1271;
	// begin inline asm
	shf.r.clamp.b32 %r1345, %r1355, %r1355, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1349, %r1355, %r1355, %r2556;
	// end inline asm
	xor.b32  	%r3238, %r1349, %r1345;
	// begin inline asm
	shf.r.clamp.b32 %r1353, %r1355, %r1355, %r2560;
	// end inline asm
	xor.b32  	%r3239, %r3238, %r1353;
	xor.b32  	%r3240, %r1327, %r1299;
	and.b32  	%r3241, %r1355, %r3240;
	and.b32  	%r3242, %r1327, %r1299;
	xor.b32  	%r3243, %r3241, %r3242;
	add.s32 	%r3244, %r3237, %r3243;
	add.s32 	%r1383, %r3244, %r3239;
	// begin inline asm
	shf.r.clamp.b32 %r1357, %r1427, %r1427, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1361, %r1427, %r1427, %r2540;
	// end inline asm
	xor.b32  	%r3245, %r1361, %r1357;
	// begin inline asm
	shf.r.clamp.b32 %r1365, %r1427, %r1427, %r4014;
	// end inline asm
	xor.b32  	%r3246, %r3245, %r1365;
	mov.u32 	%r1370, %r1427;
	// begin inline asm
	not.b32  %r1370, %r1370;     
	and.b32  %r1369, %r1370, %r1371; 
	
	// end inline asm
	and.b32  	%r3948, %r1427, %r1399;
	xor.b32  	%r3248, %r1369, %r3948;
	add.s32 	%r3249, %r327, %r1343;
	add.s32 	%r3250, %r3249, %r3246;
	add.s32 	%r3251, %r3250, %r3248;
	add.s32 	%r3252, %r3251, 1249150122;
	add.s32 	%r1455, %r3252, %r1299;
	// begin inline asm
	shf.r.clamp.b32 %r1373, %r1383, %r1383, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1377, %r1383, %r1383, %r2556;
	// end inline asm
	xor.b32  	%r3253, %r1377, %r1373;
	// begin inline asm
	shf.r.clamp.b32 %r1381, %r1383, %r1383, %r2560;
	// end inline asm
	xor.b32  	%r3254, %r3253, %r1381;
	xor.b32  	%r3255, %r1355, %r1327;
	and.b32  	%r3256, %r1383, %r3255;
	and.b32  	%r3257, %r1355, %r1327;
	xor.b32  	%r3258, %r3256, %r3257;
	add.s32 	%r3259, %r3252, %r3258;
	add.s32 	%r1411, %r3259, %r3254;
	// begin inline asm
	shf.r.clamp.b32 %r1385, %r1455, %r1455, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1389, %r1455, %r1455, %r2540;
	// end inline asm
	xor.b32  	%r3260, %r1389, %r1385;
	// begin inline asm
	shf.r.clamp.b32 %r1393, %r1455, %r1455, %r4014;
	// end inline asm
	xor.b32  	%r3261, %r3260, %r1393;
	mov.u32 	%r1398, %r1455;
	// begin inline asm
	not.b32  %r1398, %r1398;     
	and.b32  %r1397, %r1398, %r1399; 
	
	// end inline asm
	and.b32  	%r3947, %r1455, %r1427;
	xor.b32  	%r3263, %r1397, %r3947;
	add.s32 	%r3264, %r343, %r1371;
	add.s32 	%r3265, %r3264, %r3261;
	add.s32 	%r3266, %r3265, %r3263;
	add.s32 	%r3267, %r3266, 1555081692;
	add.s32 	%r1483, %r3267, %r1327;
	// begin inline asm
	shf.r.clamp.b32 %r1401, %r1411, %r1411, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1405, %r1411, %r1411, %r2556;
	// end inline asm
	xor.b32  	%r3268, %r1405, %r1401;
	// begin inline asm
	shf.r.clamp.b32 %r1409, %r1411, %r1411, %r2560;
	// end inline asm
	xor.b32  	%r3269, %r3268, %r1409;
	xor.b32  	%r3270, %r1383, %r1355;
	and.b32  	%r3271, %r1411, %r3270;
	and.b32  	%r3272, %r1383, %r1355;
	xor.b32  	%r3273, %r3271, %r3272;
	add.s32 	%r3274, %r3267, %r3273;
	add.s32 	%r1439, %r3274, %r3269;
	// begin inline asm
	shf.r.clamp.b32 %r1413, %r1483, %r1483, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1417, %r1483, %r1483, %r2540;
	// end inline asm
	xor.b32  	%r3275, %r1417, %r1413;
	// begin inline asm
	shf.r.clamp.b32 %r1421, %r1483, %r1483, %r4014;
	// end inline asm
	xor.b32  	%r3276, %r3275, %r1421;
	mov.u32 	%r1426, %r1483;
	// begin inline asm
	not.b32  %r1426, %r1426;     
	and.b32  %r1425, %r1426, %r1427; 
	
	// end inline asm
	and.b32  	%r3946, %r1483, %r1455;
	xor.b32  	%r3278, %r1425, %r3946;
	add.s32 	%r3279, %r359, %r1399;
	add.s32 	%r3280, %r3279, %r3276;
	add.s32 	%r3281, %r3280, %r3278;
	add.s32 	%r3282, %r3281, 1996064986;
	add.s32 	%r1511, %r3282, %r1355;
	// begin inline asm
	shf.r.clamp.b32 %r1429, %r1439, %r1439, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1433, %r1439, %r1439, %r2556;
	// end inline asm
	xor.b32  	%r3283, %r1433, %r1429;
	// begin inline asm
	shf.r.clamp.b32 %r1437, %r1439, %r1439, %r2560;
	// end inline asm
	xor.b32  	%r3284, %r3283, %r1437;
	xor.b32  	%r3285, %r1411, %r1383;
	and.b32  	%r3286, %r1439, %r3285;
	and.b32  	%r3287, %r1411, %r1383;
	xor.b32  	%r3288, %r3286, %r3287;
	add.s32 	%r3289, %r3282, %r3288;
	add.s32 	%r1467, %r3289, %r3284;
	// begin inline asm
	shf.r.clamp.b32 %r1441, %r1511, %r1511, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1445, %r1511, %r1511, %r2540;
	// end inline asm
	xor.b32  	%r3290, %r1445, %r1441;
	// begin inline asm
	shf.r.clamp.b32 %r1449, %r1511, %r1511, %r4014;
	// end inline asm
	xor.b32  	%r3291, %r3290, %r1449;
	mov.u32 	%r1454, %r1511;
	// begin inline asm
	not.b32  %r1454, %r1454;     
	and.b32  %r1453, %r1454, %r1455; 
	
	// end inline asm
	and.b32  	%r3945, %r1511, %r1483;
	xor.b32  	%r3293, %r1453, %r3945;
	add.s32 	%r3294, %r375, %r1427;
	add.s32 	%r3295, %r3294, %r3291;
	add.s32 	%r3296, %r3295, %r3293;
	add.s32 	%r3297, %r3296, -1740746414;
	add.s32 	%r1539, %r3297, %r1383;
	// begin inline asm
	shf.r.clamp.b32 %r1457, %r1467, %r1467, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1461, %r1467, %r1467, %r2556;
	// end inline asm
	xor.b32  	%r3298, %r1461, %r1457;
	// begin inline asm
	shf.r.clamp.b32 %r1465, %r1467, %r1467, %r2560;
	// end inline asm
	xor.b32  	%r3299, %r3298, %r1465;
	xor.b32  	%r3300, %r1439, %r1411;
	and.b32  	%r3301, %r1467, %r3300;
	and.b32  	%r3302, %r1439, %r1411;
	xor.b32  	%r3303, %r3301, %r3302;
	add.s32 	%r3304, %r3297, %r3303;
	add.s32 	%r1495, %r3304, %r3299;
	// begin inline asm
	shf.r.clamp.b32 %r1469, %r1539, %r1539, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1473, %r1539, %r1539, %r2540;
	// end inline asm
	xor.b32  	%r3305, %r1473, %r1469;
	// begin inline asm
	shf.r.clamp.b32 %r1477, %r1539, %r1539, %r4014;
	// end inline asm
	xor.b32  	%r3306, %r3305, %r1477;
	mov.u32 	%r1482, %r1539;
	// begin inline asm
	not.b32  %r1482, %r1482;     
	and.b32  %r1481, %r1482, %r1483; 
	
	// end inline asm
	and.b32  	%r3944, %r1539, %r1511;
	xor.b32  	%r3308, %r1481, %r3944;
	add.s32 	%r3309, %r391, %r1455;
	add.s32 	%r3310, %r3309, %r3306;
	add.s32 	%r3311, %r3310, %r3308;
	add.s32 	%r3312, %r3311, -1473132947;
	add.s32 	%r1567, %r3312, %r1411;
	// begin inline asm
	shf.r.clamp.b32 %r1485, %r1495, %r1495, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1489, %r1495, %r1495, %r2556;
	// end inline asm
	xor.b32  	%r3313, %r1489, %r1485;
	// begin inline asm
	shf.r.clamp.b32 %r1493, %r1495, %r1495, %r2560;
	// end inline asm
	xor.b32  	%r3314, %r3313, %r1493;
	xor.b32  	%r3315, %r1467, %r1439;
	and.b32  	%r3316, %r1495, %r3315;
	and.b32  	%r3317, %r1467, %r1439;
	xor.b32  	%r3318, %r3316, %r3317;
	add.s32 	%r3319, %r3312, %r3318;
	add.s32 	%r1523, %r3319, %r3314;
	// begin inline asm
	shf.r.clamp.b32 %r1497, %r1567, %r1567, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1501, %r1567, %r1567, %r2540;
	// end inline asm
	xor.b32  	%r3320, %r1501, %r1497;
	// begin inline asm
	shf.r.clamp.b32 %r1505, %r1567, %r1567, %r4014;
	// end inline asm
	xor.b32  	%r3321, %r3320, %r1505;
	mov.u32 	%r1510, %r1567;
	// begin inline asm
	not.b32  %r1510, %r1510;     
	and.b32  %r1509, %r1510, %r1511; 
	
	// end inline asm
	and.b32  	%r3943, %r1567, %r1539;
	xor.b32  	%r3323, %r1509, %r3943;
	add.s32 	%r3324, %r407, %r1483;
	add.s32 	%r3325, %r3324, %r3321;
	add.s32 	%r3326, %r3325, %r3323;
	add.s32 	%r3327, %r3326, -1341970488;
	add.s32 	%r1595, %r3327, %r1439;
	// begin inline asm
	shf.r.clamp.b32 %r1513, %r1523, %r1523, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1517, %r1523, %r1523, %r2556;
	// end inline asm
	xor.b32  	%r3328, %r1517, %r1513;
	// begin inline asm
	shf.r.clamp.b32 %r1521, %r1523, %r1523, %r2560;
	// end inline asm
	xor.b32  	%r3329, %r3328, %r1521;
	xor.b32  	%r3330, %r1495, %r1467;
	and.b32  	%r3331, %r1523, %r3330;
	and.b32  	%r3332, %r1495, %r1467;
	xor.b32  	%r3333, %r3331, %r3332;
	add.s32 	%r3334, %r3327, %r3333;
	add.s32 	%r1551, %r3334, %r3329;
	// begin inline asm
	shf.r.clamp.b32 %r1525, %r1595, %r1595, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1529, %r1595, %r1595, %r2540;
	// end inline asm
	xor.b32  	%r3335, %r1529, %r1525;
	// begin inline asm
	shf.r.clamp.b32 %r1533, %r1595, %r1595, %r4014;
	// end inline asm
	xor.b32  	%r3336, %r3335, %r1533;
	mov.u32 	%r1538, %r1595;
	// begin inline asm
	not.b32  %r1538, %r1538;     
	and.b32  %r1537, %r1538, %r1539; 
	
	// end inline asm
	and.b32  	%r3942, %r1595, %r1567;
	xor.b32  	%r3338, %r1537, %r3942;
	add.s32 	%r3339, %r423, %r1511;
	add.s32 	%r3340, %r3339, %r3336;
	add.s32 	%r3341, %r3340, %r3338;
	add.s32 	%r3342, %r3341, -1084653625;
	add.s32 	%r1623, %r3342, %r1467;
	// begin inline asm
	shf.r.clamp.b32 %r1541, %r1551, %r1551, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1545, %r1551, %r1551, %r2556;
	// end inline asm
	xor.b32  	%r3343, %r1545, %r1541;
	// begin inline asm
	shf.r.clamp.b32 %r1549, %r1551, %r1551, %r2560;
	// end inline asm
	xor.b32  	%r3344, %r3343, %r1549;
	xor.b32  	%r3345, %r1523, %r1495;
	and.b32  	%r3346, %r1551, %r3345;
	and.b32  	%r3347, %r1523, %r1495;
	xor.b32  	%r3348, %r3346, %r3347;
	add.s32 	%r3349, %r3342, %r3348;
	add.s32 	%r1579, %r3349, %r3344;
	// begin inline asm
	shf.r.clamp.b32 %r1553, %r1623, %r1623, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1557, %r1623, %r1623, %r2540;
	// end inline asm
	xor.b32  	%r3350, %r1557, %r1553;
	// begin inline asm
	shf.r.clamp.b32 %r1561, %r1623, %r1623, %r4014;
	// end inline asm
	xor.b32  	%r3351, %r3350, %r1561;
	mov.u32 	%r1566, %r1623;
	// begin inline asm
	not.b32  %r1566, %r1566;     
	and.b32  %r1565, %r1566, %r1567; 
	
	// end inline asm
	and.b32  	%r3941, %r1623, %r1595;
	xor.b32  	%r3353, %r1565, %r3941;
	add.s32 	%r3354, %r439, %r1539;
	add.s32 	%r3355, %r3354, %r3351;
	add.s32 	%r3356, %r3355, %r3353;
	add.s32 	%r3357, %r3356, -958395405;
	add.s32 	%r1651, %r3357, %r1495;
	// begin inline asm
	shf.r.clamp.b32 %r1569, %r1579, %r1579, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1573, %r1579, %r1579, %r2556;
	// end inline asm
	xor.b32  	%r3358, %r1573, %r1569;
	// begin inline asm
	shf.r.clamp.b32 %r1577, %r1579, %r1579, %r2560;
	// end inline asm
	xor.b32  	%r3359, %r3358, %r1577;
	xor.b32  	%r3360, %r1551, %r1523;
	and.b32  	%r3361, %r1579, %r3360;
	and.b32  	%r3362, %r1551, %r1523;
	xor.b32  	%r3363, %r3361, %r3362;
	add.s32 	%r3364, %r3357, %r3363;
	add.s32 	%r1607, %r3364, %r3359;
	// begin inline asm
	shf.r.clamp.b32 %r1581, %r1651, %r1651, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1585, %r1651, %r1651, %r2540;
	// end inline asm
	xor.b32  	%r3365, %r1585, %r1581;
	// begin inline asm
	shf.r.clamp.b32 %r1589, %r1651, %r1651, %r4014;
	// end inline asm
	xor.b32  	%r3366, %r3365, %r1589;
	mov.u32 	%r1594, %r1651;
	// begin inline asm
	not.b32  %r1594, %r1594;     
	and.b32  %r1593, %r1594, %r1595; 
	
	// end inline asm
	and.b32  	%r3940, %r1651, %r1623;
	xor.b32  	%r3368, %r1593, %r3940;
	add.s32 	%r3369, %r455, %r1567;
	add.s32 	%r3370, %r3369, %r3366;
	add.s32 	%r3371, %r3370, %r3368;
	add.s32 	%r3372, %r3371, -710438585;
	add.s32 	%r1679, %r3372, %r1523;
	// begin inline asm
	shf.r.clamp.b32 %r1597, %r1607, %r1607, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1601, %r1607, %r1607, %r2556;
	// end inline asm
	xor.b32  	%r3373, %r1601, %r1597;
	// begin inline asm
	shf.r.clamp.b32 %r1605, %r1607, %r1607, %r2560;
	// end inline asm
	xor.b32  	%r3374, %r3373, %r1605;
	xor.b32  	%r3375, %r1579, %r1551;
	and.b32  	%r3376, %r1607, %r3375;
	and.b32  	%r3377, %r1579, %r1551;
	xor.b32  	%r3378, %r3376, %r3377;
	add.s32 	%r3379, %r3372, %r3378;
	add.s32 	%r1635, %r3379, %r3374;
	// begin inline asm
	shf.r.clamp.b32 %r1609, %r1679, %r1679, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1613, %r1679, %r1679, %r2540;
	// end inline asm
	xor.b32  	%r3380, %r1613, %r1609;
	// begin inline asm
	shf.r.clamp.b32 %r1617, %r1679, %r1679, %r4014;
	// end inline asm
	xor.b32  	%r3381, %r3380, %r1617;
	mov.u32 	%r1622, %r1679;
	// begin inline asm
	not.b32  %r1622, %r1622;     
	and.b32  %r1621, %r1622, %r1623; 
	
	// end inline asm
	and.b32  	%r3939, %r1679, %r1651;
	xor.b32  	%r3383, %r1621, %r3939;
	add.s32 	%r3384, %r471, %r1595;
	add.s32 	%r3385, %r3384, %r3381;
	add.s32 	%r3386, %r3385, %r3383;
	add.s32 	%r3387, %r3386, 113926993;
	add.s32 	%r1707, %r3387, %r1551;
	// begin inline asm
	shf.r.clamp.b32 %r1625, %r1635, %r1635, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1629, %r1635, %r1635, %r2556;
	// end inline asm
	xor.b32  	%r3388, %r1629, %r1625;
	// begin inline asm
	shf.r.clamp.b32 %r1633, %r1635, %r1635, %r2560;
	// end inline asm
	xor.b32  	%r3389, %r3388, %r1633;
	xor.b32  	%r3390, %r1607, %r1579;
	and.b32  	%r3391, %r1635, %r3390;
	and.b32  	%r3392, %r1607, %r1579;
	xor.b32  	%r3393, %r3391, %r3392;
	add.s32 	%r3394, %r3387, %r3393;
	add.s32 	%r1663, %r3394, %r3389;
	// begin inline asm
	shf.r.clamp.b32 %r1637, %r1707, %r1707, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1641, %r1707, %r1707, %r2540;
	// end inline asm
	xor.b32  	%r3395, %r1641, %r1637;
	// begin inline asm
	shf.r.clamp.b32 %r1645, %r1707, %r1707, %r4014;
	// end inline asm
	xor.b32  	%r3396, %r3395, %r1645;
	mov.u32 	%r1650, %r1707;
	// begin inline asm
	not.b32  %r1650, %r1650;     
	and.b32  %r1649, %r1650, %r1651; 
	
	// end inline asm
	and.b32  	%r3938, %r1707, %r1679;
	xor.b32  	%r3398, %r1649, %r3938;
	add.s32 	%r3399, %r487, %r1623;
	add.s32 	%r3400, %r3399, %r3396;
	add.s32 	%r3401, %r3400, %r3398;
	add.s32 	%r3402, %r3401, 338241895;
	add.s32 	%r1735, %r3402, %r1579;
	// begin inline asm
	shf.r.clamp.b32 %r1653, %r1663, %r1663, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1657, %r1663, %r1663, %r2556;
	// end inline asm
	xor.b32  	%r3403, %r1657, %r1653;
	// begin inline asm
	shf.r.clamp.b32 %r1661, %r1663, %r1663, %r2560;
	// end inline asm
	xor.b32  	%r3404, %r3403, %r1661;
	xor.b32  	%r3405, %r1635, %r1607;
	and.b32  	%r3406, %r1663, %r3405;
	and.b32  	%r3407, %r1635, %r1607;
	xor.b32  	%r3408, %r3406, %r3407;
	add.s32 	%r3409, %r3402, %r3408;
	add.s32 	%r1691, %r3409, %r3404;
	// begin inline asm
	shf.r.clamp.b32 %r1665, %r1735, %r1735, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1669, %r1735, %r1735, %r2540;
	// end inline asm
	xor.b32  	%r3410, %r1669, %r1665;
	// begin inline asm
	shf.r.clamp.b32 %r1673, %r1735, %r1735, %r4014;
	// end inline asm
	xor.b32  	%r3411, %r3410, %r1673;
	mov.u32 	%r1678, %r1735;
	// begin inline asm
	not.b32  %r1678, %r1678;     
	and.b32  %r1677, %r1678, %r1679; 
	
	// end inline asm
	and.b32  	%r3937, %r1735, %r1707;
	xor.b32  	%r3413, %r1677, %r3937;
	add.s32 	%r3414, %r503, %r1651;
	add.s32 	%r3415, %r3414, %r3411;
	add.s32 	%r3416, %r3415, %r3413;
	add.s32 	%r3417, %r3416, 666307205;
	add.s32 	%r1763, %r3417, %r1607;
	// begin inline asm
	shf.r.clamp.b32 %r1681, %r1691, %r1691, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1685, %r1691, %r1691, %r2556;
	// end inline asm
	xor.b32  	%r3418, %r1685, %r1681;
	// begin inline asm
	shf.r.clamp.b32 %r1689, %r1691, %r1691, %r2560;
	// end inline asm
	xor.b32  	%r3419, %r3418, %r1689;
	xor.b32  	%r3420, %r1663, %r1635;
	and.b32  	%r3421, %r1691, %r3420;
	and.b32  	%r3422, %r1663, %r1635;
	xor.b32  	%r3423, %r3421, %r3422;
	add.s32 	%r3424, %r3417, %r3423;
	add.s32 	%r1719, %r3424, %r3419;
	// begin inline asm
	shf.r.clamp.b32 %r1693, %r1763, %r1763, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1697, %r1763, %r1763, %r2540;
	// end inline asm
	xor.b32  	%r3425, %r1697, %r1693;
	// begin inline asm
	shf.r.clamp.b32 %r1701, %r1763, %r1763, %r4014;
	// end inline asm
	xor.b32  	%r3426, %r3425, %r1701;
	mov.u32 	%r1706, %r1763;
	// begin inline asm
	not.b32  %r1706, %r1706;     
	and.b32  %r1705, %r1706, %r1707; 
	
	// end inline asm
	and.b32  	%r3936, %r1763, %r1735;
	xor.b32  	%r3428, %r1705, %r3936;
	add.s32 	%r3429, %r519, %r1679;
	add.s32 	%r3430, %r3429, %r3426;
	add.s32 	%r3431, %r3430, %r3428;
	add.s32 	%r3432, %r3431, 773529912;
	add.s32 	%r1791, %r3432, %r1635;
	// begin inline asm
	shf.r.clamp.b32 %r1709, %r1719, %r1719, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1713, %r1719, %r1719, %r2556;
	// end inline asm
	xor.b32  	%r3433, %r1713, %r1709;
	// begin inline asm
	shf.r.clamp.b32 %r1717, %r1719, %r1719, %r2560;
	// end inline asm
	xor.b32  	%r3434, %r3433, %r1717;
	xor.b32  	%r3435, %r1691, %r1663;
	and.b32  	%r3436, %r1719, %r3435;
	and.b32  	%r3437, %r1691, %r1663;
	xor.b32  	%r3438, %r3436, %r3437;
	add.s32 	%r3439, %r3432, %r3438;
	add.s32 	%r1747, %r3439, %r3434;
	// begin inline asm
	shf.r.clamp.b32 %r1721, %r1791, %r1791, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1725, %r1791, %r1791, %r2540;
	// end inline asm
	xor.b32  	%r3440, %r1725, %r1721;
	// begin inline asm
	shf.r.clamp.b32 %r1729, %r1791, %r1791, %r4014;
	// end inline asm
	xor.b32  	%r3441, %r3440, %r1729;
	mov.u32 	%r1734, %r1791;
	// begin inline asm
	not.b32  %r1734, %r1734;     
	and.b32  %r1733, %r1734, %r1735; 
	
	// end inline asm
	and.b32  	%r3935, %r1791, %r1763;
	xor.b32  	%r3443, %r1733, %r3935;
	add.s32 	%r3444, %r535, %r1707;
	add.s32 	%r3445, %r3444, %r3441;
	add.s32 	%r3446, %r3445, %r3443;
	add.s32 	%r3447, %r3446, 1294757372;
	add.s32 	%r1819, %r3447, %r1663;
	// begin inline asm
	shf.r.clamp.b32 %r1737, %r1747, %r1747, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1741, %r1747, %r1747, %r2556;
	// end inline asm
	xor.b32  	%r3448, %r1741, %r1737;
	// begin inline asm
	shf.r.clamp.b32 %r1745, %r1747, %r1747, %r2560;
	// end inline asm
	xor.b32  	%r3449, %r3448, %r1745;
	xor.b32  	%r3450, %r1719, %r1691;
	and.b32  	%r3451, %r1747, %r3450;
	and.b32  	%r3452, %r1719, %r1691;
	xor.b32  	%r3453, %r3451, %r3452;
	add.s32 	%r3454, %r3447, %r3453;
	add.s32 	%r1775, %r3454, %r3449;
	// begin inline asm
	shf.r.clamp.b32 %r1749, %r1819, %r1819, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1753, %r1819, %r1819, %r2540;
	// end inline asm
	xor.b32  	%r3455, %r1753, %r1749;
	// begin inline asm
	shf.r.clamp.b32 %r1757, %r1819, %r1819, %r4014;
	// end inline asm
	xor.b32  	%r3456, %r3455, %r1757;
	mov.u32 	%r1762, %r1819;
	// begin inline asm
	not.b32  %r1762, %r1762;     
	and.b32  %r1761, %r1762, %r1763; 
	
	// end inline asm
	and.b32  	%r3934, %r1819, %r1791;
	xor.b32  	%r3458, %r1761, %r3934;
	add.s32 	%r3459, %r551, %r1735;
	add.s32 	%r3460, %r3459, %r3456;
	add.s32 	%r3461, %r3460, %r3458;
	add.s32 	%r3462, %r3461, 1396182291;
	add.s32 	%r1847, %r3462, %r1691;
	// begin inline asm
	shf.r.clamp.b32 %r1765, %r1775, %r1775, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1769, %r1775, %r1775, %r2556;
	// end inline asm
	xor.b32  	%r3463, %r1769, %r1765;
	// begin inline asm
	shf.r.clamp.b32 %r1773, %r1775, %r1775, %r2560;
	// end inline asm
	xor.b32  	%r3464, %r3463, %r1773;
	xor.b32  	%r3465, %r1747, %r1719;
	and.b32  	%r3466, %r1775, %r3465;
	and.b32  	%r3467, %r1747, %r1719;
	xor.b32  	%r3468, %r3466, %r3467;
	add.s32 	%r3469, %r3462, %r3468;
	add.s32 	%r1803, %r3469, %r3464;
	// begin inline asm
	shf.r.clamp.b32 %r1777, %r1847, %r1847, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1781, %r1847, %r1847, %r2540;
	// end inline asm
	xor.b32  	%r3470, %r1781, %r1777;
	// begin inline asm
	shf.r.clamp.b32 %r1785, %r1847, %r1847, %r4014;
	// end inline asm
	xor.b32  	%r3471, %r3470, %r1785;
	mov.u32 	%r1790, %r1847;
	// begin inline asm
	not.b32  %r1790, %r1790;     
	and.b32  %r1789, %r1790, %r1791; 
	
	// end inline asm
	and.b32  	%r3933, %r1847, %r1819;
	xor.b32  	%r3473, %r1789, %r3933;
	add.s32 	%r3474, %r567, %r1763;
	add.s32 	%r3475, %r3474, %r3471;
	add.s32 	%r3476, %r3475, %r3473;
	add.s32 	%r3477, %r3476, 1695183700;
	add.s32 	%r1875, %r3477, %r1719;
	// begin inline asm
	shf.r.clamp.b32 %r1793, %r1803, %r1803, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1797, %r1803, %r1803, %r2556;
	// end inline asm
	xor.b32  	%r3478, %r1797, %r1793;
	// begin inline asm
	shf.r.clamp.b32 %r1801, %r1803, %r1803, %r2560;
	// end inline asm
	xor.b32  	%r3479, %r3478, %r1801;
	xor.b32  	%r3480, %r1775, %r1747;
	and.b32  	%r3481, %r1803, %r3480;
	and.b32  	%r3482, %r1775, %r1747;
	xor.b32  	%r3483, %r3481, %r3482;
	add.s32 	%r3484, %r3477, %r3483;
	add.s32 	%r1831, %r3484, %r3479;
	// begin inline asm
	shf.r.clamp.b32 %r1805, %r1875, %r1875, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1809, %r1875, %r1875, %r2540;
	// end inline asm
	xor.b32  	%r3485, %r1809, %r1805;
	// begin inline asm
	shf.r.clamp.b32 %r1813, %r1875, %r1875, %r4014;
	// end inline asm
	xor.b32  	%r3486, %r3485, %r1813;
	mov.u32 	%r1818, %r1875;
	// begin inline asm
	not.b32  %r1818, %r1818;     
	and.b32  %r1817, %r1818, %r1819; 
	
	// end inline asm
	and.b32  	%r3932, %r1875, %r1847;
	xor.b32  	%r3488, %r1817, %r3932;
	add.s32 	%r3489, %r583, %r1791;
	add.s32 	%r3490, %r3489, %r3486;
	add.s32 	%r3491, %r3490, %r3488;
	add.s32 	%r3492, %r3491, 1986661051;
	add.s32 	%r1903, %r3492, %r1747;
	// begin inline asm
	shf.r.clamp.b32 %r1821, %r1831, %r1831, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1825, %r1831, %r1831, %r2556;
	// end inline asm
	xor.b32  	%r3493, %r1825, %r1821;
	// begin inline asm
	shf.r.clamp.b32 %r1829, %r1831, %r1831, %r2560;
	// end inline asm
	xor.b32  	%r3494, %r3493, %r1829;
	xor.b32  	%r3495, %r1803, %r1775;
	and.b32  	%r3496, %r1831, %r3495;
	and.b32  	%r3497, %r1803, %r1775;
	xor.b32  	%r3498, %r3496, %r3497;
	add.s32 	%r3499, %r3492, %r3498;
	add.s32 	%r1859, %r3499, %r3494;
	// begin inline asm
	shf.r.clamp.b32 %r1833, %r1903, %r1903, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1837, %r1903, %r1903, %r2540;
	// end inline asm
	xor.b32  	%r3500, %r1837, %r1833;
	// begin inline asm
	shf.r.clamp.b32 %r1841, %r1903, %r1903, %r4014;
	// end inline asm
	xor.b32  	%r3501, %r3500, %r1841;
	mov.u32 	%r1846, %r1903;
	// begin inline asm
	not.b32  %r1846, %r1846;     
	and.b32  %r1845, %r1846, %r1847; 
	
	// end inline asm
	and.b32  	%r3931, %r1903, %r1875;
	xor.b32  	%r3503, %r1845, %r3931;
	add.s32 	%r3504, %r599, %r1819;
	add.s32 	%r3505, %r3504, %r3501;
	add.s32 	%r3506, %r3505, %r3503;
	add.s32 	%r3507, %r3506, -2117940946;
	add.s32 	%r1931, %r3507, %r1775;
	// begin inline asm
	shf.r.clamp.b32 %r1849, %r1859, %r1859, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1853, %r1859, %r1859, %r2556;
	// end inline asm
	xor.b32  	%r3508, %r1853, %r1849;
	// begin inline asm
	shf.r.clamp.b32 %r1857, %r1859, %r1859, %r2560;
	// end inline asm
	xor.b32  	%r3509, %r3508, %r1857;
	xor.b32  	%r3510, %r1831, %r1803;
	and.b32  	%r3511, %r1859, %r3510;
	and.b32  	%r3512, %r1831, %r1803;
	xor.b32  	%r3513, %r3511, %r3512;
	add.s32 	%r3514, %r3507, %r3513;
	add.s32 	%r1887, %r3514, %r3509;
	// begin inline asm
	shf.r.clamp.b32 %r1861, %r1931, %r1931, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1865, %r1931, %r1931, %r2540;
	// end inline asm
	xor.b32  	%r3515, %r1865, %r1861;
	// begin inline asm
	shf.r.clamp.b32 %r1869, %r1931, %r1931, %r4014;
	// end inline asm
	xor.b32  	%r3516, %r3515, %r1869;
	mov.u32 	%r1874, %r1931;
	// begin inline asm
	not.b32  %r1874, %r1874;     
	and.b32  %r1873, %r1874, %r1875; 
	
	// end inline asm
	and.b32  	%r3930, %r1931, %r1903;
	xor.b32  	%r3518, %r1873, %r3930;
	add.s32 	%r3519, %r615, %r1847;
	add.s32 	%r3520, %r3519, %r3516;
	add.s32 	%r3521, %r3520, %r3518;
	add.s32 	%r3522, %r3521, -1838011259;
	add.s32 	%r1959, %r3522, %r1803;
	// begin inline asm
	shf.r.clamp.b32 %r1877, %r1887, %r1887, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1881, %r1887, %r1887, %r2556;
	// end inline asm
	xor.b32  	%r3523, %r1881, %r1877;
	// begin inline asm
	shf.r.clamp.b32 %r1885, %r1887, %r1887, %r2560;
	// end inline asm
	xor.b32  	%r3524, %r3523, %r1885;
	xor.b32  	%r3525, %r1859, %r1831;
	and.b32  	%r3526, %r1887, %r3525;
	and.b32  	%r3527, %r1859, %r1831;
	xor.b32  	%r3528, %r3526, %r3527;
	add.s32 	%r3529, %r3522, %r3528;
	add.s32 	%r1915, %r3529, %r3524;
	// begin inline asm
	shf.r.clamp.b32 %r1889, %r1959, %r1959, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1893, %r1959, %r1959, %r2540;
	// end inline asm
	xor.b32  	%r3530, %r1893, %r1889;
	// begin inline asm
	shf.r.clamp.b32 %r1897, %r1959, %r1959, %r4014;
	// end inline asm
	xor.b32  	%r3531, %r3530, %r1897;
	mov.u32 	%r1902, %r1959;
	// begin inline asm
	not.b32  %r1902, %r1902;     
	and.b32  %r1901, %r1902, %r1903; 
	
	// end inline asm
	and.b32  	%r3929, %r1959, %r1931;
	xor.b32  	%r3533, %r1901, %r3929;
	add.s32 	%r3534, %r631, %r1875;
	add.s32 	%r3535, %r3534, %r3531;
	add.s32 	%r3536, %r3535, %r3533;
	add.s32 	%r3537, %r3536, -1564481375;
	add.s32 	%r1987, %r3537, %r1831;
	// begin inline asm
	shf.r.clamp.b32 %r1905, %r1915, %r1915, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1909, %r1915, %r1915, %r2556;
	// end inline asm
	xor.b32  	%r3538, %r1909, %r1905;
	// begin inline asm
	shf.r.clamp.b32 %r1913, %r1915, %r1915, %r2560;
	// end inline asm
	xor.b32  	%r3539, %r3538, %r1913;
	xor.b32  	%r3540, %r1887, %r1859;
	and.b32  	%r3541, %r1915, %r3540;
	and.b32  	%r3542, %r1887, %r1859;
	xor.b32  	%r3543, %r3541, %r3542;
	add.s32 	%r3544, %r3537, %r3543;
	add.s32 	%r1943, %r3544, %r3539;
	// begin inline asm
	shf.r.clamp.b32 %r1917, %r1987, %r1987, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1921, %r1987, %r1987, %r2540;
	// end inline asm
	xor.b32  	%r3545, %r1921, %r1917;
	// begin inline asm
	shf.r.clamp.b32 %r1925, %r1987, %r1987, %r4014;
	// end inline asm
	xor.b32  	%r3546, %r3545, %r1925;
	mov.u32 	%r1930, %r1987;
	// begin inline asm
	not.b32  %r1930, %r1930;     
	and.b32  %r1929, %r1930, %r1931; 
	
	// end inline asm
	and.b32  	%r3928, %r1987, %r1959;
	xor.b32  	%r3548, %r1929, %r3928;
	add.s32 	%r3549, %r647, %r1903;
	add.s32 	%r3550, %r3549, %r3546;
	add.s32 	%r3551, %r3550, %r3548;
	add.s32 	%r3552, %r3551, -1474664885;
	add.s32 	%r2015, %r3552, %r1859;
	// begin inline asm
	shf.r.clamp.b32 %r1933, %r1943, %r1943, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1937, %r1943, %r1943, %r2556;
	// end inline asm
	xor.b32  	%r3553, %r1937, %r1933;
	// begin inline asm
	shf.r.clamp.b32 %r1941, %r1943, %r1943, %r2560;
	// end inline asm
	xor.b32  	%r3554, %r3553, %r1941;
	xor.b32  	%r3555, %r1915, %r1887;
	and.b32  	%r3556, %r1943, %r3555;
	and.b32  	%r3557, %r1915, %r1887;
	xor.b32  	%r3558, %r3556, %r3557;
	add.s32 	%r3559, %r3552, %r3558;
	add.s32 	%r1971, %r3559, %r3554;
	// begin inline asm
	shf.r.clamp.b32 %r1945, %r2015, %r2015, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1949, %r2015, %r2015, %r2540;
	// end inline asm
	xor.b32  	%r3560, %r1949, %r1945;
	// begin inline asm
	shf.r.clamp.b32 %r1953, %r2015, %r2015, %r4014;
	// end inline asm
	xor.b32  	%r3561, %r3560, %r1953;
	mov.u32 	%r1958, %r2015;
	// begin inline asm
	not.b32  %r1958, %r1958;     
	and.b32  %r1957, %r1958, %r1959; 
	
	// end inline asm
	and.b32  	%r3927, %r2015, %r1987;
	xor.b32  	%r3563, %r1957, %r3927;
	add.s32 	%r3564, %r663, %r1931;
	add.s32 	%r3565, %r3564, %r3561;
	add.s32 	%r3566, %r3565, %r3563;
	add.s32 	%r3567, %r3566, -1035236496;
	add.s32 	%r2043, %r3567, %r1887;
	// begin inline asm
	shf.r.clamp.b32 %r1961, %r1971, %r1971, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1965, %r1971, %r1971, %r2556;
	// end inline asm
	xor.b32  	%r3568, %r1965, %r1961;
	// begin inline asm
	shf.r.clamp.b32 %r1969, %r1971, %r1971, %r2560;
	// end inline asm
	xor.b32  	%r3569, %r3568, %r1969;
	xor.b32  	%r3570, %r1943, %r1915;
	and.b32  	%r3571, %r1971, %r3570;
	and.b32  	%r3572, %r1943, %r1915;
	xor.b32  	%r3573, %r3571, %r3572;
	add.s32 	%r3574, %r3567, %r3573;
	add.s32 	%r1999, %r3574, %r3569;
	// begin inline asm
	shf.r.clamp.b32 %r1973, %r2043, %r2043, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1977, %r2043, %r2043, %r2540;
	// end inline asm
	xor.b32  	%r3575, %r1977, %r1973;
	// begin inline asm
	shf.r.clamp.b32 %r1981, %r2043, %r2043, %r4014;
	// end inline asm
	xor.b32  	%r3576, %r3575, %r1981;
	mov.u32 	%r1986, %r2043;
	// begin inline asm
	not.b32  %r1986, %r1986;     
	and.b32  %r1985, %r1986, %r1987; 
	
	// end inline asm
	and.b32  	%r3926, %r2043, %r2015;
	xor.b32  	%r3578, %r1985, %r3926;
	add.s32 	%r3579, %r679, %r1959;
	add.s32 	%r3580, %r3579, %r3576;
	add.s32 	%r3581, %r3580, %r3578;
	add.s32 	%r3582, %r3581, -949202525;
	add.s32 	%r2071, %r3582, %r1915;
	// begin inline asm
	shf.r.clamp.b32 %r1989, %r1999, %r1999, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r1993, %r1999, %r1999, %r2556;
	// end inline asm
	xor.b32  	%r3583, %r1993, %r1989;
	// begin inline asm
	shf.r.clamp.b32 %r1997, %r1999, %r1999, %r2560;
	// end inline asm
	xor.b32  	%r3584, %r3583, %r1997;
	xor.b32  	%r3585, %r1971, %r1943;
	and.b32  	%r3586, %r1999, %r3585;
	and.b32  	%r3587, %r1971, %r1943;
	xor.b32  	%r3588, %r3586, %r3587;
	add.s32 	%r3589, %r3582, %r3588;
	add.s32 	%r2027, %r3589, %r3584;
	// begin inline asm
	shf.r.clamp.b32 %r2001, %r2071, %r2071, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2005, %r2071, %r2071, %r2540;
	// end inline asm
	xor.b32  	%r3590, %r2005, %r2001;
	// begin inline asm
	shf.r.clamp.b32 %r2009, %r2071, %r2071, %r4014;
	// end inline asm
	xor.b32  	%r3591, %r3590, %r2009;
	mov.u32 	%r2014, %r2071;
	// begin inline asm
	not.b32  %r2014, %r2014;     
	and.b32  %r2013, %r2014, %r2015; 
	
	// end inline asm
	and.b32  	%r3925, %r2071, %r2043;
	xor.b32  	%r3593, %r2013, %r3925;
	add.s32 	%r3594, %r695, %r1987;
	add.s32 	%r3595, %r3594, %r3591;
	add.s32 	%r3596, %r3595, %r3593;
	add.s32 	%r3597, %r3596, -778901479;
	add.s32 	%r2099, %r3597, %r1943;
	// begin inline asm
	shf.r.clamp.b32 %r2017, %r2027, %r2027, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2021, %r2027, %r2027, %r2556;
	// end inline asm
	xor.b32  	%r3598, %r2021, %r2017;
	// begin inline asm
	shf.r.clamp.b32 %r2025, %r2027, %r2027, %r2560;
	// end inline asm
	xor.b32  	%r3599, %r3598, %r2025;
	xor.b32  	%r3600, %r1999, %r1971;
	and.b32  	%r3601, %r2027, %r3600;
	and.b32  	%r3602, %r1999, %r1971;
	xor.b32  	%r3603, %r3601, %r3602;
	add.s32 	%r3604, %r3597, %r3603;
	add.s32 	%r2055, %r3604, %r3599;
	// begin inline asm
	shf.r.clamp.b32 %r2029, %r2099, %r2099, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2033, %r2099, %r2099, %r2540;
	// end inline asm
	xor.b32  	%r3605, %r2033, %r2029;
	// begin inline asm
	shf.r.clamp.b32 %r2037, %r2099, %r2099, %r4014;
	// end inline asm
	xor.b32  	%r3606, %r3605, %r2037;
	mov.u32 	%r2042, %r2099;
	// begin inline asm
	not.b32  %r2042, %r2042;     
	and.b32  %r2041, %r2042, %r2043; 
	
	// end inline asm
	and.b32  	%r3924, %r2099, %r2071;
	xor.b32  	%r3608, %r2041, %r3924;
	add.s32 	%r3609, %r711, %r2015;
	add.s32 	%r3610, %r3609, %r3606;
	add.s32 	%r3611, %r3610, %r3608;
	add.s32 	%r3612, %r3611, -694614492;
	add.s32 	%r2127, %r3612, %r1971;
	// begin inline asm
	shf.r.clamp.b32 %r2045, %r2055, %r2055, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2049, %r2055, %r2055, %r2556;
	// end inline asm
	xor.b32  	%r3613, %r2049, %r2045;
	// begin inline asm
	shf.r.clamp.b32 %r2053, %r2055, %r2055, %r2560;
	// end inline asm
	xor.b32  	%r3614, %r3613, %r2053;
	xor.b32  	%r3615, %r2027, %r1999;
	and.b32  	%r3616, %r2055, %r3615;
	and.b32  	%r3617, %r2027, %r1999;
	xor.b32  	%r3618, %r3616, %r3617;
	add.s32 	%r3619, %r3612, %r3618;
	add.s32 	%r2083, %r3619, %r3614;
	// begin inline asm
	shf.r.clamp.b32 %r2057, %r2127, %r2127, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2061, %r2127, %r2127, %r2540;
	// end inline asm
	xor.b32  	%r3620, %r2061, %r2057;
	// begin inline asm
	shf.r.clamp.b32 %r2065, %r2127, %r2127, %r4014;
	// end inline asm
	xor.b32  	%r3621, %r3620, %r2065;
	mov.u32 	%r2070, %r2127;
	// begin inline asm
	not.b32  %r2070, %r2070;     
	and.b32  %r2069, %r2070, %r2071; 
	
	// end inline asm
	and.b32  	%r3923, %r2127, %r2099;
	xor.b32  	%r3623, %r2069, %r3923;
	add.s32 	%r3624, %r727, %r2043;
	add.s32 	%r3625, %r3624, %r3621;
	add.s32 	%r3626, %r3625, %r3623;
	add.s32 	%r3627, %r3626, -200395387;
	add.s32 	%r2155, %r3627, %r1999;
	// begin inline asm
	shf.r.clamp.b32 %r2073, %r2083, %r2083, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2077, %r2083, %r2083, %r2556;
	// end inline asm
	xor.b32  	%r3628, %r2077, %r2073;
	// begin inline asm
	shf.r.clamp.b32 %r2081, %r2083, %r2083, %r2560;
	// end inline asm
	xor.b32  	%r3629, %r3628, %r2081;
	xor.b32  	%r3630, %r2055, %r2027;
	and.b32  	%r3631, %r2083, %r3630;
	and.b32  	%r3632, %r2055, %r2027;
	xor.b32  	%r3633, %r3631, %r3632;
	add.s32 	%r3634, %r3627, %r3633;
	add.s32 	%r2111, %r3634, %r3629;
	// begin inline asm
	shf.r.clamp.b32 %r2085, %r2155, %r2155, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2089, %r2155, %r2155, %r2540;
	// end inline asm
	xor.b32  	%r3635, %r2089, %r2085;
	// begin inline asm
	shf.r.clamp.b32 %r2093, %r2155, %r2155, %r4014;
	// end inline asm
	xor.b32  	%r3636, %r3635, %r2093;
	mov.u32 	%r2098, %r2155;
	// begin inline asm
	not.b32  %r2098, %r2098;     
	and.b32  %r2097, %r2098, %r2099; 
	
	// end inline asm
	and.b32  	%r3922, %r2155, %r2127;
	xor.b32  	%r3638, %r2097, %r3922;
	add.s32 	%r3639, %r743, %r2071;
	add.s32 	%r3640, %r3639, %r3636;
	add.s32 	%r3641, %r3640, %r3638;
	add.s32 	%r3642, %r3641, 275423344;
	add.s32 	%r2183, %r3642, %r2027;
	// begin inline asm
	shf.r.clamp.b32 %r2101, %r2111, %r2111, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2105, %r2111, %r2111, %r2556;
	// end inline asm
	xor.b32  	%r3643, %r2105, %r2101;
	// begin inline asm
	shf.r.clamp.b32 %r2109, %r2111, %r2111, %r2560;
	// end inline asm
	xor.b32  	%r3644, %r3643, %r2109;
	xor.b32  	%r3645, %r2083, %r2055;
	and.b32  	%r3646, %r2111, %r3645;
	and.b32  	%r3647, %r2083, %r2055;
	xor.b32  	%r3648, %r3646, %r3647;
	add.s32 	%r3649, %r3642, %r3648;
	add.s32 	%r2139, %r3649, %r3644;
	// begin inline asm
	shf.r.clamp.b32 %r2113, %r2183, %r2183, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2117, %r2183, %r2183, %r2540;
	// end inline asm
	xor.b32  	%r3650, %r2117, %r2113;
	// begin inline asm
	shf.r.clamp.b32 %r2121, %r2183, %r2183, %r4014;
	// end inline asm
	xor.b32  	%r3651, %r3650, %r2121;
	mov.u32 	%r2126, %r2183;
	// begin inline asm
	not.b32  %r2126, %r2126;     
	and.b32  %r2125, %r2126, %r2127; 
	
	// end inline asm
	and.b32  	%r3921, %r2183, %r2155;
	xor.b32  	%r3653, %r2125, %r3921;
	add.s32 	%r3654, %r759, %r2099;
	add.s32 	%r3655, %r3654, %r3651;
	add.s32 	%r3656, %r3655, %r3653;
	add.s32 	%r3657, %r3656, 430227734;
	add.s32 	%r2211, %r3657, %r2055;
	// begin inline asm
	shf.r.clamp.b32 %r2129, %r2139, %r2139, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2133, %r2139, %r2139, %r2556;
	// end inline asm
	xor.b32  	%r3658, %r2133, %r2129;
	// begin inline asm
	shf.r.clamp.b32 %r2137, %r2139, %r2139, %r2560;
	// end inline asm
	xor.b32  	%r3659, %r3658, %r2137;
	xor.b32  	%r3660, %r2111, %r2083;
	and.b32  	%r3661, %r2139, %r3660;
	and.b32  	%r3662, %r2111, %r2083;
	xor.b32  	%r3663, %r3661, %r3662;
	add.s32 	%r3664, %r3657, %r3663;
	add.s32 	%r2167, %r3664, %r3659;
	// begin inline asm
	shf.r.clamp.b32 %r2141, %r2211, %r2211, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2145, %r2211, %r2211, %r2540;
	// end inline asm
	xor.b32  	%r3665, %r2145, %r2141;
	// begin inline asm
	shf.r.clamp.b32 %r2149, %r2211, %r2211, %r4014;
	// end inline asm
	xor.b32  	%r3666, %r3665, %r2149;
	mov.u32 	%r2154, %r2211;
	// begin inline asm
	not.b32  %r2154, %r2154;     
	and.b32  %r2153, %r2154, %r2155; 
	
	// end inline asm
	and.b32  	%r3920, %r2211, %r2183;
	xor.b32  	%r3668, %r2153, %r3920;
	add.s32 	%r3669, %r575, %r2127;
	add.s32 	%r3670, %r3669, %r3666;
	add.s32 	%r3671, %r3670, %r3668;
	add.s32 	%r3672, %r3671, 506948616;
	add.s32 	%r2239, %r3672, %r2083;
	// begin inline asm
	shf.r.clamp.b32 %r2157, %r2167, %r2167, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2161, %r2167, %r2167, %r2556;
	// end inline asm
	xor.b32  	%r3673, %r2161, %r2157;
	// begin inline asm
	shf.r.clamp.b32 %r2165, %r2167, %r2167, %r2560;
	// end inline asm
	xor.b32  	%r3674, %r3673, %r2165;
	xor.b32  	%r3675, %r2139, %r2111;
	and.b32  	%r3676, %r2167, %r3675;
	and.b32  	%r3677, %r2139, %r2111;
	xor.b32  	%r3678, %r3676, %r3677;
	add.s32 	%r3679, %r3672, %r3678;
	add.s32 	%r2195, %r3679, %r3674;
	// begin inline asm
	shf.r.clamp.b32 %r2169, %r2239, %r2239, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2173, %r2239, %r2239, %r2540;
	// end inline asm
	xor.b32  	%r3680, %r2173, %r2169;
	// begin inline asm
	shf.r.clamp.b32 %r2177, %r2239, %r2239, %r4014;
	// end inline asm
	xor.b32  	%r3681, %r3680, %r2177;
	mov.u32 	%r2182, %r2239;
	// begin inline asm
	not.b32  %r2182, %r2182;     
	and.b32  %r2181, %r2182, %r2183; 
	
	// end inline asm
	and.b32  	%r3919, %r2239, %r2211;
	xor.b32  	%r3683, %r2181, %r3919;
	add.s32 	%r3684, %r591, %r2155;
	add.s32 	%r3685, %r3684, %r3681;
	add.s32 	%r3686, %r3685, %r3683;
	add.s32 	%r3687, %r3686, 659060556;
	add.s32 	%r2267, %r3687, %r2111;
	// begin inline asm
	shf.r.clamp.b32 %r2185, %r2195, %r2195, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2189, %r2195, %r2195, %r2556;
	// end inline asm
	xor.b32  	%r3688, %r2189, %r2185;
	// begin inline asm
	shf.r.clamp.b32 %r2193, %r2195, %r2195, %r2560;
	// end inline asm
	xor.b32  	%r3689, %r3688, %r2193;
	xor.b32  	%r3690, %r2167, %r2139;
	and.b32  	%r3691, %r2195, %r3690;
	and.b32  	%r3692, %r2167, %r2139;
	xor.b32  	%r3693, %r3691, %r3692;
	add.s32 	%r3694, %r3687, %r3693;
	add.s32 	%r2223, %r3694, %r3689;
	// begin inline asm
	shf.r.clamp.b32 %r2197, %r2267, %r2267, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2201, %r2267, %r2267, %r2540;
	// end inline asm
	xor.b32  	%r3695, %r2201, %r2197;
	// begin inline asm
	shf.r.clamp.b32 %r2205, %r2267, %r2267, %r4014;
	// end inline asm
	xor.b32  	%r3696, %r3695, %r2205;
	mov.u32 	%r2210, %r2267;
	// begin inline asm
	not.b32  %r2210, %r2210;     
	and.b32  %r2209, %r2210, %r2211; 
	
	// end inline asm
	and.b32  	%r3918, %r2267, %r2239;
	xor.b32  	%r3698, %r2209, %r3918;
	add.s32 	%r3699, %r607, %r2183;
	add.s32 	%r3700, %r3699, %r3696;
	add.s32 	%r3701, %r3700, %r3698;
	add.s32 	%r3702, %r3701, 883997877;
	add.s32 	%r2295, %r3702, %r2139;
	// begin inline asm
	shf.r.clamp.b32 %r2213, %r2223, %r2223, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2217, %r2223, %r2223, %r2556;
	// end inline asm
	xor.b32  	%r3703, %r2217, %r2213;
	// begin inline asm
	shf.r.clamp.b32 %r2221, %r2223, %r2223, %r2560;
	// end inline asm
	xor.b32  	%r3704, %r3703, %r2221;
	xor.b32  	%r3705, %r2195, %r2167;
	and.b32  	%r3706, %r2223, %r3705;
	and.b32  	%r3707, %r2195, %r2167;
	xor.b32  	%r3708, %r3706, %r3707;
	add.s32 	%r3709, %r3702, %r3708;
	add.s32 	%r2251, %r3709, %r3704;
	// begin inline asm
	shf.r.clamp.b32 %r2225, %r2295, %r2295, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2229, %r2295, %r2295, %r2540;
	// end inline asm
	xor.b32  	%r3710, %r2229, %r2225;
	// begin inline asm
	shf.r.clamp.b32 %r2233, %r2295, %r2295, %r4014;
	// end inline asm
	xor.b32  	%r3711, %r3710, %r2233;
	mov.u32 	%r2238, %r2295;
	// begin inline asm
	not.b32  %r2238, %r2238;     
	and.b32  %r2237, %r2238, %r2239; 
	
	// end inline asm
	and.b32  	%r3917, %r2295, %r2267;
	xor.b32  	%r3713, %r2237, %r3917;
	add.s32 	%r3714, %r623, %r2211;
	add.s32 	%r3715, %r3714, %r3711;
	add.s32 	%r3716, %r3715, %r3713;
	add.s32 	%r3717, %r3716, 958139571;
	add.s32 	%r2323, %r3717, %r2167;
	// begin inline asm
	shf.r.clamp.b32 %r2241, %r2251, %r2251, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2245, %r2251, %r2251, %r2556;
	// end inline asm
	xor.b32  	%r3718, %r2245, %r2241;
	// begin inline asm
	shf.r.clamp.b32 %r2249, %r2251, %r2251, %r2560;
	// end inline asm
	xor.b32  	%r3719, %r3718, %r2249;
	xor.b32  	%r3720, %r2223, %r2195;
	and.b32  	%r3721, %r2251, %r3720;
	and.b32  	%r3722, %r2223, %r2195;
	xor.b32  	%r3723, %r3721, %r3722;
	add.s32 	%r3724, %r3717, %r3723;
	add.s32 	%r2279, %r3724, %r3719;
	// begin inline asm
	shf.r.clamp.b32 %r2253, %r2323, %r2323, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2257, %r2323, %r2323, %r2540;
	// end inline asm
	xor.b32  	%r3725, %r2257, %r2253;
	// begin inline asm
	shf.r.clamp.b32 %r2261, %r2323, %r2323, %r4014;
	// end inline asm
	xor.b32  	%r3726, %r3725, %r2261;
	mov.u32 	%r2266, %r2323;
	// begin inline asm
	not.b32  %r2266, %r2266;     
	and.b32  %r2265, %r2266, %r2267; 
	
	// end inline asm
	and.b32  	%r3916, %r2323, %r2295;
	xor.b32  	%r3728, %r2265, %r3916;
	add.s32 	%r3729, %r639, %r2239;
	add.s32 	%r3730, %r3729, %r3726;
	add.s32 	%r3731, %r3730, %r3728;
	add.s32 	%r3732, %r3731, 1322822218;
	add.s32 	%r2351, %r3732, %r2195;
	// begin inline asm
	shf.r.clamp.b32 %r2269, %r2279, %r2279, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2273, %r2279, %r2279, %r2556;
	// end inline asm
	xor.b32  	%r3733, %r2273, %r2269;
	// begin inline asm
	shf.r.clamp.b32 %r2277, %r2279, %r2279, %r2560;
	// end inline asm
	xor.b32  	%r3734, %r3733, %r2277;
	xor.b32  	%r3735, %r2251, %r2223;
	and.b32  	%r3736, %r2279, %r3735;
	and.b32  	%r3737, %r2251, %r2223;
	xor.b32  	%r3738, %r3736, %r3737;
	add.s32 	%r3739, %r3732, %r3738;
	add.s32 	%r2307, %r3739, %r3734;
	// begin inline asm
	shf.r.clamp.b32 %r2281, %r2351, %r2351, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2285, %r2351, %r2351, %r2540;
	// end inline asm
	xor.b32  	%r3740, %r2285, %r2281;
	// begin inline asm
	shf.r.clamp.b32 %r2289, %r2351, %r2351, %r4014;
	// end inline asm
	xor.b32  	%r3741, %r3740, %r2289;
	mov.u32 	%r2294, %r2351;
	// begin inline asm
	not.b32  %r2294, %r2294;     
	and.b32  %r2293, %r2294, %r2295; 
	
	// end inline asm
	and.b32  	%r3915, %r2351, %r2323;
	xor.b32  	%r3743, %r2293, %r3915;
	add.s32 	%r3744, %r655, %r2267;
	add.s32 	%r3745, %r3744, %r3741;
	add.s32 	%r3746, %r3745, %r3743;
	add.s32 	%r3747, %r3746, 1537002063;
	add.s32 	%r2379, %r3747, %r2223;
	// begin inline asm
	shf.r.clamp.b32 %r2297, %r2307, %r2307, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2301, %r2307, %r2307, %r2556;
	// end inline asm
	xor.b32  	%r3748, %r2301, %r2297;
	// begin inline asm
	shf.r.clamp.b32 %r2305, %r2307, %r2307, %r2560;
	// end inline asm
	xor.b32  	%r3749, %r3748, %r2305;
	xor.b32  	%r3750, %r2279, %r2251;
	and.b32  	%r3751, %r2307, %r3750;
	and.b32  	%r3752, %r2279, %r2251;
	xor.b32  	%r3753, %r3751, %r3752;
	add.s32 	%r3754, %r3747, %r3753;
	add.s32 	%r2335, %r3754, %r3749;
	// begin inline asm
	shf.r.clamp.b32 %r2309, %r2379, %r2379, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2313, %r2379, %r2379, %r2540;
	// end inline asm
	xor.b32  	%r3755, %r2313, %r2309;
	// begin inline asm
	shf.r.clamp.b32 %r2317, %r2379, %r2379, %r4014;
	// end inline asm
	xor.b32  	%r3756, %r3755, %r2317;
	mov.u32 	%r2322, %r2379;
	// begin inline asm
	not.b32  %r2322, %r2322;     
	and.b32  %r2321, %r2322, %r2323; 
	
	// end inline asm
	and.b32  	%r3914, %r2379, %r2351;
	xor.b32  	%r3758, %r2321, %r3914;
	add.s32 	%r3759, %r671, %r2295;
	add.s32 	%r3760, %r3759, %r3756;
	add.s32 	%r3761, %r3760, %r3758;
	add.s32 	%r3762, %r3761, 1747873779;
	add.s32 	%r2407, %r3762, %r2251;
	// begin inline asm
	shf.r.clamp.b32 %r2325, %r2335, %r2335, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2329, %r2335, %r2335, %r2556;
	// end inline asm
	xor.b32  	%r3763, %r2329, %r2325;
	// begin inline asm
	shf.r.clamp.b32 %r2333, %r2335, %r2335, %r2560;
	// end inline asm
	xor.b32  	%r3764, %r3763, %r2333;
	xor.b32  	%r3765, %r2307, %r2279;
	and.b32  	%r3766, %r2335, %r3765;
	and.b32  	%r3767, %r2307, %r2279;
	xor.b32  	%r3768, %r3766, %r3767;
	add.s32 	%r3769, %r3762, %r3768;
	add.s32 	%r2363, %r3769, %r3764;
	// begin inline asm
	shf.r.clamp.b32 %r2337, %r2407, %r2407, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2341, %r2407, %r2407, %r2540;
	// end inline asm
	xor.b32  	%r3770, %r2341, %r2337;
	// begin inline asm
	shf.r.clamp.b32 %r2345, %r2407, %r2407, %r4014;
	// end inline asm
	xor.b32  	%r3771, %r3770, %r2345;
	mov.u32 	%r2350, %r2407;
	// begin inline asm
	not.b32  %r2350, %r2350;     
	and.b32  %r2349, %r2350, %r2351; 
	
	// end inline asm
	and.b32  	%r3913, %r2407, %r2379;
	xor.b32  	%r3773, %r2349, %r3913;
	add.s32 	%r3774, %r687, %r2323;
	add.s32 	%r3775, %r3774, %r3771;
	add.s32 	%r3776, %r3775, %r3773;
	add.s32 	%r3777, %r3776, 1955562222;
	add.s32 	%r2435, %r3777, %r2279;
	// begin inline asm
	shf.r.clamp.b32 %r2353, %r2363, %r2363, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2357, %r2363, %r2363, %r2556;
	// end inline asm
	xor.b32  	%r3778, %r2357, %r2353;
	// begin inline asm
	shf.r.clamp.b32 %r2361, %r2363, %r2363, %r2560;
	// end inline asm
	xor.b32  	%r3779, %r3778, %r2361;
	xor.b32  	%r3780, %r2335, %r2307;
	and.b32  	%r3781, %r2363, %r3780;
	and.b32  	%r3782, %r2335, %r2307;
	xor.b32  	%r3783, %r3781, %r3782;
	add.s32 	%r3784, %r3777, %r3783;
	add.s32 	%r2391, %r3784, %r3779;
	// begin inline asm
	shf.r.clamp.b32 %r2365, %r2435, %r2435, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2369, %r2435, %r2435, %r2540;
	// end inline asm
	xor.b32  	%r3785, %r2369, %r2365;
	// begin inline asm
	shf.r.clamp.b32 %r2373, %r2435, %r2435, %r4014;
	// end inline asm
	xor.b32  	%r3786, %r3785, %r2373;
	mov.u32 	%r2378, %r2435;
	// begin inline asm
	not.b32  %r2378, %r2378;     
	and.b32  %r2377, %r2378, %r2379; 
	
	// end inline asm
	and.b32  	%r3912, %r2435, %r2407;
	xor.b32  	%r3788, %r2377, %r3912;
	add.s32 	%r3789, %r703, %r2351;
	add.s32 	%r3790, %r3789, %r3786;
	add.s32 	%r3791, %r3790, %r3788;
	add.s32 	%r3792, %r3791, 2024104815;
	add.s32 	%r2463, %r3792, %r2307;
	// begin inline asm
	shf.r.clamp.b32 %r2381, %r2391, %r2391, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2385, %r2391, %r2391, %r2556;
	// end inline asm
	xor.b32  	%r3793, %r2385, %r2381;
	// begin inline asm
	shf.r.clamp.b32 %r2389, %r2391, %r2391, %r2560;
	// end inline asm
	xor.b32  	%r3794, %r3793, %r2389;
	xor.b32  	%r3795, %r2363, %r2335;
	and.b32  	%r3796, %r2391, %r3795;
	and.b32  	%r3797, %r2363, %r2335;
	xor.b32  	%r3798, %r3796, %r3797;
	add.s32 	%r3799, %r3792, %r3798;
	add.s32 	%r2419, %r3799, %r3794;
	// begin inline asm
	shf.r.clamp.b32 %r2393, %r2463, %r2463, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2397, %r2463, %r2463, %r2540;
	// end inline asm
	xor.b32  	%r3800, %r2397, %r2393;
	// begin inline asm
	shf.r.clamp.b32 %r2401, %r2463, %r2463, %r4014;
	// end inline asm
	xor.b32  	%r3801, %r3800, %r2401;
	mov.u32 	%r2406, %r2463;
	// begin inline asm
	not.b32  %r2406, %r2406;     
	and.b32  %r2405, %r2406, %r2407; 
	
	// end inline asm
	and.b32  	%r3911, %r2463, %r2435;
	xor.b32  	%r3803, %r2405, %r3911;
	add.s32 	%r3804, %r719, %r2379;
	add.s32 	%r3805, %r3804, %r3801;
	add.s32 	%r3806, %r3805, %r3803;
	add.s32 	%r3807, %r3806, -2067236844;
	add.s32 	%r2491, %r3807, %r2335;
	// begin inline asm
	shf.r.clamp.b32 %r2409, %r2419, %r2419, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2413, %r2419, %r2419, %r2556;
	// end inline asm
	xor.b32  	%r3808, %r2413, %r2409;
	// begin inline asm
	shf.r.clamp.b32 %r2417, %r2419, %r2419, %r2560;
	// end inline asm
	xor.b32  	%r3809, %r3808, %r2417;
	xor.b32  	%r3810, %r2391, %r2363;
	and.b32  	%r3811, %r2419, %r3810;
	and.b32  	%r3812, %r2391, %r2363;
	xor.b32  	%r3813, %r3811, %r3812;
	add.s32 	%r3814, %r3807, %r3813;
	add.s32 	%r2447, %r3814, %r3809;
	// begin inline asm
	shf.r.clamp.b32 %r2421, %r2491, %r2491, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2425, %r2491, %r2491, %r2540;
	// end inline asm
	xor.b32  	%r3815, %r2425, %r2421;
	// begin inline asm
	shf.r.clamp.b32 %r2429, %r2491, %r2491, %r4014;
	// end inline asm
	xor.b32  	%r3816, %r3815, %r2429;
	mov.u32 	%r2434, %r2491;
	// begin inline asm
	not.b32  %r2434, %r2434;     
	and.b32  %r2433, %r2434, %r2435; 
	
	// end inline asm
	and.b32  	%r3910, %r2491, %r2463;
	xor.b32  	%r3818, %r2433, %r3910;
	add.s32 	%r3819, %r735, %r2407;
	add.s32 	%r3820, %r3819, %r3816;
	add.s32 	%r3821, %r3820, %r3818;
	add.s32 	%r3822, %r3821, -1933114872;
	add.s32 	%r2519, %r3822, %r2363;
	// begin inline asm
	shf.r.clamp.b32 %r2437, %r2447, %r2447, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2441, %r2447, %r2447, %r2556;
	// end inline asm
	xor.b32  	%r3823, %r2441, %r2437;
	// begin inline asm
	shf.r.clamp.b32 %r2445, %r2447, %r2447, %r2560;
	// end inline asm
	xor.b32  	%r3824, %r3823, %r2445;
	xor.b32  	%r3825, %r2419, %r2391;
	and.b32  	%r3826, %r2447, %r3825;
	and.b32  	%r3827, %r2419, %r2391;
	xor.b32  	%r3828, %r3826, %r3827;
	add.s32 	%r3829, %r3822, %r3828;
	add.s32 	%r2475, %r3829, %r3824;
	// begin inline asm
	shf.r.clamp.b32 %r2449, %r2519, %r2519, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2453, %r2519, %r2519, %r2540;
	// end inline asm
	xor.b32  	%r3830, %r2453, %r2449;
	// begin inline asm
	shf.r.clamp.b32 %r2457, %r2519, %r2519, %r4014;
	// end inline asm
	xor.b32  	%r3831, %r3830, %r2457;
	mov.u32 	%r2462, %r2519;
	// begin inline asm
	not.b32  %r2462, %r2462;     
	and.b32  %r2461, %r2462, %r2463; 
	
	// end inline asm
	and.b32  	%r3909, %r2519, %r2491;
	xor.b32  	%r3833, %r2461, %r3909;
	add.s32 	%r3834, %r751, %r2435;
	add.s32 	%r3835, %r3834, %r3831;
	add.s32 	%r3836, %r3835, %r3833;
	add.s32 	%r3837, %r3836, -1866530822;
	add.s32 	%r2547, %r3837, %r2391;
	// begin inline asm
	shf.r.clamp.b32 %r2465, %r2475, %r2475, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2469, %r2475, %r2475, %r2556;
	// end inline asm
	xor.b32  	%r3838, %r2469, %r2465;
	// begin inline asm
	shf.r.clamp.b32 %r2473, %r2475, %r2475, %r2560;
	// end inline asm
	xor.b32  	%r3839, %r3838, %r2473;
	xor.b32  	%r3840, %r2447, %r2419;
	and.b32  	%r3841, %r2475, %r3840;
	and.b32  	%r3842, %r2447, %r2419;
	xor.b32  	%r3843, %r3841, %r3842;
	add.s32 	%r3844, %r3837, %r3843;
	add.s32 	%r2503, %r3844, %r3839;
	// begin inline asm
	shf.r.clamp.b32 %r2477, %r2547, %r2547, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2481, %r2547, %r2547, %r2540;
	// end inline asm
	xor.b32  	%r3845, %r2481, %r2477;
	// begin inline asm
	shf.r.clamp.b32 %r2485, %r2547, %r2547, %r4014;
	// end inline asm
	xor.b32  	%r3846, %r3845, %r2485;
	mov.u32 	%r2490, %r2547;
	// begin inline asm
	not.b32  %r2490, %r2490;     
	and.b32  %r2489, %r2490, %r2491; 
	
	// end inline asm
	and.b32  	%r3908, %r2547, %r2519;
	xor.b32  	%r3848, %r2489, %r3908;
	add.s32 	%r3849, %r767, %r2463;
	add.s32 	%r3850, %r3849, %r3846;
	add.s32 	%r3851, %r3850, %r3848;
	add.s32 	%r3852, %r3851, -1538233109;
	add.s32 	%r2520, %r3852, %r2419;
	// begin inline asm
	shf.r.clamp.b32 %r2493, %r2503, %r2503, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2497, %r2503, %r2503, %r2556;
	// end inline asm
	xor.b32  	%r3853, %r2497, %r2493;
	// begin inline asm
	shf.r.clamp.b32 %r2501, %r2503, %r2503, %r2560;
	// end inline asm
	xor.b32  	%r3854, %r3853, %r2501;
	xor.b32  	%r3855, %r2475, %r2447;
	and.b32  	%r3856, %r2503, %r3855;
	and.b32  	%r3857, %r2475, %r2447;
	xor.b32  	%r3858, %r3856, %r3857;
	add.s32 	%r3859, %r3852, %r3858;
	add.s32 	%r2531, %r3859, %r3854;
	// begin inline asm
	shf.r.clamp.b32 %r2505, %r2520, %r2520, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2509, %r2520, %r2520, %r2540;
	// end inline asm
	xor.b32  	%r3860, %r2509, %r2505;
	// begin inline asm
	shf.r.clamp.b32 %r2513, %r2520, %r2520, %r4014;
	// end inline asm
	xor.b32  	%r3861, %r3860, %r2513;
	mov.u32 	%r2518, %r2520;
	// begin inline asm
	not.b32  %r2518, %r2518;     
	and.b32  %r2517, %r2518, %r2519; 
	
	// end inline asm
	and.b32  	%r3907, %r2520, %r2547;
	xor.b32  	%r3863, %r2517, %r3907;
	add.s32 	%r3864, %r727, %r671;
	add.s32 	%r3865, %r3864, %r2932;
	add.s32 	%r3866, %r3865, %r2935;
	add.s32 	%r3867, %r3866, %r2491;
	add.s32 	%r3868, %r3867, %r3861;
	add.s32 	%r3869, %r3868, %r3863;
	add.s32 	%r3870, %r3869, -1090935817;
	add.s32 	%r2548, %r3870, %r2447;
	// begin inline asm
	shf.r.clamp.b32 %r2521, %r2531, %r2531, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2525, %r2531, %r2531, %r2556;
	// end inline asm
	xor.b32  	%r3871, %r2525, %r2521;
	// begin inline asm
	shf.r.clamp.b32 %r2529, %r2531, %r2531, %r2560;
	// end inline asm
	xor.b32  	%r3872, %r3871, %r2529;
	xor.b32  	%r3873, %r2503, %r2475;
	and.b32  	%r3874, %r2531, %r3873;
	and.b32  	%r3875, %r2503, %r2475;
	xor.b32  	%r3876, %r3874, %r3875;
	add.s32 	%r3877, %r3870, %r3876;
	add.s32 	%r2559, %r3877, %r3872;
	// begin inline asm
	shf.r.clamp.b32 %r2533, %r2548, %r2548, %r2536;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2537, %r2548, %r2548, %r2540;
	// end inline asm
	xor.b32  	%r3878, %r2537, %r2533;
	// begin inline asm
	shf.r.clamp.b32 %r2541, %r2548, %r2548, %r4014;
	// end inline asm
	xor.b32  	%r3879, %r3878, %r2541;
	mov.u32 	%r2546, %r2548;
	// begin inline asm
	not.b32  %r2546, %r2546;     
	and.b32  %r2545, %r2546, %r2547; 
	
	// end inline asm
	and.b32  	%r3906, %r2548, %r2520;
	xor.b32  	%r3881, %r2545, %r3906;
	add.s32 	%r3882, %r743, %r687;
	add.s32 	%r3883, %r3882, %r2938;
	add.s32 	%r3884, %r3883, %r2941;
	add.s32 	%r3885, %r3884, %r2519;
	add.s32 	%r3886, %r3885, %r3879;
	add.s32 	%r3887, %r3886, %r3881;
	add.s32 	%r3888, %r3887, -965641998;
	// begin inline asm
	shf.r.clamp.b32 %r2549, %r2559, %r2559, %r4004;
	// end inline asm
	// begin inline asm
	shf.r.clamp.b32 %r2553, %r2559, %r2559, %r2556;
	// end inline asm
	xor.b32  	%r3889, %r2553, %r2549;
	// begin inline asm
	shf.r.clamp.b32 %r2557, %r2559, %r2559, %r2560;
	// end inline asm
	xor.b32  	%r3890, %r3889, %r2557;
	xor.b32  	%r3891, %r2531, %r2503;
	and.b32  	%r3892, %r2559, %r3891;
	and.b32  	%r3893, %r2531, %r2503;
	xor.b32  	%r3894, %r3892, %r3893;
	add.s32 	%r3895, %r3894, %r3888;
	add.s32 	%r3896, %r3895, %r3890;
	add.s32 	%r3897, %r3896, 1779033703;
	add.s32 	%r3898, %r2559, -1150833019;
	add.s32 	%r3899, %r2531, 1013904242;
	add.s32 	%r3900, %r2503, -1521486534;
	add.s32 	%r3901, %r2475, %r3888;
	add.s32 	%r3902, %r3901, 1359893119;
	add.s32 	%r3903, %r2548, -1694144372;
	add.s32 	%r3904, %r2520, 528734635;
	add.s32 	%r3905, %r2547, 1541459225;
	st.global.u32 	[%rd2], %r3897;
	st.global.u32 	[%rd2+4], %r3898;
	st.global.u32 	[%rd2+8], %r3899;
	st.global.u32 	[%rd2+12], %r3900;
	st.global.u32 	[%rd2+16], %r3902;
	st.global.u32 	[%rd2+20], %r3903;
	st.global.u32 	[%rd2+24], %r3904;
	st.global.u32 	[%rd2+28], %r3905;
	ret;

}

